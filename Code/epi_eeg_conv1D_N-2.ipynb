{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"epi_eeg_conv1D_N-2.ipynb","provenance":[{"file_id":"1iMQSmCTe8qbXD7fYd5iMTW-3MIGgEUIP","timestamp":1594649002058},{"file_id":"15xAyW7q6DS5Q7H5AcbH3fa-ELwgrEkQc","timestamp":1590467082991}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"cMcs6N31D6LZ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"executionInfo":{"status":"ok","timestamp":1594657662517,"user_tz":-330,"elapsed":32196,"user":{"displayName":"Manoj Kaushik","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhhMecDSNh8KC1pSFRd792Uf7-_hhbyuVBzLZm2nQ=s64","userId":"07264516168551766650"}},"outputId":"4e8aca2b-985e-4d52-cd3e-6df44485d0c7"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZBI6Re1V8YVf","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594657664075,"user_tz":-330,"elapsed":3626,"user":{"displayName":"Manoj Kaushik","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhhMecDSNh8KC1pSFRd792Uf7-_hhbyuVBzLZm2nQ=s64","userId":"07264516168551766650"}},"outputId":"426449a5-5006-43b5-cf61-1f893088e993"},"source":["from __future__ import print_function\n","from keras.preprocessing import sequence\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout, Activation\n","from keras.layers import Embedding\n","from keras.layers import Conv1D, GlobalMaxPooling1D\n","from keras.datasets import imdb"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"LhlKwS3QD4mm","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594658912619,"user_tz":-330,"elapsed":1317,"user":{"displayName":"Manoj Kaushik","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhhMecDSNh8KC1pSFRd792Uf7-_hhbyuVBzLZm2nQ=s64","userId":"07264516168551766650"}}},"source":["import os\n","import pandas as pd\n","import numpy as np\n","import sys\n","from tqdm import tqdm\n","import glob\n","\n","row = 8\n","def prep_data(path):\n","  data = []\n","  labels = []\n","  filenames = [img for img in glob.glob(path)]\n","  for name in tqdm(filenames):\n","      df = pd.read_csv(name, header=None, error_bad_lines=False)\n","      values = df.values[row - 1]\n","      data.append(values.tolist())\n","      split = name.split(os.sep)[-2]\n","      if split == 'control':\n","        labels.append(0)\n","      else:\n","        labels.append(1)\n","\n","  data = np.asarray(data)\n","  labels = np.asarray(labels)\n","  return data,labels"],"execution_count":25,"outputs":[]},{"cell_type":"code","metadata":{"id":"AypffwijnbM5","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594658120053,"user_tz":-330,"elapsed":440701,"user":{"displayName":"Manoj Kaushik","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhhMecDSNh8KC1pSFRd792Uf7-_hhbyuVBzLZm2nQ=s64","userId":"07264516168551766650"}},"outputId":"5dc8603f-e128-4fd4-ac1a-94e6b096f048"},"source":["train_x, train_y = prep_data('/content/drive/My Drive/datasets/N_dataset/train/*/*')"],"execution_count":4,"outputs":[{"output_type":"stream","text":["100%|██████████| 143/143 [07:16<00:00,  3.06s/it]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"PLCnmnmEnkAl","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594658294835,"user_tz":-330,"elapsed":598061,"user":{"displayName":"Manoj Kaushik","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhhMecDSNh8KC1pSFRd792Uf7-_hhbyuVBzLZm2nQ=s64","userId":"07264516168551766650"}},"outputId":"fdcd9159-f2ed-435a-e1a3-6dbc07e7ae45"},"source":["val_x, val_y = prep_data('/content/drive/My Drive/datasets/N_dataset/val/*/*')"],"execution_count":5,"outputs":[{"output_type":"stream","text":["100%|██████████| 55/55 [02:54<00:00,  3.17s/it]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"gd31mm9Mnrc9","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594658371715,"user_tz":-330,"elapsed":672933,"user":{"displayName":"Manoj Kaushik","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhhMecDSNh8KC1pSFRd792Uf7-_hhbyuVBzLZm2nQ=s64","userId":"07264516168551766650"}},"outputId":"30650e1e-b7e3-4a33-ee2f-89c39a6d4d23"},"source":["test_x, test_y = prep_data('/content/drive/My Drive/datasets/N_dataset/test/*/*')"],"execution_count":6,"outputs":[{"output_type":"stream","text":["100%|██████████| 23/23 [01:15<00:00,  3.30s/it]\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"e3krLu5c6Gl2","colab_type":"code","colab":{}},"source":["# from sklearn.model_selection import train_test_split\n","# x_train, x_test, y_train, y_test = train_test_split(data, labels, test_size=0.33, random_state=42)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CaxLF_RI6qCG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594661146396,"user_tz":-330,"elapsed":1268,"user":{"displayName":"Manoj Kaushik","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhhMecDSNh8KC1pSFRd792Uf7-_hhbyuVBzLZm2nQ=s64","userId":"07264516168551766650"}},"outputId":"43d73464-cf00-4631-f0c4-51081161b95d"},"source":["print('Pad sequences (samples x time)')\n","maxlen = 1000\n","train_x = sequence.pad_sequences(train_x, maxlen=maxlen)\n","val_x = sequence.pad_sequences(val_x, maxlen=maxlen)\n","test_x = sequence.pad_sequences(test_x, maxlen=maxlen)"],"execution_count":110,"outputs":[{"output_type":"stream","text":["Pad sequences (samples x time)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Q-CEKJ7h391A","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594661147279,"user_tz":-330,"elapsed":2101,"user":{"displayName":"Manoj Kaushik","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhhMecDSNh8KC1pSFRd792Uf7-_hhbyuVBzLZm2nQ=s64","userId":"07264516168551766650"}}},"source":["model = Sequential()\n","\n","batch_size = 32\n","embedding_dims = 5\n","filters = 80\n","kernel_size = 3\n","hidden_dims = 300\n","max_features = 8000\n","\n","# we start off with an efficient embedding layer which maps\n","# our vocab indices into embedding_dims dimensions\n","model.add(Embedding(max_features, embedding_dims, input_length=maxlen))\n","model.add(Dropout(0.2))\n","\n","# we add a Convolution1D, which will learn filters\n","# word group filters of size filter_length:\n","model.add(Conv1D(filters, kernel_size, padding='valid', activation='relu', strides=1))\n","# we use max pooling:\n","model.add(GlobalMaxPooling1D())\n","\n","# We add a vanilla hidden layer:\n","model.add(Dense(hidden_dims))\n","model.add(Dropout(0.2))\n","model.add(Activation('relu'))\n","\n","# We project onto a single unit output layer, and squash it with a sigmoid:\n","model.add(Dense(1))\n","model.add(Activation('sigmoid'))\n","\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"],"execution_count":111,"outputs":[]},{"cell_type":"code","metadata":{"id":"3onZAaaIfJLq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594661147284,"user_tz":-330,"elapsed":2079,"user":{"displayName":"Manoj Kaushik","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhhMecDSNh8KC1pSFRd792Uf7-_hhbyuVBzLZm2nQ=s64","userId":"07264516168551766650"}},"outputId":"0bcba3ed-c3af-42d5-a1a2-a5a276d58cc7"},"source":["train_x.shape"],"execution_count":112,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(143, 1000)"]},"metadata":{"tags":[]},"execution_count":112}]},{"cell_type":"code","metadata":{"id":"NEohXimk7IAp","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":459},"executionInfo":{"status":"ok","timestamp":1594661147287,"user_tz":-330,"elapsed":2045,"user":{"displayName":"Manoj Kaushik","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhhMecDSNh8KC1pSFRd792Uf7-_hhbyuVBzLZm2nQ=s64","userId":"07264516168551766650"}},"outputId":"1db5064d-373d-4739-83ee-bd8f6e5ed293"},"source":["model.summary()"],"execution_count":113,"outputs":[{"output_type":"stream","text":["Model: \"sequential_4\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding_4 (Embedding)      (None, 1000, 5)           40000     \n","_________________________________________________________________\n","dropout_7 (Dropout)          (None, 1000, 5)           0         \n","_________________________________________________________________\n","conv1d_4 (Conv1D)            (None, 998, 80)           1280      \n","_________________________________________________________________\n","global_max_pooling1d_4 (Glob (None, 80)                0         \n","_________________________________________________________________\n","dense_7 (Dense)              (None, 300)               24300     \n","_________________________________________________________________\n","dropout_8 (Dropout)          (None, 300)               0         \n","_________________________________________________________________\n","activation_7 (Activation)    (None, 300)               0         \n","_________________________________________________________________\n","dense_8 (Dense)              (None, 1)                 301       \n","_________________________________________________________________\n","activation_8 (Activation)    (None, 1)                 0         \n","=================================================================\n","Total params: 65,881\n","Trainable params: 65,881\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LUNKlEMmP8kT","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594661147289,"user_tz":-330,"elapsed":2004,"user":{"displayName":"Manoj Kaushik","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhhMecDSNh8KC1pSFRd792Uf7-_hhbyuVBzLZm2nQ=s64","userId":"07264516168551766650"}}},"source":["slug = 'gazar_july_13_N'\n","epochs = 1000"],"execution_count":114,"outputs":[]},{"cell_type":"code","metadata":{"id":"5uy_0UP0ptSo","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594661148480,"user_tz":-330,"elapsed":3172,"user":{"displayName":"Manoj Kaushik","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhhMecDSNh8KC1pSFRd792Uf7-_hhbyuVBzLZm2nQ=s64","userId":"07264516168551766650"}}},"source":["pathModelSave = '/content/drive/My Drive/saveModels/epi_eeg_conv1D'+'_nigiria_'+str(embedding_dims)+'_'+str(filters)+'_'+str(batch_size)+'_'+str(epochs)+'_'+slug+'_.hdf5'\n","pathToSaveCSV = '/content/drive/My Drive/saveModels/csv/epi_eeg_conv1D'+'_nigiria_'+str(embedding_dims)+'_'+str(filters)+'_'+str(batch_size)+'_'+str(epochs)+'_'+slug+'_.csv'"],"execution_count":115,"outputs":[]},{"cell_type":"code","metadata":{"id":"wapF8cmLrSVJ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1594661205685,"user_tz":-330,"elapsed":60356,"user":{"displayName":"Manoj Kaushik","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhhMecDSNh8KC1pSFRd792Uf7-_hhbyuVBzLZm2nQ=s64","userId":"07264516168551766650"}},"outputId":"e7fb8560-8c3d-4b78-dd76-3d2b64277a92"},"source":["import time\n","from keras.callbacks import ModelCheckpoint, CSVLogger\n","\n","checkpoint = ModelCheckpoint(pathModelSave, monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n","csv_logger = CSVLogger(pathToSaveCSV, append=False, separator=',')\n","\n","tic = time.clock()\n","history = model.fit(\n","          train_x, train_y,\n","          batch_size=batch_size,\n","          epochs=epochs,\n","          callbacks = [checkpoint, csv_logger],\n","          validation_data=(val_x, val_y))\n","toc = time.clock()"],"execution_count":116,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"],"name":"stderr"},{"output_type":"stream","text":["Train on 143 samples, validate on 55 samples\n","Epoch 1/1000\n","143/143 [==============================] - 0s 3ms/step - loss: 0.6897 - accuracy: 0.5385 - val_loss: 0.6842 - val_accuracy: 0.5818\n","\n","Epoch 00001: val_accuracy improved from -inf to 0.58182, saving model to /content/drive/My Drive/saveModels/epi_eeg_conv1D_nigiria_5_80_32_1000_gazar_july_13_.hdf5\n","Epoch 2/1000\n","143/143 [==============================] - 0s 353us/step - loss: 0.6839 - accuracy: 0.5804 - val_loss: 0.6815 - val_accuracy: 0.5818\n","\n","Epoch 00002: val_accuracy did not improve from 0.58182\n","Epoch 3/1000\n","143/143 [==============================] - 0s 358us/step - loss: 0.6786 - accuracy: 0.5804 - val_loss: 0.6808 - val_accuracy: 0.5818\n","\n","Epoch 00003: val_accuracy did not improve from 0.58182\n","Epoch 4/1000\n","143/143 [==============================] - 0s 339us/step - loss: 0.6740 - accuracy: 0.5804 - val_loss: 0.6806 - val_accuracy: 0.5818\n","\n","Epoch 00004: val_accuracy did not improve from 0.58182\n","Epoch 5/1000\n","143/143 [==============================] - 0s 356us/step - loss: 0.6702 - accuracy: 0.5804 - val_loss: 0.6810 - val_accuracy: 0.5818\n","\n","Epoch 00005: val_accuracy did not improve from 0.58182\n","Epoch 6/1000\n","143/143 [==============================] - 0s 359us/step - loss: 0.6696 - accuracy: 0.5804 - val_loss: 0.6819 - val_accuracy: 0.5818\n","\n","Epoch 00006: val_accuracy did not improve from 0.58182\n","Epoch 7/1000\n","143/143 [==============================] - 0s 360us/step - loss: 0.6644 - accuracy: 0.5804 - val_loss: 0.6839 - val_accuracy: 0.5818\n","\n","Epoch 00007: val_accuracy did not improve from 0.58182\n","Epoch 8/1000\n","143/143 [==============================] - 0s 350us/step - loss: 0.6587 - accuracy: 0.5804 - val_loss: 0.6857 - val_accuracy: 0.5818\n","\n","Epoch 00008: val_accuracy did not improve from 0.58182\n","Epoch 9/1000\n","143/143 [==============================] - 0s 343us/step - loss: 0.6510 - accuracy: 0.5804 - val_loss: 0.6871 - val_accuracy: 0.5818\n","\n","Epoch 00009: val_accuracy did not improve from 0.58182\n","Epoch 10/1000\n","143/143 [==============================] - 0s 427us/step - loss: 0.6406 - accuracy: 0.5804 - val_loss: 0.6897 - val_accuracy: 0.5818\n","\n","Epoch 00010: val_accuracy did not improve from 0.58182\n","Epoch 11/1000\n","143/143 [==============================] - 0s 354us/step - loss: 0.6346 - accuracy: 0.5804 - val_loss: 0.6924 - val_accuracy: 0.5818\n","\n","Epoch 00011: val_accuracy did not improve from 0.58182\n","Epoch 12/1000\n","143/143 [==============================] - 0s 374us/step - loss: 0.6240 - accuracy: 0.5804 - val_loss: 0.6961 - val_accuracy: 0.5636\n","\n","Epoch 00012: val_accuracy did not improve from 0.58182\n","Epoch 13/1000\n","143/143 [==============================] - 0s 343us/step - loss: 0.6149 - accuracy: 0.6084 - val_loss: 0.7040 - val_accuracy: 0.5636\n","\n","Epoch 00013: val_accuracy did not improve from 0.58182\n","Epoch 14/1000\n","143/143 [==============================] - 0s 351us/step - loss: 0.5980 - accuracy: 0.6503 - val_loss: 0.7084 - val_accuracy: 0.5636\n","\n","Epoch 00014: val_accuracy did not improve from 0.58182\n","Epoch 15/1000\n","143/143 [==============================] - 0s 358us/step - loss: 0.5872 - accuracy: 0.6923 - val_loss: 0.7177 - val_accuracy: 0.5636\n","\n","Epoch 00015: val_accuracy did not improve from 0.58182\n","Epoch 16/1000\n","143/143 [==============================] - 0s 350us/step - loss: 0.5757 - accuracy: 0.6993 - val_loss: 0.7252 - val_accuracy: 0.5273\n","\n","Epoch 00016: val_accuracy did not improve from 0.58182\n","Epoch 17/1000\n","143/143 [==============================] - 0s 353us/step - loss: 0.5602 - accuracy: 0.6993 - val_loss: 0.7416 - val_accuracy: 0.5455\n","\n","Epoch 00017: val_accuracy did not improve from 0.58182\n","Epoch 18/1000\n","143/143 [==============================] - 0s 342us/step - loss: 0.5413 - accuracy: 0.7273 - val_loss: 0.7427 - val_accuracy: 0.5455\n","\n","Epoch 00018: val_accuracy did not improve from 0.58182\n","Epoch 19/1000\n","143/143 [==============================] - 0s 375us/step - loss: 0.5313 - accuracy: 0.7343 - val_loss: 0.7573 - val_accuracy: 0.5455\n","\n","Epoch 00019: val_accuracy did not improve from 0.58182\n","Epoch 20/1000\n","143/143 [==============================] - 0s 353us/step - loss: 0.5160 - accuracy: 0.7273 - val_loss: 0.7572 - val_accuracy: 0.4909\n","\n","Epoch 00020: val_accuracy did not improve from 0.58182\n","Epoch 21/1000\n","143/143 [==============================] - 0s 353us/step - loss: 0.4940 - accuracy: 0.7972 - val_loss: 0.7639 - val_accuracy: 0.5273\n","\n","Epoch 00021: val_accuracy did not improve from 0.58182\n","Epoch 22/1000\n","143/143 [==============================] - 0s 358us/step - loss: 0.4832 - accuracy: 0.7972 - val_loss: 0.7737 - val_accuracy: 0.4727\n","\n","Epoch 00022: val_accuracy did not improve from 0.58182\n","Epoch 23/1000\n","143/143 [==============================] - 0s 351us/step - loss: 0.4607 - accuracy: 0.8042 - val_loss: 0.7862 - val_accuracy: 0.4727\n","\n","Epoch 00023: val_accuracy did not improve from 0.58182\n","Epoch 24/1000\n","143/143 [==============================] - 0s 353us/step - loss: 0.4411 - accuracy: 0.8042 - val_loss: 0.8052 - val_accuracy: 0.4364\n","\n","Epoch 00024: val_accuracy did not improve from 0.58182\n","Epoch 25/1000\n","143/143 [==============================] - 0s 343us/step - loss: 0.4303 - accuracy: 0.7972 - val_loss: 0.8143 - val_accuracy: 0.4727\n","\n","Epoch 00025: val_accuracy did not improve from 0.58182\n","Epoch 26/1000\n","143/143 [==============================] - 0s 345us/step - loss: 0.4121 - accuracy: 0.8322 - val_loss: 0.8259 - val_accuracy: 0.4545\n","\n","Epoch 00026: val_accuracy did not improve from 0.58182\n","Epoch 27/1000\n","143/143 [==============================] - 0s 354us/step - loss: 0.3992 - accuracy: 0.8531 - val_loss: 0.8490 - val_accuracy: 0.4545\n","\n","Epoch 00027: val_accuracy did not improve from 0.58182\n","Epoch 28/1000\n","143/143 [==============================] - 0s 359us/step - loss: 0.3848 - accuracy: 0.8462 - val_loss: 0.8674 - val_accuracy: 0.4545\n","\n","Epoch 00028: val_accuracy did not improve from 0.58182\n","Epoch 29/1000\n","143/143 [==============================] - 0s 447us/step - loss: 0.3721 - accuracy: 0.8671 - val_loss: 0.8927 - val_accuracy: 0.4545\n","\n","Epoch 00029: val_accuracy did not improve from 0.58182\n","Epoch 30/1000\n","143/143 [==============================] - 0s 367us/step - loss: 0.3571 - accuracy: 0.8601 - val_loss: 0.9189 - val_accuracy: 0.4545\n","\n","Epoch 00030: val_accuracy did not improve from 0.58182\n","Epoch 31/1000\n","143/143 [==============================] - 0s 359us/step - loss: 0.3477 - accuracy: 0.8671 - val_loss: 0.9463 - val_accuracy: 0.4364\n","\n","Epoch 00031: val_accuracy did not improve from 0.58182\n","Epoch 32/1000\n","143/143 [==============================] - 0s 348us/step - loss: 0.3410 - accuracy: 0.8601 - val_loss: 0.9648 - val_accuracy: 0.4364\n","\n","Epoch 00032: val_accuracy did not improve from 0.58182\n","Epoch 33/1000\n","143/143 [==============================] - 0s 339us/step - loss: 0.3204 - accuracy: 0.9021 - val_loss: 0.9894 - val_accuracy: 0.4364\n","\n","Epoch 00033: val_accuracy did not improve from 0.58182\n","Epoch 34/1000\n","143/143 [==============================] - 0s 335us/step - loss: 0.3208 - accuracy: 0.8741 - val_loss: 0.9987 - val_accuracy: 0.4364\n","\n","Epoch 00034: val_accuracy did not improve from 0.58182\n","Epoch 35/1000\n","143/143 [==============================] - 0s 346us/step - loss: 0.3068 - accuracy: 0.8881 - val_loss: 1.0069 - val_accuracy: 0.4364\n","\n","Epoch 00035: val_accuracy did not improve from 0.58182\n","Epoch 36/1000\n","143/143 [==============================] - 0s 339us/step - loss: 0.2966 - accuracy: 0.8951 - val_loss: 1.0156 - val_accuracy: 0.4545\n","\n","Epoch 00036: val_accuracy did not improve from 0.58182\n","Epoch 37/1000\n","143/143 [==============================] - 0s 334us/step - loss: 0.2899 - accuracy: 0.9021 - val_loss: 1.0373 - val_accuracy: 0.4727\n","\n","Epoch 00037: val_accuracy did not improve from 0.58182\n","Epoch 38/1000\n","143/143 [==============================] - 0s 371us/step - loss: 0.2860 - accuracy: 0.9231 - val_loss: 1.0547 - val_accuracy: 0.4545\n","\n","Epoch 00038: val_accuracy did not improve from 0.58182\n","Epoch 39/1000\n","143/143 [==============================] - 0s 339us/step - loss: 0.2652 - accuracy: 0.9161 - val_loss: 1.0811 - val_accuracy: 0.4545\n","\n","Epoch 00039: val_accuracy did not improve from 0.58182\n","Epoch 40/1000\n","143/143 [==============================] - 0s 349us/step - loss: 0.2572 - accuracy: 0.9231 - val_loss: 1.1123 - val_accuracy: 0.4545\n","\n","Epoch 00040: val_accuracy did not improve from 0.58182\n","Epoch 41/1000\n","143/143 [==============================] - 0s 348us/step - loss: 0.2500 - accuracy: 0.9161 - val_loss: 1.1365 - val_accuracy: 0.4182\n","\n","Epoch 00041: val_accuracy did not improve from 0.58182\n","Epoch 42/1000\n","143/143 [==============================] - 0s 351us/step - loss: 0.2387 - accuracy: 0.9301 - val_loss: 1.0999 - val_accuracy: 0.4545\n","\n","Epoch 00042: val_accuracy did not improve from 0.58182\n","Epoch 43/1000\n","143/143 [==============================] - 0s 337us/step - loss: 0.2183 - accuracy: 0.9301 - val_loss: 1.1043 - val_accuracy: 0.4545\n","\n","Epoch 00043: val_accuracy did not improve from 0.58182\n","Epoch 44/1000\n","143/143 [==============================] - 0s 356us/step - loss: 0.1985 - accuracy: 0.9441 - val_loss: 1.1481 - val_accuracy: 0.4364\n","\n","Epoch 00044: val_accuracy did not improve from 0.58182\n","Epoch 45/1000\n","143/143 [==============================] - 0s 344us/step - loss: 0.2039 - accuracy: 0.9161 - val_loss: 1.1633 - val_accuracy: 0.4182\n","\n","Epoch 00045: val_accuracy did not improve from 0.58182\n","Epoch 46/1000\n","143/143 [==============================] - 0s 348us/step - loss: 0.1780 - accuracy: 0.9580 - val_loss: 1.1814 - val_accuracy: 0.4545\n","\n","Epoch 00046: val_accuracy did not improve from 0.58182\n","Epoch 47/1000\n","143/143 [==============================] - 0s 411us/step - loss: 0.1530 - accuracy: 0.9720 - val_loss: 1.2122 - val_accuracy: 0.4545\n","\n","Epoch 00047: val_accuracy did not improve from 0.58182\n","Epoch 48/1000\n","143/143 [==============================] - 0s 423us/step - loss: 0.1600 - accuracy: 0.9580 - val_loss: 1.2609 - val_accuracy: 0.4364\n","\n","Epoch 00048: val_accuracy did not improve from 0.58182\n","Epoch 49/1000\n","143/143 [==============================] - 0s 382us/step - loss: 0.1423 - accuracy: 0.9371 - val_loss: 1.2502 - val_accuracy: 0.4909\n","\n","Epoch 00049: val_accuracy did not improve from 0.58182\n","Epoch 50/1000\n","143/143 [==============================] - 0s 371us/step - loss: 0.1444 - accuracy: 0.9580 - val_loss: 1.3108 - val_accuracy: 0.4364\n","\n","Epoch 00050: val_accuracy did not improve from 0.58182\n","Epoch 51/1000\n","143/143 [==============================] - 0s 400us/step - loss: 0.1435 - accuracy: 0.9580 - val_loss: 1.3508 - val_accuracy: 0.4000\n","\n","Epoch 00051: val_accuracy did not improve from 0.58182\n","Epoch 52/1000\n","143/143 [==============================] - 0s 363us/step - loss: 0.1271 - accuracy: 0.9720 - val_loss: 1.3500 - val_accuracy: 0.4545\n","\n","Epoch 00052: val_accuracy did not improve from 0.58182\n","Epoch 53/1000\n","143/143 [==============================] - 0s 361us/step - loss: 0.1219 - accuracy: 0.9510 - val_loss: 1.4771 - val_accuracy: 0.3818\n","\n","Epoch 00053: val_accuracy did not improve from 0.58182\n","Epoch 54/1000\n","143/143 [==============================] - 0s 352us/step - loss: 0.1074 - accuracy: 0.9860 - val_loss: 1.3935 - val_accuracy: 0.4909\n","\n","Epoch 00054: val_accuracy did not improve from 0.58182\n","Epoch 55/1000\n","143/143 [==============================] - 0s 361us/step - loss: 0.1029 - accuracy: 0.9650 - val_loss: 1.4222 - val_accuracy: 0.4909\n","\n","Epoch 00055: val_accuracy did not improve from 0.58182\n","Epoch 56/1000\n","143/143 [==============================] - 0s 403us/step - loss: 0.1085 - accuracy: 0.9650 - val_loss: 1.4711 - val_accuracy: 0.4000\n","\n","Epoch 00056: val_accuracy did not improve from 0.58182\n","Epoch 57/1000\n","143/143 [==============================] - 0s 373us/step - loss: 0.0847 - accuracy: 0.9860 - val_loss: 1.4400 - val_accuracy: 0.4182\n","\n","Epoch 00057: val_accuracy did not improve from 0.58182\n","Epoch 58/1000\n","143/143 [==============================] - 0s 345us/step - loss: 0.0934 - accuracy: 0.9720 - val_loss: 1.4945 - val_accuracy: 0.4364\n","\n","Epoch 00058: val_accuracy did not improve from 0.58182\n","Epoch 59/1000\n","143/143 [==============================] - 0s 343us/step - loss: 0.0799 - accuracy: 0.9860 - val_loss: 1.4628 - val_accuracy: 0.4545\n","\n","Epoch 00059: val_accuracy did not improve from 0.58182\n","Epoch 60/1000\n","143/143 [==============================] - 0s 392us/step - loss: 0.0808 - accuracy: 0.9790 - val_loss: 1.4800 - val_accuracy: 0.4727\n","\n","Epoch 00060: val_accuracy did not improve from 0.58182\n","Epoch 61/1000\n","143/143 [==============================] - 0s 350us/step - loss: 0.0725 - accuracy: 0.9790 - val_loss: 1.5513 - val_accuracy: 0.4545\n","\n","Epoch 00061: val_accuracy did not improve from 0.58182\n","Epoch 62/1000\n","143/143 [==============================] - 0s 351us/step - loss: 0.0775 - accuracy: 0.9860 - val_loss: 1.5570 - val_accuracy: 0.4727\n","\n","Epoch 00062: val_accuracy did not improve from 0.58182\n","Epoch 63/1000\n","143/143 [==============================] - 0s 355us/step - loss: 0.0643 - accuracy: 0.9860 - val_loss: 1.5480 - val_accuracy: 0.5091\n","\n","Epoch 00063: val_accuracy did not improve from 0.58182\n","Epoch 64/1000\n","143/143 [==============================] - 0s 364us/step - loss: 0.0715 - accuracy: 0.9790 - val_loss: 1.5940 - val_accuracy: 0.4909\n","\n","Epoch 00064: val_accuracy did not improve from 0.58182\n","Epoch 65/1000\n","143/143 [==============================] - 0s 394us/step - loss: 0.0704 - accuracy: 0.9790 - val_loss: 1.5683 - val_accuracy: 0.4909\n","\n","Epoch 00065: val_accuracy did not improve from 0.58182\n","Epoch 66/1000\n","143/143 [==============================] - 0s 355us/step - loss: 0.0806 - accuracy: 0.9790 - val_loss: 1.5774 - val_accuracy: 0.4909\n","\n","Epoch 00066: val_accuracy did not improve from 0.58182\n","Epoch 67/1000\n","143/143 [==============================] - 0s 344us/step - loss: 0.0523 - accuracy: 1.0000 - val_loss: 1.6717 - val_accuracy: 0.4364\n","\n","Epoch 00067: val_accuracy did not improve from 0.58182\n","Epoch 68/1000\n","143/143 [==============================] - 0s 356us/step - loss: 0.0688 - accuracy: 0.9790 - val_loss: 1.6005 - val_accuracy: 0.4909\n","\n","Epoch 00068: val_accuracy did not improve from 0.58182\n","Epoch 69/1000\n","143/143 [==============================] - 0s 352us/step - loss: 0.0550 - accuracy: 0.9930 - val_loss: 1.6903 - val_accuracy: 0.4727\n","\n","Epoch 00069: val_accuracy did not improve from 0.58182\n","Epoch 70/1000\n","143/143 [==============================] - 0s 349us/step - loss: 0.0578 - accuracy: 0.9860 - val_loss: 1.6551 - val_accuracy: 0.4727\n","\n","Epoch 00070: val_accuracy did not improve from 0.58182\n","Epoch 71/1000\n","143/143 [==============================] - 0s 344us/step - loss: 0.0482 - accuracy: 1.0000 - val_loss: 1.6358 - val_accuracy: 0.4727\n","\n","Epoch 00071: val_accuracy did not improve from 0.58182\n","Epoch 72/1000\n","143/143 [==============================] - 0s 342us/step - loss: 0.0431 - accuracy: 0.9860 - val_loss: 1.7021 - val_accuracy: 0.4727\n","\n","Epoch 00072: val_accuracy did not improve from 0.58182\n","Epoch 73/1000\n","143/143 [==============================] - 0s 344us/step - loss: 0.0445 - accuracy: 0.9860 - val_loss: 1.7095 - val_accuracy: 0.4727\n","\n","Epoch 00073: val_accuracy did not improve from 0.58182\n","Epoch 74/1000\n","143/143 [==============================] - 0s 386us/step - loss: 0.0605 - accuracy: 0.9790 - val_loss: 1.7676 - val_accuracy: 0.4545\n","\n","Epoch 00074: val_accuracy did not improve from 0.58182\n","Epoch 75/1000\n","143/143 [==============================] - 0s 353us/step - loss: 0.0332 - accuracy: 1.0000 - val_loss: 1.7372 - val_accuracy: 0.4727\n","\n","Epoch 00075: val_accuracy did not improve from 0.58182\n","Epoch 76/1000\n","143/143 [==============================] - 0s 355us/step - loss: 0.0503 - accuracy: 0.9860 - val_loss: 1.8364 - val_accuracy: 0.4364\n","\n","Epoch 00076: val_accuracy did not improve from 0.58182\n","Epoch 77/1000\n","143/143 [==============================] - 0s 354us/step - loss: 0.0348 - accuracy: 1.0000 - val_loss: 1.9281 - val_accuracy: 0.4182\n","\n","Epoch 00077: val_accuracy did not improve from 0.58182\n","Epoch 78/1000\n","143/143 [==============================] - 0s 367us/step - loss: 0.0395 - accuracy: 0.9930 - val_loss: 1.8062 - val_accuracy: 0.4909\n","\n","Epoch 00078: val_accuracy did not improve from 0.58182\n","Epoch 79/1000\n","143/143 [==============================] - 0s 352us/step - loss: 0.0394 - accuracy: 0.9860 - val_loss: 1.8518 - val_accuracy: 0.4727\n","\n","Epoch 00079: val_accuracy did not improve from 0.58182\n","Epoch 80/1000\n","143/143 [==============================] - 0s 337us/step - loss: 0.0328 - accuracy: 0.9930 - val_loss: 1.9340 - val_accuracy: 0.4364\n","\n","Epoch 00080: val_accuracy did not improve from 0.58182\n","Epoch 81/1000\n","143/143 [==============================] - 0s 357us/step - loss: 0.0467 - accuracy: 0.9860 - val_loss: 1.8610 - val_accuracy: 0.5273\n","\n","Epoch 00081: val_accuracy did not improve from 0.58182\n","Epoch 82/1000\n","143/143 [==============================] - 0s 344us/step - loss: 0.0295 - accuracy: 1.0000 - val_loss: 1.8817 - val_accuracy: 0.5273\n","\n","Epoch 00082: val_accuracy did not improve from 0.58182\n","Epoch 83/1000\n","143/143 [==============================] - 0s 370us/step - loss: 0.0204 - accuracy: 1.0000 - val_loss: 2.0497 - val_accuracy: 0.4727\n","\n","Epoch 00083: val_accuracy did not improve from 0.58182\n","Epoch 84/1000\n","143/143 [==============================] - 0s 378us/step - loss: 0.0509 - accuracy: 0.9930 - val_loss: 1.9184 - val_accuracy: 0.5273\n","\n","Epoch 00084: val_accuracy did not improve from 0.58182\n","Epoch 85/1000\n","143/143 [==============================] - 0s 356us/step - loss: 0.0478 - accuracy: 0.9860 - val_loss: 1.9019 - val_accuracy: 0.5273\n","\n","Epoch 00085: val_accuracy did not improve from 0.58182\n","Epoch 86/1000\n","143/143 [==============================] - 0s 349us/step - loss: 0.0311 - accuracy: 1.0000 - val_loss: 2.0493 - val_accuracy: 0.4182\n","\n","Epoch 00086: val_accuracy did not improve from 0.58182\n","Epoch 87/1000\n","143/143 [==============================] - 0s 343us/step - loss: 0.0276 - accuracy: 0.9930 - val_loss: 1.9627 - val_accuracy: 0.4182\n","\n","Epoch 00087: val_accuracy did not improve from 0.58182\n","Epoch 88/1000\n","143/143 [==============================] - 0s 352us/step - loss: 0.0205 - accuracy: 1.0000 - val_loss: 1.9092 - val_accuracy: 0.4727\n","\n","Epoch 00088: val_accuracy did not improve from 0.58182\n","Epoch 89/1000\n","143/143 [==============================] - 0s 366us/step - loss: 0.0303 - accuracy: 0.9930 - val_loss: 2.0194 - val_accuracy: 0.4182\n","\n","Epoch 00089: val_accuracy did not improve from 0.58182\n","Epoch 90/1000\n","143/143 [==============================] - 0s 368us/step - loss: 0.0332 - accuracy: 0.9930 - val_loss: 2.0042 - val_accuracy: 0.4545\n","\n","Epoch 00090: val_accuracy did not improve from 0.58182\n","Epoch 91/1000\n","143/143 [==============================] - 0s 352us/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 1.9628 - val_accuracy: 0.5273\n","\n","Epoch 00091: val_accuracy did not improve from 0.58182\n","Epoch 92/1000\n","143/143 [==============================] - 0s 390us/step - loss: 0.0219 - accuracy: 1.0000 - val_loss: 2.1030 - val_accuracy: 0.4545\n","\n","Epoch 00092: val_accuracy did not improve from 0.58182\n","Epoch 93/1000\n","143/143 [==============================] - 0s 351us/step - loss: 0.0296 - accuracy: 0.9860 - val_loss: 2.1607 - val_accuracy: 0.4545\n","\n","Epoch 00093: val_accuracy did not improve from 0.58182\n","Epoch 94/1000\n","143/143 [==============================] - 0s 354us/step - loss: 0.0571 - accuracy: 0.9720 - val_loss: 2.0913 - val_accuracy: 0.5091\n","\n","Epoch 00094: val_accuracy did not improve from 0.58182\n","Epoch 95/1000\n","143/143 [==============================] - 0s 359us/step - loss: 0.0355 - accuracy: 0.9860 - val_loss: 2.2266 - val_accuracy: 0.4727\n","\n","Epoch 00095: val_accuracy did not improve from 0.58182\n","Epoch 96/1000\n","143/143 [==============================] - 0s 354us/step - loss: 0.0300 - accuracy: 1.0000 - val_loss: 2.3173 - val_accuracy: 0.4545\n","\n","Epoch 00096: val_accuracy did not improve from 0.58182\n","Epoch 97/1000\n","143/143 [==============================] - 0s 352us/step - loss: 0.0301 - accuracy: 1.0000 - val_loss: 2.1435 - val_accuracy: 0.4909\n","\n","Epoch 00097: val_accuracy did not improve from 0.58182\n","Epoch 98/1000\n","143/143 [==============================] - 0s 372us/step - loss: 0.0232 - accuracy: 1.0000 - val_loss: 2.2291 - val_accuracy: 0.4545\n","\n","Epoch 00098: val_accuracy did not improve from 0.58182\n","Epoch 99/1000\n","143/143 [==============================] - 0s 369us/step - loss: 0.0239 - accuracy: 0.9930 - val_loss: 2.3364 - val_accuracy: 0.3818\n","\n","Epoch 00099: val_accuracy did not improve from 0.58182\n","Epoch 100/1000\n","143/143 [==============================] - 0s 365us/step - loss: 0.0327 - accuracy: 0.9930 - val_loss: 2.2972 - val_accuracy: 0.3818\n","\n","Epoch 00100: val_accuracy did not improve from 0.58182\n","Epoch 101/1000\n","143/143 [==============================] - 0s 351us/step - loss: 0.0194 - accuracy: 1.0000 - val_loss: 2.2549 - val_accuracy: 0.4545\n","\n","Epoch 00101: val_accuracy did not improve from 0.58182\n","Epoch 102/1000\n","143/143 [==============================] - 0s 417us/step - loss: 0.0176 - accuracy: 1.0000 - val_loss: 2.1897 - val_accuracy: 0.4727\n","\n","Epoch 00102: val_accuracy did not improve from 0.58182\n","Epoch 103/1000\n","143/143 [==============================] - 0s 345us/step - loss: 0.0234 - accuracy: 0.9930 - val_loss: 2.1395 - val_accuracy: 0.5091\n","\n","Epoch 00103: val_accuracy did not improve from 0.58182\n","Epoch 104/1000\n","143/143 [==============================] - 0s 344us/step - loss: 0.0281 - accuracy: 0.9930 - val_loss: 2.1095 - val_accuracy: 0.5273\n","\n","Epoch 00104: val_accuracy did not improve from 0.58182\n","Epoch 105/1000\n","143/143 [==============================] - 0s 346us/step - loss: 0.0151 - accuracy: 0.9930 - val_loss: 2.2974 - val_accuracy: 0.4727\n","\n","Epoch 00105: val_accuracy did not improve from 0.58182\n","Epoch 106/1000\n","143/143 [==============================] - 0s 347us/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 2.3902 - val_accuracy: 0.3818\n","\n","Epoch 00106: val_accuracy did not improve from 0.58182\n","Epoch 107/1000\n","143/143 [==============================] - 0s 375us/step - loss: 0.0146 - accuracy: 1.0000 - val_loss: 2.2415 - val_accuracy: 0.4909\n","\n","Epoch 00107: val_accuracy did not improve from 0.58182\n","Epoch 108/1000\n","143/143 [==============================] - 0s 360us/step - loss: 0.0520 - accuracy: 0.9790 - val_loss: 2.1184 - val_accuracy: 0.5091\n","\n","Epoch 00108: val_accuracy did not improve from 0.58182\n","Epoch 109/1000\n","143/143 [==============================] - 0s 351us/step - loss: 0.0184 - accuracy: 1.0000 - val_loss: 2.3801 - val_accuracy: 0.3455\n","\n","Epoch 00109: val_accuracy did not improve from 0.58182\n","Epoch 110/1000\n","143/143 [==============================] - 0s 410us/step - loss: 0.0175 - accuracy: 1.0000 - val_loss: 2.5882 - val_accuracy: 0.3455\n","\n","Epoch 00110: val_accuracy did not improve from 0.58182\n","Epoch 111/1000\n","143/143 [==============================] - 0s 369us/step - loss: 0.0230 - accuracy: 0.9860 - val_loss: 2.1700 - val_accuracy: 0.5273\n","\n","Epoch 00111: val_accuracy did not improve from 0.58182\n","Epoch 112/1000\n","143/143 [==============================] - 0s 371us/step - loss: 0.0147 - accuracy: 1.0000 - val_loss: 2.0731 - val_accuracy: 0.5273\n","\n","Epoch 00112: val_accuracy did not improve from 0.58182\n","Epoch 113/1000\n","143/143 [==============================] - 0s 347us/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 2.2074 - val_accuracy: 0.5636\n","\n","Epoch 00113: val_accuracy did not improve from 0.58182\n","Epoch 114/1000\n","143/143 [==============================] - 0s 355us/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 2.3202 - val_accuracy: 0.4727\n","\n","Epoch 00114: val_accuracy did not improve from 0.58182\n","Epoch 115/1000\n","143/143 [==============================] - 0s 341us/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 2.1759 - val_accuracy: 0.5273\n","\n","Epoch 00115: val_accuracy did not improve from 0.58182\n","Epoch 116/1000\n","143/143 [==============================] - 0s 349us/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 2.1357 - val_accuracy: 0.5455\n","\n","Epoch 00116: val_accuracy did not improve from 0.58182\n","Epoch 117/1000\n","143/143 [==============================] - 0s 341us/step - loss: 0.0134 - accuracy: 1.0000 - val_loss: 2.2798 - val_accuracy: 0.5636\n","\n","Epoch 00117: val_accuracy did not improve from 0.58182\n","Epoch 118/1000\n","143/143 [==============================] - 0s 349us/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 2.3058 - val_accuracy: 0.5455\n","\n","Epoch 00118: val_accuracy did not improve from 0.58182\n","Epoch 119/1000\n","143/143 [==============================] - 0s 352us/step - loss: 0.0161 - accuracy: 1.0000 - val_loss: 2.2667 - val_accuracy: 0.5273\n","\n","Epoch 00119: val_accuracy did not improve from 0.58182\n","Epoch 120/1000\n","143/143 [==============================] - 0s 418us/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 2.4609 - val_accuracy: 0.4909\n","\n","Epoch 00120: val_accuracy did not improve from 0.58182\n","Epoch 121/1000\n","143/143 [==============================] - 0s 353us/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 2.6082 - val_accuracy: 0.3818\n","\n","Epoch 00121: val_accuracy did not improve from 0.58182\n","Epoch 122/1000\n","143/143 [==============================] - 0s 351us/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 2.5485 - val_accuracy: 0.4182\n","\n","Epoch 00122: val_accuracy did not improve from 0.58182\n","Epoch 123/1000\n","143/143 [==============================] - 0s 345us/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 2.3919 - val_accuracy: 0.5273\n","\n","Epoch 00123: val_accuracy did not improve from 0.58182\n","Epoch 124/1000\n","143/143 [==============================] - 0s 364us/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 2.3713 - val_accuracy: 0.5273\n","\n","Epoch 00124: val_accuracy did not improve from 0.58182\n","Epoch 125/1000\n","143/143 [==============================] - 0s 380us/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 2.5162 - val_accuracy: 0.4727\n","\n","Epoch 00125: val_accuracy did not improve from 0.58182\n","Epoch 126/1000\n","143/143 [==============================] - 0s 355us/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 2.6232 - val_accuracy: 0.4182\n","\n","Epoch 00126: val_accuracy did not improve from 0.58182\n","Epoch 127/1000\n","143/143 [==============================] - 0s 362us/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 2.4277 - val_accuracy: 0.5636\n","\n","Epoch 00127: val_accuracy did not improve from 0.58182\n","Epoch 128/1000\n","143/143 [==============================] - 0s 413us/step - loss: 0.0094 - accuracy: 1.0000 - val_loss: 2.3458 - val_accuracy: 0.5455\n","\n","Epoch 00128: val_accuracy did not improve from 0.58182\n","Epoch 129/1000\n","143/143 [==============================] - 0s 366us/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 2.3839 - val_accuracy: 0.5455\n","\n","Epoch 00129: val_accuracy did not improve from 0.58182\n","Epoch 130/1000\n","143/143 [==============================] - 0s 372us/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 2.5268 - val_accuracy: 0.5091\n","\n","Epoch 00130: val_accuracy did not improve from 0.58182\n","Epoch 131/1000\n","143/143 [==============================] - 0s 358us/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 2.4967 - val_accuracy: 0.5273\n","\n","Epoch 00131: val_accuracy did not improve from 0.58182\n","Epoch 132/1000\n","143/143 [==============================] - 0s 348us/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 2.3279 - val_accuracy: 0.5455\n","\n","Epoch 00132: val_accuracy did not improve from 0.58182\n","Epoch 133/1000\n","143/143 [==============================] - 0s 355us/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 2.3083 - val_accuracy: 0.5273\n","\n","Epoch 00133: val_accuracy did not improve from 0.58182\n","Epoch 134/1000\n","143/143 [==============================] - 0s 342us/step - loss: 0.0270 - accuracy: 0.9930 - val_loss: 2.3809 - val_accuracy: 0.5273\n","\n","Epoch 00134: val_accuracy did not improve from 0.58182\n","Epoch 135/1000\n","143/143 [==============================] - 0s 353us/step - loss: 0.0077 - accuracy: 1.0000 - val_loss: 2.4429 - val_accuracy: 0.5273\n","\n","Epoch 00135: val_accuracy did not improve from 0.58182\n","Epoch 136/1000\n","143/143 [==============================] - 0s 359us/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 2.4887 - val_accuracy: 0.4909\n","\n","Epoch 00136: val_accuracy did not improve from 0.58182\n","Epoch 137/1000\n","143/143 [==============================] - 0s 358us/step - loss: 0.0076 - accuracy: 1.0000 - val_loss: 2.4825 - val_accuracy: 0.5091\n","\n","Epoch 00137: val_accuracy did not improve from 0.58182\n","Epoch 138/1000\n","143/143 [==============================] - 0s 396us/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 2.4224 - val_accuracy: 0.5455\n","\n","Epoch 00138: val_accuracy did not improve from 0.58182\n","Epoch 139/1000\n","143/143 [==============================] - 0s 350us/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 2.4379 - val_accuracy: 0.5636\n","\n","Epoch 00139: val_accuracy did not improve from 0.58182\n","Epoch 140/1000\n","143/143 [==============================] - 0s 364us/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 2.4615 - val_accuracy: 0.5636\n","\n","Epoch 00140: val_accuracy did not improve from 0.58182\n","Epoch 141/1000\n","143/143 [==============================] - 0s 353us/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 2.5855 - val_accuracy: 0.4909\n","\n","Epoch 00141: val_accuracy did not improve from 0.58182\n","Epoch 142/1000\n","143/143 [==============================] - 0s 350us/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 2.5858 - val_accuracy: 0.5273\n","\n","Epoch 00142: val_accuracy did not improve from 0.58182\n","Epoch 143/1000\n","143/143 [==============================] - 0s 351us/step - loss: 0.0129 - accuracy: 0.9930 - val_loss: 2.4675 - val_accuracy: 0.5455\n","\n","Epoch 00143: val_accuracy did not improve from 0.58182\n","Epoch 144/1000\n","143/143 [==============================] - 0s 367us/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 2.5051 - val_accuracy: 0.5273\n","\n","Epoch 00144: val_accuracy did not improve from 0.58182\n","Epoch 145/1000\n","143/143 [==============================] - 0s 347us/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 2.6869 - val_accuracy: 0.4000\n","\n","Epoch 00145: val_accuracy did not improve from 0.58182\n","Epoch 146/1000\n","143/143 [==============================] - 0s 402us/step - loss: 0.0131 - accuracy: 0.9930 - val_loss: 2.6771 - val_accuracy: 0.4364\n","\n","Epoch 00146: val_accuracy did not improve from 0.58182\n","Epoch 147/1000\n","143/143 [==============================] - 0s 341us/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 2.5760 - val_accuracy: 0.4909\n","\n","Epoch 00147: val_accuracy did not improve from 0.58182\n","Epoch 148/1000\n","143/143 [==============================] - 0s 349us/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 2.4893 - val_accuracy: 0.5455\n","\n","Epoch 00148: val_accuracy did not improve from 0.58182\n","Epoch 149/1000\n","143/143 [==============================] - 0s 358us/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 2.4741 - val_accuracy: 0.5636\n","\n","Epoch 00149: val_accuracy did not improve from 0.58182\n","Epoch 150/1000\n","143/143 [==============================] - 0s 351us/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 2.5210 - val_accuracy: 0.5273\n","\n","Epoch 00150: val_accuracy did not improve from 0.58182\n","Epoch 151/1000\n","143/143 [==============================] - 0s 346us/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 2.5376 - val_accuracy: 0.5273\n","\n","Epoch 00151: val_accuracy did not improve from 0.58182\n","Epoch 152/1000\n","143/143 [==============================] - 0s 350us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.5483 - val_accuracy: 0.5273\n","\n","Epoch 00152: val_accuracy did not improve from 0.58182\n","Epoch 153/1000\n","143/143 [==============================] - 0s 342us/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 2.5881 - val_accuracy: 0.4909\n","\n","Epoch 00153: val_accuracy did not improve from 0.58182\n","Epoch 154/1000\n","143/143 [==============================] - 0s 374us/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 2.6304 - val_accuracy: 0.4909\n","\n","Epoch 00154: val_accuracy did not improve from 0.58182\n","Epoch 155/1000\n","143/143 [==============================] - 0s 390us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 2.6247 - val_accuracy: 0.4909\n","\n","Epoch 00155: val_accuracy did not improve from 0.58182\n","Epoch 156/1000\n","143/143 [==============================] - 0s 433us/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 2.5964 - val_accuracy: 0.5091\n","\n","Epoch 00156: val_accuracy did not improve from 0.58182\n","Epoch 157/1000\n","143/143 [==============================] - 0s 371us/step - loss: 0.0086 - accuracy: 1.0000 - val_loss: 2.5455 - val_accuracy: 0.5455\n","\n","Epoch 00157: val_accuracy did not improve from 0.58182\n","Epoch 158/1000\n","143/143 [==============================] - 0s 348us/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 2.5424 - val_accuracy: 0.5455\n","\n","Epoch 00158: val_accuracy did not improve from 0.58182\n","Epoch 159/1000\n","143/143 [==============================] - 0s 351us/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 2.6552 - val_accuracy: 0.4727\n","\n","Epoch 00159: val_accuracy did not improve from 0.58182\n","Epoch 160/1000\n","143/143 [==============================] - 0s 363us/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 2.6485 - val_accuracy: 0.4909\n","\n","Epoch 00160: val_accuracy did not improve from 0.58182\n","Epoch 161/1000\n","143/143 [==============================] - 0s 350us/step - loss: 0.0064 - accuracy: 1.0000 - val_loss: 2.5844 - val_accuracy: 0.5455\n","\n","Epoch 00161: val_accuracy did not improve from 0.58182\n","Epoch 162/1000\n","143/143 [==============================] - 0s 374us/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 2.6986 - val_accuracy: 0.4545\n","\n","Epoch 00162: val_accuracy did not improve from 0.58182\n","Epoch 163/1000\n","143/143 [==============================] - 0s 357us/step - loss: 0.0139 - accuracy: 0.9930 - val_loss: 2.6250 - val_accuracy: 0.5273\n","\n","Epoch 00163: val_accuracy did not improve from 0.58182\n","Epoch 164/1000\n","143/143 [==============================] - 0s 409us/step - loss: 0.0180 - accuracy: 0.9930 - val_loss: 2.4870 - val_accuracy: 0.5636\n","\n","Epoch 00164: val_accuracy did not improve from 0.58182\n","Epoch 165/1000\n","143/143 [==============================] - 0s 345us/step - loss: 0.0121 - accuracy: 0.9930 - val_loss: 2.8929 - val_accuracy: 0.4545\n","\n","Epoch 00165: val_accuracy did not improve from 0.58182\n","Epoch 166/1000\n","143/143 [==============================] - 0s 354us/step - loss: 0.0111 - accuracy: 1.0000 - val_loss: 2.7062 - val_accuracy: 0.5273\n","\n","Epoch 00166: val_accuracy did not improve from 0.58182\n","Epoch 167/1000\n","143/143 [==============================] - 0s 369us/step - loss: 0.0147 - accuracy: 0.9930 - val_loss: 2.5130 - val_accuracy: 0.5273\n","\n","Epoch 00167: val_accuracy did not improve from 0.58182\n","Epoch 168/1000\n","143/143 [==============================] - 0s 346us/step - loss: 0.0260 - accuracy: 0.9930 - val_loss: 2.5385 - val_accuracy: 0.5273\n","\n","Epoch 00168: val_accuracy did not improve from 0.58182\n","Epoch 169/1000\n","143/143 [==============================] - 0s 351us/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 2.8778 - val_accuracy: 0.4909\n","\n","Epoch 00169: val_accuracy did not improve from 0.58182\n","Epoch 170/1000\n","143/143 [==============================] - 0s 336us/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 3.4726 - val_accuracy: 0.3455\n","\n","Epoch 00170: val_accuracy did not improve from 0.58182\n","Epoch 171/1000\n","143/143 [==============================] - 0s 423us/step - loss: 0.0456 - accuracy: 0.9790 - val_loss: 2.9916 - val_accuracy: 0.4182\n","\n","Epoch 00171: val_accuracy did not improve from 0.58182\n","Epoch 172/1000\n","143/143 [==============================] - 0s 422us/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 2.5271 - val_accuracy: 0.5091\n","\n","Epoch 00172: val_accuracy did not improve from 0.58182\n","Epoch 173/1000\n","143/143 [==============================] - 0s 353us/step - loss: 0.0245 - accuracy: 0.9790 - val_loss: 2.6866 - val_accuracy: 0.5273\n","\n","Epoch 00173: val_accuracy did not improve from 0.58182\n","Epoch 174/1000\n","143/143 [==============================] - 0s 399us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.9278 - val_accuracy: 0.4364\n","\n","Epoch 00174: val_accuracy did not improve from 0.58182\n","Epoch 175/1000\n","143/143 [==============================] - 0s 349us/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 2.9775 - val_accuracy: 0.4000\n","\n","Epoch 00175: val_accuracy did not improve from 0.58182\n","Epoch 176/1000\n","143/143 [==============================] - 0s 391us/step - loss: 0.0160 - accuracy: 0.9860 - val_loss: 2.6950 - val_accuracy: 0.5273\n","\n","Epoch 00176: val_accuracy did not improve from 0.58182\n","Epoch 177/1000\n","143/143 [==============================] - 0s 345us/step - loss: 0.0136 - accuracy: 0.9930 - val_loss: 2.7123 - val_accuracy: 0.5273\n","\n","Epoch 00177: val_accuracy did not improve from 0.58182\n","Epoch 178/1000\n","143/143 [==============================] - 0s 355us/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 2.8352 - val_accuracy: 0.4545\n","\n","Epoch 00178: val_accuracy did not improve from 0.58182\n","Epoch 179/1000\n","143/143 [==============================] - 0s 357us/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 2.8991 - val_accuracy: 0.4364\n","\n","Epoch 00179: val_accuracy did not improve from 0.58182\n","Epoch 180/1000\n","143/143 [==============================] - 0s 337us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.8886 - val_accuracy: 0.4545\n","\n","Epoch 00180: val_accuracy did not improve from 0.58182\n","Epoch 181/1000\n","143/143 [==============================] - 0s 350us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.9063 - val_accuracy: 0.4909\n","\n","Epoch 00181: val_accuracy did not improve from 0.58182\n","Epoch 182/1000\n","143/143 [==============================] - 0s 400us/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 3.0200 - val_accuracy: 0.4545\n","\n","Epoch 00182: val_accuracy did not improve from 0.58182\n","Epoch 183/1000\n","143/143 [==============================] - 0s 357us/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 3.0435 - val_accuracy: 0.4545\n","\n","Epoch 00183: val_accuracy did not improve from 0.58182\n","Epoch 184/1000\n","143/143 [==============================] - 0s 361us/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 3.0182 - val_accuracy: 0.4545\n","\n","Epoch 00184: val_accuracy did not improve from 0.58182\n","Epoch 185/1000\n","143/143 [==============================] - 0s 363us/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 3.0378 - val_accuracy: 0.4182\n","\n","Epoch 00185: val_accuracy did not improve from 0.58182\n","Epoch 186/1000\n","143/143 [==============================] - 0s 347us/step - loss: 0.0159 - accuracy: 0.9930 - val_loss: 2.9024 - val_accuracy: 0.4727\n","\n","Epoch 00186: val_accuracy did not improve from 0.58182\n","Epoch 187/1000\n","143/143 [==============================] - 0s 353us/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 2.8041 - val_accuracy: 0.5273\n","\n","Epoch 00187: val_accuracy did not improve from 0.58182\n","Epoch 188/1000\n","143/143 [==============================] - 0s 356us/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 2.7976 - val_accuracy: 0.5455\n","\n","Epoch 00188: val_accuracy did not improve from 0.58182\n","Epoch 189/1000\n","143/143 [==============================] - 0s 367us/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 2.8303 - val_accuracy: 0.5091\n","\n","Epoch 00189: val_accuracy did not improve from 0.58182\n","Epoch 190/1000\n","143/143 [==============================] - 0s 399us/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 2.9987 - val_accuracy: 0.4727\n","\n","Epoch 00190: val_accuracy did not improve from 0.58182\n","Epoch 191/1000\n","143/143 [==============================] - 0s 362us/step - loss: 0.0122 - accuracy: 0.9930 - val_loss: 3.0162 - val_accuracy: 0.4727\n","\n","Epoch 00191: val_accuracy did not improve from 0.58182\n","Epoch 192/1000\n","143/143 [==============================] - 0s 404us/step - loss: 0.0119 - accuracy: 0.9930 - val_loss: 2.8442 - val_accuracy: 0.5091\n","\n","Epoch 00192: val_accuracy did not improve from 0.58182\n","Epoch 193/1000\n","143/143 [==============================] - 0s 345us/step - loss: 0.0114 - accuracy: 0.9930 - val_loss: 2.9010 - val_accuracy: 0.5091\n","\n","Epoch 00193: val_accuracy did not improve from 0.58182\n","Epoch 194/1000\n","143/143 [==============================] - 0s 355us/step - loss: 0.0073 - accuracy: 0.9930 - val_loss: 2.9746 - val_accuracy: 0.5091\n","\n","Epoch 00194: val_accuracy did not improve from 0.58182\n","Epoch 195/1000\n","143/143 [==============================] - 0s 354us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 3.0013 - val_accuracy: 0.4545\n","\n","Epoch 00195: val_accuracy did not improve from 0.58182\n","Epoch 196/1000\n","143/143 [==============================] - 0s 346us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 3.0052 - val_accuracy: 0.4545\n","\n","Epoch 00196: val_accuracy did not improve from 0.58182\n","Epoch 197/1000\n","143/143 [==============================] - 0s 375us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 3.0145 - val_accuracy: 0.4545\n","\n","Epoch 00197: val_accuracy did not improve from 0.58182\n","Epoch 198/1000\n","143/143 [==============================] - 0s 338us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 3.0665 - val_accuracy: 0.4364\n","\n","Epoch 00198: val_accuracy did not improve from 0.58182\n","Epoch 199/1000\n","143/143 [==============================] - 0s 352us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 3.1074 - val_accuracy: 0.4182\n","\n","Epoch 00199: val_accuracy did not improve from 0.58182\n","Epoch 200/1000\n","143/143 [==============================] - 0s 379us/step - loss: 0.0161 - accuracy: 0.9930 - val_loss: 3.1238 - val_accuracy: 0.4182\n","\n","Epoch 00200: val_accuracy did not improve from 0.58182\n","Epoch 201/1000\n","143/143 [==============================] - 0s 358us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 3.2627 - val_accuracy: 0.3455\n","\n","Epoch 00201: val_accuracy did not improve from 0.58182\n","Epoch 202/1000\n","143/143 [==============================] - 0s 363us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 3.2195 - val_accuracy: 0.3636\n","\n","Epoch 00202: val_accuracy did not improve from 0.58182\n","Epoch 203/1000\n","143/143 [==============================] - 0s 353us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 3.0839 - val_accuracy: 0.4182\n","\n","Epoch 00203: val_accuracy did not improve from 0.58182\n","Epoch 204/1000\n","143/143 [==============================] - 0s 356us/step - loss: 0.0058 - accuracy: 1.0000 - val_loss: 2.9932 - val_accuracy: 0.4545\n","\n","Epoch 00204: val_accuracy did not improve from 0.58182\n","Epoch 205/1000\n","143/143 [==============================] - 0s 344us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 3.0435 - val_accuracy: 0.4364\n","\n","Epoch 00205: val_accuracy did not improve from 0.58182\n","Epoch 206/1000\n","143/143 [==============================] - 0s 352us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 3.0582 - val_accuracy: 0.4364\n","\n","Epoch 00206: val_accuracy did not improve from 0.58182\n","Epoch 207/1000\n","143/143 [==============================] - 0s 355us/step - loss: 0.0091 - accuracy: 1.0000 - val_loss: 2.9163 - val_accuracy: 0.4909\n","\n","Epoch 00207: val_accuracy did not improve from 0.58182\n","Epoch 208/1000\n","143/143 [==============================] - 0s 351us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.9368 - val_accuracy: 0.4727\n","\n","Epoch 00208: val_accuracy did not improve from 0.58182\n","Epoch 209/1000\n","143/143 [==============================] - 0s 348us/step - loss: 0.0265 - accuracy: 0.9930 - val_loss: 2.7694 - val_accuracy: 0.5273\n","\n","Epoch 00209: val_accuracy did not improve from 0.58182\n","Epoch 210/1000\n","143/143 [==============================] - 0s 357us/step - loss: 0.0082 - accuracy: 0.9930 - val_loss: 2.7538 - val_accuracy: 0.5091\n","\n","Epoch 00210: val_accuracy did not improve from 0.58182\n","Epoch 211/1000\n","143/143 [==============================] - 0s 381us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 3.0625 - val_accuracy: 0.4182\n","\n","Epoch 00211: val_accuracy did not improve from 0.58182\n","Epoch 212/1000\n","143/143 [==============================] - 0s 347us/step - loss: 0.0219 - accuracy: 0.9860 - val_loss: 2.8912 - val_accuracy: 0.4364\n","\n","Epoch 00212: val_accuracy did not improve from 0.58182\n","Epoch 213/1000\n","143/143 [==============================] - 0s 370us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.8033 - val_accuracy: 0.5273\n","\n","Epoch 00213: val_accuracy did not improve from 0.58182\n","Epoch 214/1000\n","143/143 [==============================] - 0s 365us/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 2.8621 - val_accuracy: 0.5273\n","\n","Epoch 00214: val_accuracy did not improve from 0.58182\n","Epoch 215/1000\n","143/143 [==============================] - 0s 360us/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 3.1165 - val_accuracy: 0.4182\n","\n","Epoch 00215: val_accuracy did not improve from 0.58182\n","Epoch 216/1000\n","143/143 [==============================] - 0s 355us/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 3.2280 - val_accuracy: 0.3818\n","\n","Epoch 00216: val_accuracy did not improve from 0.58182\n","Epoch 217/1000\n","143/143 [==============================] - 0s 356us/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 2.9478 - val_accuracy: 0.4909\n","\n","Epoch 00217: val_accuracy did not improve from 0.58182\n","Epoch 218/1000\n","143/143 [==============================] - 0s 393us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.8670 - val_accuracy: 0.5273\n","\n","Epoch 00218: val_accuracy did not improve from 0.58182\n","Epoch 219/1000\n","143/143 [==============================] - 0s 383us/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 2.8867 - val_accuracy: 0.5273\n","\n","Epoch 00219: val_accuracy did not improve from 0.58182\n","Epoch 220/1000\n","143/143 [==============================] - 0s 353us/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 2.9868 - val_accuracy: 0.4727\n","\n","Epoch 00220: val_accuracy did not improve from 0.58182\n","Epoch 221/1000\n","143/143 [==============================] - 0s 350us/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 3.0322 - val_accuracy: 0.4364\n","\n","Epoch 00221: val_accuracy did not improve from 0.58182\n","Epoch 222/1000\n","143/143 [==============================] - 0s 346us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.0456 - val_accuracy: 0.4364\n","\n","Epoch 00222: val_accuracy did not improve from 0.58182\n","Epoch 223/1000\n","143/143 [==============================] - 0s 347us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 3.0069 - val_accuracy: 0.4545\n","\n","Epoch 00223: val_accuracy did not improve from 0.58182\n","Epoch 224/1000\n","143/143 [==============================] - 0s 345us/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 2.9193 - val_accuracy: 0.4727\n","\n","Epoch 00224: val_accuracy did not improve from 0.58182\n","Epoch 225/1000\n","143/143 [==============================] - 0s 353us/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 2.8737 - val_accuracy: 0.4909\n","\n","Epoch 00225: val_accuracy did not improve from 0.58182\n","Epoch 226/1000\n","143/143 [==============================] - 0s 354us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.9743 - val_accuracy: 0.4727\n","\n","Epoch 00226: val_accuracy did not improve from 0.58182\n","Epoch 227/1000\n","143/143 [==============================] - 0s 357us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 3.0802 - val_accuracy: 0.4182\n","\n","Epoch 00227: val_accuracy did not improve from 0.58182\n","Epoch 228/1000\n","143/143 [==============================] - 0s 359us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 3.0731 - val_accuracy: 0.4364\n","\n","Epoch 00228: val_accuracy did not improve from 0.58182\n","Epoch 229/1000\n","143/143 [==============================] - 0s 391us/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 2.9657 - val_accuracy: 0.4727\n","\n","Epoch 00229: val_accuracy did not improve from 0.58182\n","Epoch 230/1000\n","143/143 [==============================] - 0s 351us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.9428 - val_accuracy: 0.4909\n","\n","Epoch 00230: val_accuracy did not improve from 0.58182\n","Epoch 231/1000\n","143/143 [==============================] - 0s 342us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.9710 - val_accuracy: 0.4545\n","\n","Epoch 00231: val_accuracy did not improve from 0.58182\n","Epoch 232/1000\n","143/143 [==============================] - 0s 350us/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 2.9427 - val_accuracy: 0.4909\n","\n","Epoch 00232: val_accuracy did not improve from 0.58182\n","Epoch 233/1000\n","143/143 [==============================] - 0s 346us/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 3.0148 - val_accuracy: 0.4727\n","\n","Epoch 00233: val_accuracy did not improve from 0.58182\n","Epoch 234/1000\n","143/143 [==============================] - 0s 351us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 3.3392 - val_accuracy: 0.3818\n","\n","Epoch 00234: val_accuracy did not improve from 0.58182\n","Epoch 235/1000\n","143/143 [==============================] - 0s 355us/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 3.2380 - val_accuracy: 0.4364\n","\n","Epoch 00235: val_accuracy did not improve from 0.58182\n","Epoch 236/1000\n","143/143 [==============================] - 0s 382us/step - loss: 0.0134 - accuracy: 0.9930 - val_loss: 2.9423 - val_accuracy: 0.4727\n","\n","Epoch 00236: val_accuracy did not improve from 0.58182\n","Epoch 237/1000\n","143/143 [==============================] - 0s 367us/step - loss: 0.0132 - accuracy: 0.9930 - val_loss: 3.1114 - val_accuracy: 0.4727\n","\n","Epoch 00237: val_accuracy did not improve from 0.58182\n","Epoch 238/1000\n","143/143 [==============================] - 0s 359us/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 3.4145 - val_accuracy: 0.4545\n","\n","Epoch 00238: val_accuracy did not improve from 0.58182\n","Epoch 239/1000\n","143/143 [==============================] - 0s 346us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 3.5405 - val_accuracy: 0.4364\n","\n","Epoch 00239: val_accuracy did not improve from 0.58182\n","Epoch 240/1000\n","143/143 [==============================] - 0s 361us/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 3.4250 - val_accuracy: 0.4727\n","\n","Epoch 00240: val_accuracy did not improve from 0.58182\n","Epoch 241/1000\n","143/143 [==============================] - 0s 356us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 3.2866 - val_accuracy: 0.4364\n","\n","Epoch 00241: val_accuracy did not improve from 0.58182\n","Epoch 242/1000\n","143/143 [==============================] - 0s 344us/step - loss: 0.0096 - accuracy: 1.0000 - val_loss: 3.1363 - val_accuracy: 0.4909\n","\n","Epoch 00242: val_accuracy did not improve from 0.58182\n","Epoch 243/1000\n","143/143 [==============================] - 0s 349us/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 3.2276 - val_accuracy: 0.4727\n","\n","Epoch 00243: val_accuracy did not improve from 0.58182\n","Epoch 244/1000\n","143/143 [==============================] - 0s 352us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 3.2709 - val_accuracy: 0.4727\n","\n","Epoch 00244: val_accuracy did not improve from 0.58182\n","Epoch 245/1000\n","143/143 [==============================] - 0s 349us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 3.2887 - val_accuracy: 0.4727\n","\n","Epoch 00245: val_accuracy did not improve from 0.58182\n","Epoch 246/1000\n","143/143 [==============================] - 0s 348us/step - loss: 9.5015e-04 - accuracy: 1.0000 - val_loss: 3.2861 - val_accuracy: 0.4727\n","\n","Epoch 00246: val_accuracy did not improve from 0.58182\n","Epoch 247/1000\n","143/143 [==============================] - 0s 382us/step - loss: 0.0089 - accuracy: 0.9930 - val_loss: 3.1281 - val_accuracy: 0.5091\n","\n","Epoch 00247: val_accuracy did not improve from 0.58182\n","Epoch 248/1000\n","143/143 [==============================] - 0s 380us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 3.1530 - val_accuracy: 0.5091\n","\n","Epoch 00248: val_accuracy did not improve from 0.58182\n","Epoch 249/1000\n","143/143 [==============================] - 0s 362us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 3.1948 - val_accuracy: 0.4909\n","\n","Epoch 00249: val_accuracy did not improve from 0.58182\n","Epoch 250/1000\n","143/143 [==============================] - 0s 352us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 3.2252 - val_accuracy: 0.4909\n","\n","Epoch 00250: val_accuracy did not improve from 0.58182\n","Epoch 251/1000\n","143/143 [==============================] - 0s 337us/step - loss: 8.3635e-04 - accuracy: 1.0000 - val_loss: 3.2561 - val_accuracy: 0.4909\n","\n","Epoch 00251: val_accuracy did not improve from 0.58182\n","Epoch 252/1000\n","143/143 [==============================] - 0s 349us/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 3.2590 - val_accuracy: 0.4909\n","\n","Epoch 00252: val_accuracy did not improve from 0.58182\n","Epoch 253/1000\n","143/143 [==============================] - 0s 352us/step - loss: 0.0106 - accuracy: 0.9930 - val_loss: 3.3243 - val_accuracy: 0.4545\n","\n","Epoch 00253: val_accuracy did not improve from 0.58182\n","Epoch 254/1000\n","143/143 [==============================] - 0s 371us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 3.3098 - val_accuracy: 0.4545\n","\n","Epoch 00254: val_accuracy did not improve from 0.58182\n","Epoch 255/1000\n","143/143 [==============================] - 0s 356us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 3.2683 - val_accuracy: 0.4909\n","\n","Epoch 00255: val_accuracy did not improve from 0.58182\n","Epoch 256/1000\n","143/143 [==============================] - 0s 356us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.2529 - val_accuracy: 0.4909\n","\n","Epoch 00256: val_accuracy did not improve from 0.58182\n","Epoch 257/1000\n","143/143 [==============================] - 0s 357us/step - loss: 0.0080 - accuracy: 0.9930 - val_loss: 3.2074 - val_accuracy: 0.4909\n","\n","Epoch 00257: val_accuracy did not improve from 0.58182\n","Epoch 258/1000\n","143/143 [==============================] - 0s 367us/step - loss: 0.0141 - accuracy: 0.9930 - val_loss: 3.0535 - val_accuracy: 0.5455\n","\n","Epoch 00258: val_accuracy did not improve from 0.58182\n","Epoch 259/1000\n","143/143 [==============================] - 0s 365us/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 3.0547 - val_accuracy: 0.5273\n","\n","Epoch 00259: val_accuracy did not improve from 0.58182\n","Epoch 260/1000\n","143/143 [==============================] - 0s 355us/step - loss: 0.0148 - accuracy: 0.9930 - val_loss: 3.5306 - val_accuracy: 0.4727\n","\n","Epoch 00260: val_accuracy did not improve from 0.58182\n","Epoch 261/1000\n","143/143 [==============================] - 0s 351us/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 4.0271 - val_accuracy: 0.3636\n","\n","Epoch 00261: val_accuracy did not improve from 0.58182\n","Epoch 262/1000\n","143/143 [==============================] - 0s 420us/step - loss: 0.0278 - accuracy: 0.9860 - val_loss: 3.1060 - val_accuracy: 0.5273\n","\n","Epoch 00262: val_accuracy did not improve from 0.58182\n","Epoch 263/1000\n","143/143 [==============================] - 0s 370us/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 2.9631 - val_accuracy: 0.5273\n","\n","Epoch 00263: val_accuracy did not improve from 0.58182\n","Epoch 264/1000\n","143/143 [==============================] - 0s 360us/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 3.0204 - val_accuracy: 0.5091\n","\n","Epoch 00264: val_accuracy did not improve from 0.58182\n","Epoch 265/1000\n","143/143 [==============================] - 0s 351us/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 3.2993 - val_accuracy: 0.4727\n","\n","Epoch 00265: val_accuracy did not improve from 0.58182\n","Epoch 266/1000\n","143/143 [==============================] - 0s 387us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 3.6160 - val_accuracy: 0.4000\n","\n","Epoch 00266: val_accuracy did not improve from 0.58182\n","Epoch 267/1000\n","143/143 [==============================] - 0s 388us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 3.5975 - val_accuracy: 0.4000\n","\n","Epoch 00267: val_accuracy did not improve from 0.58182\n","Epoch 268/1000\n","143/143 [==============================] - 0s 358us/step - loss: 0.0076 - accuracy: 0.9930 - val_loss: 3.2038 - val_accuracy: 0.4909\n","\n","Epoch 00268: val_accuracy did not improve from 0.58182\n","Epoch 269/1000\n","143/143 [==============================] - 0s 371us/step - loss: 0.0126 - accuracy: 0.9930 - val_loss: 2.9574 - val_accuracy: 0.5273\n","\n","Epoch 00269: val_accuracy did not improve from 0.58182\n","Epoch 270/1000\n","143/143 [==============================] - 0s 372us/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 3.0341 - val_accuracy: 0.4909\n","\n","Epoch 00270: val_accuracy did not improve from 0.58182\n","Epoch 271/1000\n","143/143 [==============================] - 0s 365us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 3.1865 - val_accuracy: 0.4909\n","\n","Epoch 00271: val_accuracy did not improve from 0.58182\n","Epoch 272/1000\n","143/143 [==============================] - 0s 371us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 3.3306 - val_accuracy: 0.4545\n","\n","Epoch 00272: val_accuracy did not improve from 0.58182\n","Epoch 273/1000\n","143/143 [==============================] - 0s 359us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 3.4196 - val_accuracy: 0.4000\n","\n","Epoch 00273: val_accuracy did not improve from 0.58182\n","Epoch 274/1000\n","143/143 [==============================] - 0s 358us/step - loss: 7.2426e-04 - accuracy: 1.0000 - val_loss: 3.4533 - val_accuracy: 0.4000\n","\n","Epoch 00274: val_accuracy did not improve from 0.58182\n","Epoch 275/1000\n","143/143 [==============================] - 0s 340us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.3978 - val_accuracy: 0.4000\n","\n","Epoch 00275: val_accuracy did not improve from 0.58182\n","Epoch 276/1000\n","143/143 [==============================] - 0s 370us/step - loss: 0.0078 - accuracy: 0.9930 - val_loss: 3.1297 - val_accuracy: 0.5273\n","\n","Epoch 00276: val_accuracy did not improve from 0.58182\n","Epoch 277/1000\n","143/143 [==============================] - 0s 357us/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 3.2583 - val_accuracy: 0.4545\n","\n","Epoch 00277: val_accuracy did not improve from 0.58182\n","Epoch 278/1000\n","143/143 [==============================] - 0s 355us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.4120 - val_accuracy: 0.4000\n","\n","Epoch 00278: val_accuracy did not improve from 0.58182\n","Epoch 279/1000\n","143/143 [==============================] - 0s 349us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 3.2863 - val_accuracy: 0.4364\n","\n","Epoch 00279: val_accuracy did not improve from 0.58182\n","Epoch 280/1000\n","143/143 [==============================] - 0s 358us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 3.2168 - val_accuracy: 0.4545\n","\n","Epoch 00280: val_accuracy did not improve from 0.58182\n","Epoch 281/1000\n","143/143 [==============================] - 0s 346us/step - loss: 0.0121 - accuracy: 0.9930 - val_loss: 2.9336 - val_accuracy: 0.5273\n","\n","Epoch 00281: val_accuracy did not improve from 0.58182\n","Epoch 282/1000\n","143/143 [==============================] - 0s 342us/step - loss: 0.0204 - accuracy: 0.9930 - val_loss: 2.9265 - val_accuracy: 0.5818\n","\n","Epoch 00282: val_accuracy did not improve from 0.58182\n","Epoch 283/1000\n","143/143 [==============================] - 0s 351us/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 3.5193 - val_accuracy: 0.4000\n","\n","Epoch 00283: val_accuracy did not improve from 0.58182\n","Epoch 284/1000\n","143/143 [==============================] - 0s 446us/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 3.8225 - val_accuracy: 0.3818\n","\n","Epoch 00284: val_accuracy did not improve from 0.58182\n","Epoch 285/1000\n","143/143 [==============================] - 0s 356us/step - loss: 0.0114 - accuracy: 0.9930 - val_loss: 3.3391 - val_accuracy: 0.5455\n","\n","Epoch 00285: val_accuracy did not improve from 0.58182\n","Epoch 286/1000\n","143/143 [==============================] - 0s 347us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 3.2201 - val_accuracy: 0.5455\n","\n","Epoch 00286: val_accuracy did not improve from 0.58182\n","Epoch 287/1000\n","143/143 [==============================] - 0s 349us/step - loss: 0.0136 - accuracy: 0.9930 - val_loss: 3.1422 - val_accuracy: 0.5091\n","\n","Epoch 00287: val_accuracy did not improve from 0.58182\n","Epoch 288/1000\n","143/143 [==============================] - 0s 337us/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 3.1263 - val_accuracy: 0.5091\n","\n","Epoch 00288: val_accuracy did not improve from 0.58182\n","Epoch 289/1000\n","143/143 [==============================] - 0s 356us/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 3.2880 - val_accuracy: 0.5636\n","\n","Epoch 00289: val_accuracy did not improve from 0.58182\n","Epoch 290/1000\n","143/143 [==============================] - 0s 386us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 3.4743 - val_accuracy: 0.4545\n","\n","Epoch 00290: val_accuracy did not improve from 0.58182\n","Epoch 291/1000\n","143/143 [==============================] - 0s 358us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.5509 - val_accuracy: 0.4364\n","\n","Epoch 00291: val_accuracy did not improve from 0.58182\n","Epoch 292/1000\n","143/143 [==============================] - 0s 370us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 3.4846 - val_accuracy: 0.4545\n","\n","Epoch 00292: val_accuracy did not improve from 0.58182\n","Epoch 293/1000\n","143/143 [==============================] - 0s 338us/step - loss: 9.6330e-04 - accuracy: 1.0000 - val_loss: 3.3233 - val_accuracy: 0.5455\n","\n","Epoch 00293: val_accuracy did not improve from 0.58182\n","Epoch 294/1000\n","143/143 [==============================] - 0s 366us/step - loss: 0.0167 - accuracy: 0.9930 - val_loss: 3.3642 - val_accuracy: 0.5636\n","\n","Epoch 00294: val_accuracy did not improve from 0.58182\n","Epoch 295/1000\n","143/143 [==============================] - 0s 354us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 3.5120 - val_accuracy: 0.4909\n","\n","Epoch 00295: val_accuracy did not improve from 0.58182\n","Epoch 296/1000\n","143/143 [==============================] - 0s 350us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 3.5999 - val_accuracy: 0.4364\n","\n","Epoch 00296: val_accuracy did not improve from 0.58182\n","Epoch 297/1000\n","143/143 [==============================] - 0s 346us/step - loss: 0.0124 - accuracy: 0.9930 - val_loss: 3.3216 - val_accuracy: 0.5636\n","\n","Epoch 00297: val_accuracy did not improve from 0.58182\n","Epoch 298/1000\n","143/143 [==============================] - 0s 347us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 3.2163 - val_accuracy: 0.5455\n","\n","Epoch 00298: val_accuracy did not improve from 0.58182\n","Epoch 299/1000\n","143/143 [==============================] - 0s 346us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 3.2123 - val_accuracy: 0.5273\n","\n","Epoch 00299: val_accuracy did not improve from 0.58182\n","Epoch 300/1000\n","143/143 [==============================] - 0s 348us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 3.2439 - val_accuracy: 0.5455\n","\n","Epoch 00300: val_accuracy did not improve from 0.58182\n","Epoch 301/1000\n","143/143 [==============================] - 0s 350us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 3.2961 - val_accuracy: 0.5636\n","\n","Epoch 00301: val_accuracy did not improve from 0.58182\n","Epoch 302/1000\n","143/143 [==============================] - 0s 387us/step - loss: 0.0396 - accuracy: 0.9860 - val_loss: 3.2752 - val_accuracy: 0.5636\n","\n","Epoch 00302: val_accuracy did not improve from 0.58182\n","Epoch 303/1000\n","143/143 [==============================] - 0s 348us/step - loss: 0.0171 - accuracy: 0.9930 - val_loss: 3.1972 - val_accuracy: 0.5455\n","\n","Epoch 00303: val_accuracy did not improve from 0.58182\n","Epoch 304/1000\n","143/143 [==============================] - 0s 392us/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 3.0483 - val_accuracy: 0.5455\n","\n","Epoch 00304: val_accuracy did not improve from 0.58182\n","Epoch 305/1000\n","143/143 [==============================] - 0s 345us/step - loss: 0.0159 - accuracy: 0.9930 - val_loss: 3.0640 - val_accuracy: 0.5273\n","\n","Epoch 00305: val_accuracy did not improve from 0.58182\n","Epoch 306/1000\n","143/143 [==============================] - 0s 349us/step - loss: 9.3746e-04 - accuracy: 1.0000 - val_loss: 3.5063 - val_accuracy: 0.4727\n","\n","Epoch 00306: val_accuracy did not improve from 0.58182\n","Epoch 307/1000\n","143/143 [==============================] - 0s 352us/step - loss: 0.0109 - accuracy: 0.9930 - val_loss: 3.4374 - val_accuracy: 0.4909\n","\n","Epoch 00307: val_accuracy did not improve from 0.58182\n","Epoch 308/1000\n","143/143 [==============================] - 0s 351us/step - loss: 9.5305e-04 - accuracy: 1.0000 - val_loss: 3.1693 - val_accuracy: 0.5273\n","\n","Epoch 00308: val_accuracy did not improve from 0.58182\n","Epoch 309/1000\n","143/143 [==============================] - 0s 368us/step - loss: 0.0212 - accuracy: 0.9860 - val_loss: 3.3072 - val_accuracy: 0.5091\n","\n","Epoch 00309: val_accuracy did not improve from 0.58182\n","Epoch 310/1000\n","143/143 [==============================] - 0s 360us/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 4.0048 - val_accuracy: 0.4000\n","\n","Epoch 00310: val_accuracy did not improve from 0.58182\n","Epoch 311/1000\n","143/143 [==============================] - 0s 353us/step - loss: 0.0344 - accuracy: 0.9860 - val_loss: 3.5489 - val_accuracy: 0.4545\n","\n","Epoch 00311: val_accuracy did not improve from 0.58182\n","Epoch 312/1000\n","143/143 [==============================] - 0s 359us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 3.0193 - val_accuracy: 0.5091\n","\n","Epoch 00312: val_accuracy did not improve from 0.58182\n","Epoch 313/1000\n","143/143 [==============================] - 0s 405us/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 3.1897 - val_accuracy: 0.4545\n","\n","Epoch 00313: val_accuracy did not improve from 0.58182\n","Epoch 314/1000\n","143/143 [==============================] - 0s 372us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.5559 - val_accuracy: 0.5091\n","\n","Epoch 00314: val_accuracy did not improve from 0.58182\n","Epoch 315/1000\n","143/143 [==============================] - 0s 372us/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 3.6107 - val_accuracy: 0.5091\n","\n","Epoch 00315: val_accuracy did not improve from 0.58182\n","Epoch 316/1000\n","143/143 [==============================] - 0s 369us/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 3.1126 - val_accuracy: 0.4545\n","\n","Epoch 00316: val_accuracy did not improve from 0.58182\n","Epoch 317/1000\n","143/143 [==============================] - 0s 369us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.9202 - val_accuracy: 0.4727\n","\n","Epoch 00317: val_accuracy did not improve from 0.58182\n","Epoch 318/1000\n","143/143 [==============================] - 0s 349us/step - loss: 0.0158 - accuracy: 0.9930 - val_loss: 3.2654 - val_accuracy: 0.4909\n","\n","Epoch 00318: val_accuracy did not improve from 0.58182\n","Epoch 319/1000\n","143/143 [==============================] - 0s 347us/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 3.7132 - val_accuracy: 0.4727\n","\n","Epoch 00319: val_accuracy did not improve from 0.58182\n","Epoch 320/1000\n","143/143 [==============================] - 0s 392us/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 3.3103 - val_accuracy: 0.5091\n","\n","Epoch 00320: val_accuracy did not improve from 0.58182\n","Epoch 321/1000\n","143/143 [==============================] - 0s 352us/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 3.1603 - val_accuracy: 0.5091\n","\n","Epoch 00321: val_accuracy did not improve from 0.58182\n","Epoch 322/1000\n","143/143 [==============================] - 0s 353us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 3.3502 - val_accuracy: 0.4727\n","\n","Epoch 00322: val_accuracy did not improve from 0.58182\n","Epoch 323/1000\n","143/143 [==============================] - 0s 344us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 3.4502 - val_accuracy: 0.4909\n","\n","Epoch 00323: val_accuracy did not improve from 0.58182\n","Epoch 324/1000\n","143/143 [==============================] - 0s 355us/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 3.3444 - val_accuracy: 0.5091\n","\n","Epoch 00324: val_accuracy did not improve from 0.58182\n","Epoch 325/1000\n","143/143 [==============================] - 0s 342us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 3.1791 - val_accuracy: 0.4727\n","\n","Epoch 00325: val_accuracy did not improve from 0.58182\n","Epoch 326/1000\n","143/143 [==============================] - 0s 376us/step - loss: 8.5976e-04 - accuracy: 1.0000 - val_loss: 3.1315 - val_accuracy: 0.4727\n","\n","Epoch 00326: val_accuracy did not improve from 0.58182\n","Epoch 327/1000\n","143/143 [==============================] - 0s 347us/step - loss: 0.0071 - accuracy: 0.9930 - val_loss: 2.8984 - val_accuracy: 0.5455\n","\n","Epoch 00327: val_accuracy did not improve from 0.58182\n","Epoch 328/1000\n","143/143 [==============================] - 0s 342us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 2.8322 - val_accuracy: 0.5818\n","\n","Epoch 00328: val_accuracy did not improve from 0.58182\n","Epoch 329/1000\n","143/143 [==============================] - 0s 353us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.9168 - val_accuracy: 0.5818\n","\n","Epoch 00329: val_accuracy did not improve from 0.58182\n","Epoch 330/1000\n","143/143 [==============================] - 0s 343us/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 3.0815 - val_accuracy: 0.5455\n","\n","Epoch 00330: val_accuracy did not improve from 0.58182\n","Epoch 331/1000\n","143/143 [==============================] - 0s 351us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 3.3232 - val_accuracy: 0.4909\n","\n","Epoch 00331: val_accuracy did not improve from 0.58182\n","Epoch 332/1000\n","143/143 [==============================] - 0s 350us/step - loss: 8.6644e-04 - accuracy: 1.0000 - val_loss: 3.4465 - val_accuracy: 0.4727\n","\n","Epoch 00332: val_accuracy did not improve from 0.58182\n","Epoch 333/1000\n","143/143 [==============================] - 0s 353us/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 3.1578 - val_accuracy: 0.5273\n","\n","Epoch 00333: val_accuracy did not improve from 0.58182\n","Epoch 334/1000\n","143/143 [==============================] - 0s 348us/step - loss: 3.6083e-04 - accuracy: 1.0000 - val_loss: 3.0078 - val_accuracy: 0.5818\n","\n","Epoch 00334: val_accuracy did not improve from 0.58182\n","Epoch 335/1000\n","143/143 [==============================] - 0s 347us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 2.9721 - val_accuracy: 0.5818\n","\n","Epoch 00335: val_accuracy did not improve from 0.58182\n","Epoch 336/1000\n","143/143 [==============================] - 0s 342us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.9956 - val_accuracy: 0.5818\n","\n","Epoch 00336: val_accuracy did not improve from 0.58182\n","Epoch 337/1000\n","143/143 [==============================] - 0s 347us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 3.0271 - val_accuracy: 0.6000\n","\n","Epoch 00337: val_accuracy improved from 0.58182 to 0.60000, saving model to /content/drive/My Drive/saveModels/epi_eeg_conv1D_nigiria_5_80_32_1000_gazar_july_13_.hdf5\n","Epoch 338/1000\n","143/143 [==============================] - 0s 421us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 3.1223 - val_accuracy: 0.5455\n","\n","Epoch 00338: val_accuracy did not improve from 0.60000\n","Epoch 339/1000\n","143/143 [==============================] - 0s 348us/step - loss: 5.7068e-04 - accuracy: 1.0000 - val_loss: 3.2434 - val_accuracy: 0.4727\n","\n","Epoch 00339: val_accuracy did not improve from 0.60000\n","Epoch 340/1000\n","143/143 [==============================] - 0s 343us/step - loss: 6.4617e-04 - accuracy: 1.0000 - val_loss: 3.3115 - val_accuracy: 0.4727\n","\n","Epoch 00340: val_accuracy did not improve from 0.60000\n","Epoch 341/1000\n","143/143 [==============================] - 0s 351us/step - loss: 7.5130e-04 - accuracy: 1.0000 - val_loss: 3.3018 - val_accuracy: 0.4727\n","\n","Epoch 00341: val_accuracy did not improve from 0.60000\n","Epoch 342/1000\n","143/143 [==============================] - 0s 372us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 3.2003 - val_accuracy: 0.4727\n","\n","Epoch 00342: val_accuracy did not improve from 0.60000\n","Epoch 343/1000\n","143/143 [==============================] - 0s 362us/step - loss: 7.7577e-04 - accuracy: 1.0000 - val_loss: 3.0708 - val_accuracy: 0.5091\n","\n","Epoch 00343: val_accuracy did not improve from 0.60000\n","Epoch 344/1000\n","143/143 [==============================] - 0s 396us/step - loss: 9.0325e-04 - accuracy: 1.0000 - val_loss: 2.9924 - val_accuracy: 0.6182\n","\n","Epoch 00344: val_accuracy improved from 0.60000 to 0.61818, saving model to /content/drive/My Drive/saveModels/epi_eeg_conv1D_nigiria_5_80_32_1000_gazar_july_13_.hdf5\n","Epoch 345/1000\n","143/143 [==============================] - 0s 338us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.9747 - val_accuracy: 0.6182\n","\n","Epoch 00345: val_accuracy did not improve from 0.61818\n","Epoch 346/1000\n","143/143 [==============================] - 0s 345us/step - loss: 3.7390e-04 - accuracy: 1.0000 - val_loss: 2.9916 - val_accuracy: 0.6182\n","\n","Epoch 00346: val_accuracy did not improve from 0.61818\n","Epoch 347/1000\n","143/143 [==============================] - 0s 357us/step - loss: 4.7418e-04 - accuracy: 1.0000 - val_loss: 3.0179 - val_accuracy: 0.5636\n","\n","Epoch 00347: val_accuracy did not improve from 0.61818\n","Epoch 348/1000\n","143/143 [==============================] - 0s 410us/step - loss: 3.6605e-04 - accuracy: 1.0000 - val_loss: 3.0394 - val_accuracy: 0.5455\n","\n","Epoch 00348: val_accuracy did not improve from 0.61818\n","Epoch 349/1000\n","143/143 [==============================] - 0s 370us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.0199 - val_accuracy: 0.6182\n","\n","Epoch 00349: val_accuracy did not improve from 0.61818\n","Epoch 350/1000\n","143/143 [==============================] - 0s 387us/step - loss: 7.8210e-04 - accuracy: 1.0000 - val_loss: 3.0619 - val_accuracy: 0.5273\n","\n","Epoch 00350: val_accuracy did not improve from 0.61818\n","Epoch 351/1000\n","143/143 [==============================] - 0s 355us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 3.0629 - val_accuracy: 0.5455\n","\n","Epoch 00351: val_accuracy did not improve from 0.61818\n","Epoch 352/1000\n","143/143 [==============================] - 0s 357us/step - loss: 9.4637e-04 - accuracy: 1.0000 - val_loss: 3.0611 - val_accuracy: 0.5636\n","\n","Epoch 00352: val_accuracy did not improve from 0.61818\n","Epoch 353/1000\n","143/143 [==============================] - 0s 350us/step - loss: 3.6309e-04 - accuracy: 1.0000 - val_loss: 3.0458 - val_accuracy: 0.6182\n","\n","Epoch 00353: val_accuracy did not improve from 0.61818\n","Epoch 354/1000\n","143/143 [==============================] - 0s 369us/step - loss: 9.6754e-04 - accuracy: 1.0000 - val_loss: 3.0471 - val_accuracy: 0.6182\n","\n","Epoch 00354: val_accuracy did not improve from 0.61818\n","Epoch 355/1000\n","143/143 [==============================] - 0s 356us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 3.0052 - val_accuracy: 0.6182\n","\n","Epoch 00355: val_accuracy did not improve from 0.61818\n","Epoch 356/1000\n","143/143 [==============================] - 0s 347us/step - loss: 5.4816e-04 - accuracy: 1.0000 - val_loss: 2.9526 - val_accuracy: 0.5818\n","\n","Epoch 00356: val_accuracy did not improve from 0.61818\n","Epoch 357/1000\n","143/143 [==============================] - 0s 361us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.9309 - val_accuracy: 0.5818\n","\n","Epoch 00357: val_accuracy did not improve from 0.61818\n","Epoch 358/1000\n","143/143 [==============================] - 0s 356us/step - loss: 7.7214e-04 - accuracy: 1.0000 - val_loss: 2.9708 - val_accuracy: 0.6182\n","\n","Epoch 00358: val_accuracy did not improve from 0.61818\n","Epoch 359/1000\n","143/143 [==============================] - 0s 364us/step - loss: 4.8933e-04 - accuracy: 1.0000 - val_loss: 3.0191 - val_accuracy: 0.6182\n","\n","Epoch 00359: val_accuracy did not improve from 0.61818\n","Epoch 360/1000\n","143/143 [==============================] - 0s 350us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.0186 - val_accuracy: 0.6182\n","\n","Epoch 00360: val_accuracy did not improve from 0.61818\n","Epoch 361/1000\n","143/143 [==============================] - 0s 349us/step - loss: 8.8849e-04 - accuracy: 1.0000 - val_loss: 3.0507 - val_accuracy: 0.5455\n","\n","Epoch 00361: val_accuracy did not improve from 0.61818\n","Epoch 362/1000\n","143/143 [==============================] - 0s 341us/step - loss: 5.9807e-04 - accuracy: 1.0000 - val_loss: 3.1224 - val_accuracy: 0.5091\n","\n","Epoch 00362: val_accuracy did not improve from 0.61818\n","Epoch 363/1000\n","143/143 [==============================] - 0s 352us/step - loss: 8.0660e-04 - accuracy: 1.0000 - val_loss: 3.1568 - val_accuracy: 0.5091\n","\n","Epoch 00363: val_accuracy did not improve from 0.61818\n","Epoch 364/1000\n","143/143 [==============================] - 0s 351us/step - loss: 4.0911e-04 - accuracy: 1.0000 - val_loss: 3.1930 - val_accuracy: 0.5091\n","\n","Epoch 00364: val_accuracy did not improve from 0.61818\n","Epoch 365/1000\n","143/143 [==============================] - 0s 352us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.0816 - val_accuracy: 0.5091\n","\n","Epoch 00365: val_accuracy did not improve from 0.61818\n","Epoch 366/1000\n","143/143 [==============================] - 0s 346us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 3.0525 - val_accuracy: 0.5455\n","\n","Epoch 00366: val_accuracy did not improve from 0.61818\n","Epoch 367/1000\n","143/143 [==============================] - 0s 394us/step - loss: 2.7050e-04 - accuracy: 1.0000 - val_loss: 3.0795 - val_accuracy: 0.5273\n","\n","Epoch 00367: val_accuracy did not improve from 0.61818\n","Epoch 368/1000\n","143/143 [==============================] - 0s 350us/step - loss: 9.0935e-04 - accuracy: 1.0000 - val_loss: 3.0823 - val_accuracy: 0.5273\n","\n","Epoch 00368: val_accuracy did not improve from 0.61818\n","Epoch 369/1000\n","143/143 [==============================] - 0s 346us/step - loss: 4.2966e-04 - accuracy: 1.0000 - val_loss: 3.0879 - val_accuracy: 0.5273\n","\n","Epoch 00369: val_accuracy did not improve from 0.61818\n","Epoch 370/1000\n","143/143 [==============================] - 0s 350us/step - loss: 4.4240e-04 - accuracy: 1.0000 - val_loss: 3.0580 - val_accuracy: 0.5636\n","\n","Epoch 00370: val_accuracy did not improve from 0.61818\n","Epoch 371/1000\n","143/143 [==============================] - 0s 370us/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 3.0326 - val_accuracy: 0.5818\n","\n","Epoch 00371: val_accuracy did not improve from 0.61818\n","Epoch 372/1000\n","143/143 [==============================] - 0s 351us/step - loss: 9.9990e-04 - accuracy: 1.0000 - val_loss: 3.0843 - val_accuracy: 0.5818\n","\n","Epoch 00372: val_accuracy did not improve from 0.61818\n","Epoch 373/1000\n","143/143 [==============================] - 0s 394us/step - loss: 7.3001e-04 - accuracy: 1.0000 - val_loss: 3.1504 - val_accuracy: 0.5273\n","\n","Epoch 00373: val_accuracy did not improve from 0.61818\n","Epoch 374/1000\n","143/143 [==============================] - 0s 368us/step - loss: 7.6374e-04 - accuracy: 1.0000 - val_loss: 3.2413 - val_accuracy: 0.4727\n","\n","Epoch 00374: val_accuracy did not improve from 0.61818\n","Epoch 375/1000\n","143/143 [==============================] - 0s 356us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.4403 - val_accuracy: 0.4727\n","\n","Epoch 00375: val_accuracy did not improve from 0.61818\n","Epoch 376/1000\n","143/143 [==============================] - 0s 352us/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 3.4285 - val_accuracy: 0.4364\n","\n","Epoch 00376: val_accuracy did not improve from 0.61818\n","Epoch 377/1000\n","143/143 [==============================] - 0s 355us/step - loss: 5.0636e-04 - accuracy: 1.0000 - val_loss: 3.2931 - val_accuracy: 0.4727\n","\n","Epoch 00377: val_accuracy did not improve from 0.61818\n","Epoch 378/1000\n","143/143 [==============================] - 0s 354us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 3.1779 - val_accuracy: 0.5455\n","\n","Epoch 00378: val_accuracy did not improve from 0.61818\n","Epoch 379/1000\n","143/143 [==============================] - 0s 354us/step - loss: 7.6983e-04 - accuracy: 1.0000 - val_loss: 3.1245 - val_accuracy: 0.5455\n","\n","Epoch 00379: val_accuracy did not improve from 0.61818\n","Epoch 380/1000\n","143/143 [==============================] - 0s 366us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 3.1500 - val_accuracy: 0.5636\n","\n","Epoch 00380: val_accuracy did not improve from 0.61818\n","Epoch 381/1000\n","143/143 [==============================] - 0s 344us/step - loss: 6.1746e-04 - accuracy: 1.0000 - val_loss: 3.2118 - val_accuracy: 0.5091\n","\n","Epoch 00381: val_accuracy did not improve from 0.61818\n","Epoch 382/1000\n","143/143 [==============================] - 0s 372us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 3.2251 - val_accuracy: 0.5091\n","\n","Epoch 00382: val_accuracy did not improve from 0.61818\n","Epoch 383/1000\n","143/143 [==============================] - 0s 347us/step - loss: 2.9917e-04 - accuracy: 1.0000 - val_loss: 3.2209 - val_accuracy: 0.5091\n","\n","Epoch 00383: val_accuracy did not improve from 0.61818\n","Epoch 384/1000\n","143/143 [==============================] - 0s 345us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 3.2741 - val_accuracy: 0.4727\n","\n","Epoch 00384: val_accuracy did not improve from 0.61818\n","Epoch 385/1000\n","143/143 [==============================] - 0s 400us/step - loss: 3.9427e-04 - accuracy: 1.0000 - val_loss: 3.3485 - val_accuracy: 0.4727\n","\n","Epoch 00385: val_accuracy did not improve from 0.61818\n","Epoch 386/1000\n","143/143 [==============================] - 0s 354us/step - loss: 8.8634e-04 - accuracy: 1.0000 - val_loss: 3.4105 - val_accuracy: 0.4727\n","\n","Epoch 00386: val_accuracy did not improve from 0.61818\n","Epoch 387/1000\n","143/143 [==============================] - 0s 350us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 3.2832 - val_accuracy: 0.4727\n","\n","Epoch 00387: val_accuracy did not improve from 0.61818\n","Epoch 388/1000\n","143/143 [==============================] - 0s 346us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.0966 - val_accuracy: 0.5273\n","\n","Epoch 00388: val_accuracy did not improve from 0.61818\n","Epoch 389/1000\n","143/143 [==============================] - 0s 354us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 3.0647 - val_accuracy: 0.5273\n","\n","Epoch 00389: val_accuracy did not improve from 0.61818\n","Epoch 390/1000\n","143/143 [==============================] - 0s 349us/step - loss: 9.9655e-04 - accuracy: 1.0000 - val_loss: 3.1372 - val_accuracy: 0.4909\n","\n","Epoch 00390: val_accuracy did not improve from 0.61818\n","Epoch 391/1000\n","143/143 [==============================] - 0s 391us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 3.2702 - val_accuracy: 0.4545\n","\n","Epoch 00391: val_accuracy did not improve from 0.61818\n","Epoch 392/1000\n","143/143 [==============================] - 0s 353us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 3.3029 - val_accuracy: 0.4727\n","\n","Epoch 00392: val_accuracy did not improve from 0.61818\n","Epoch 393/1000\n","143/143 [==============================] - 0s 350us/step - loss: 3.6424e-04 - accuracy: 1.0000 - val_loss: 3.3290 - val_accuracy: 0.5091\n","\n","Epoch 00393: val_accuracy did not improve from 0.61818\n","Epoch 394/1000\n","143/143 [==============================] - 0s 372us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 3.3986 - val_accuracy: 0.5091\n","\n","Epoch 00394: val_accuracy did not improve from 0.61818\n","Epoch 395/1000\n","143/143 [==============================] - 0s 350us/step - loss: 8.8509e-04 - accuracy: 1.0000 - val_loss: 3.2902 - val_accuracy: 0.4727\n","\n","Epoch 00395: val_accuracy did not improve from 0.61818\n","Epoch 396/1000\n","143/143 [==============================] - 0s 357us/step - loss: 2.1721e-04 - accuracy: 1.0000 - val_loss: 3.2354 - val_accuracy: 0.4727\n","\n","Epoch 00396: val_accuracy did not improve from 0.61818\n","Epoch 397/1000\n","143/143 [==============================] - 0s 359us/step - loss: 9.6516e-04 - accuracy: 1.0000 - val_loss: 3.2284 - val_accuracy: 0.4727\n","\n","Epoch 00397: val_accuracy did not improve from 0.61818\n","Epoch 398/1000\n","143/143 [==============================] - 0s 381us/step - loss: 2.1217e-04 - accuracy: 1.0000 - val_loss: 3.2619 - val_accuracy: 0.4909\n","\n","Epoch 00398: val_accuracy did not improve from 0.61818\n","Epoch 399/1000\n","143/143 [==============================] - 0s 362us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 3.2306 - val_accuracy: 0.4909\n","\n","Epoch 00399: val_accuracy did not improve from 0.61818\n","Epoch 400/1000\n","143/143 [==============================] - 0s 358us/step - loss: 3.0099e-04 - accuracy: 1.0000 - val_loss: 3.0519 - val_accuracy: 0.5455\n","\n","Epoch 00400: val_accuracy did not improve from 0.61818\n","Epoch 401/1000\n","143/143 [==============================] - 0s 347us/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 3.1128 - val_accuracy: 0.4727\n","\n","Epoch 00401: val_accuracy did not improve from 0.61818\n","Epoch 402/1000\n","143/143 [==============================] - 0s 339us/step - loss: 6.3480e-04 - accuracy: 1.0000 - val_loss: 3.2999 - val_accuracy: 0.4727\n","\n","Epoch 00402: val_accuracy did not improve from 0.61818\n","Epoch 403/1000\n","143/143 [==============================] - 0s 372us/step - loss: 6.7599e-04 - accuracy: 1.0000 - val_loss: 3.4999 - val_accuracy: 0.5091\n","\n","Epoch 00403: val_accuracy did not improve from 0.61818\n","Epoch 404/1000\n","143/143 [==============================] - 0s 359us/step - loss: 0.0103 - accuracy: 0.9930 - val_loss: 3.2033 - val_accuracy: 0.4727\n","\n","Epoch 00404: val_accuracy did not improve from 0.61818\n","Epoch 405/1000\n","143/143 [==============================] - 0s 346us/step - loss: 7.3972e-04 - accuracy: 1.0000 - val_loss: 2.9879 - val_accuracy: 0.5636\n","\n","Epoch 00405: val_accuracy did not improve from 0.61818\n","Epoch 406/1000\n","143/143 [==============================] - 0s 344us/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 2.9817 - val_accuracy: 0.5636\n","\n","Epoch 00406: val_accuracy did not improve from 0.61818\n","Epoch 407/1000\n","143/143 [==============================] - 0s 349us/step - loss: 0.0075 - accuracy: 0.9930 - val_loss: 3.6214 - val_accuracy: 0.4545\n","\n","Epoch 00407: val_accuracy did not improve from 0.61818\n","Epoch 408/1000\n","143/143 [==============================] - 0s 352us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 4.1436 - val_accuracy: 0.4364\n","\n","Epoch 00408: val_accuracy did not improve from 0.61818\n","Epoch 409/1000\n","143/143 [==============================] - 0s 391us/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 3.8979 - val_accuracy: 0.4727\n","\n","Epoch 00409: val_accuracy did not improve from 0.61818\n","Epoch 410/1000\n","143/143 [==============================] - 0s 343us/step - loss: 4.4640e-04 - accuracy: 1.0000 - val_loss: 3.5884 - val_accuracy: 0.5091\n","\n","Epoch 00410: val_accuracy did not improve from 0.61818\n","Epoch 411/1000\n","143/143 [==============================] - 0s 364us/step - loss: 8.0758e-04 - accuracy: 1.0000 - val_loss: 3.4448 - val_accuracy: 0.5818\n","\n","Epoch 00411: val_accuracy did not improve from 0.61818\n","Epoch 412/1000\n","143/143 [==============================] - 0s 349us/step - loss: 3.8779e-04 - accuracy: 1.0000 - val_loss: 3.3985 - val_accuracy: 0.5455\n","\n","Epoch 00412: val_accuracy did not improve from 0.61818\n","Epoch 413/1000\n","143/143 [==============================] - 0s 352us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 3.4345 - val_accuracy: 0.5636\n","\n","Epoch 00413: val_accuracy did not improve from 0.61818\n","Epoch 414/1000\n","143/143 [==============================] - 0s 354us/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 3.8699 - val_accuracy: 0.5091\n","\n","Epoch 00414: val_accuracy did not improve from 0.61818\n","Epoch 415/1000\n","143/143 [==============================] - 0s 354us/step - loss: 0.0126 - accuracy: 0.9930 - val_loss: 3.7053 - val_accuracy: 0.5091\n","\n","Epoch 00415: val_accuracy did not improve from 0.61818\n","Epoch 416/1000\n","143/143 [==============================] - 0s 352us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 3.4149 - val_accuracy: 0.5273\n","\n","Epoch 00416: val_accuracy did not improve from 0.61818\n","Epoch 417/1000\n","143/143 [==============================] - 0s 346us/step - loss: 0.0117 - accuracy: 0.9930 - val_loss: 3.5920 - val_accuracy: 0.4909\n","\n","Epoch 00417: val_accuracy did not improve from 0.61818\n","Epoch 418/1000\n","143/143 [==============================] - 0s 345us/step - loss: 0.0130 - accuracy: 0.9930 - val_loss: 4.4200 - val_accuracy: 0.4182\n","\n","Epoch 00418: val_accuracy did not improve from 0.61818\n","Epoch 419/1000\n","143/143 [==============================] - 0s 352us/step - loss: 0.0169 - accuracy: 0.9930 - val_loss: 3.3107 - val_accuracy: 0.4909\n","\n","Epoch 00419: val_accuracy did not improve from 0.61818\n","Epoch 420/1000\n","143/143 [==============================] - 0s 368us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.7882 - val_accuracy: 0.5273\n","\n","Epoch 00420: val_accuracy did not improve from 0.61818\n","Epoch 421/1000\n","143/143 [==============================] - 0s 350us/step - loss: 0.0260 - accuracy: 0.9860 - val_loss: 2.7208 - val_accuracy: 0.5636\n","\n","Epoch 00421: val_accuracy did not improve from 0.61818\n","Epoch 422/1000\n","143/143 [==============================] - 0s 414us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 3.1407 - val_accuracy: 0.5091\n","\n","Epoch 00422: val_accuracy did not improve from 0.61818\n","Epoch 423/1000\n","143/143 [==============================] - 0s 357us/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 3.5556 - val_accuracy: 0.4545\n","\n","Epoch 00423: val_accuracy did not improve from 0.61818\n","Epoch 424/1000\n","143/143 [==============================] - 0s 346us/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 3.6998 - val_accuracy: 0.4545\n","\n","Epoch 00424: val_accuracy did not improve from 0.61818\n","Epoch 425/1000\n","143/143 [==============================] - 0s 345us/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 3.4476 - val_accuracy: 0.5091\n","\n","Epoch 00425: val_accuracy did not improve from 0.61818\n","Epoch 426/1000\n","143/143 [==============================] - 0s 341us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 3.2022 - val_accuracy: 0.5091\n","\n","Epoch 00426: val_accuracy did not improve from 0.61818\n","Epoch 427/1000\n","143/143 [==============================] - 0s 385us/step - loss: 5.3641e-04 - accuracy: 1.0000 - val_loss: 3.0754 - val_accuracy: 0.5273\n","\n","Epoch 00427: val_accuracy did not improve from 0.61818\n","Epoch 428/1000\n","143/143 [==============================] - 0s 353us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.1032 - val_accuracy: 0.5273\n","\n","Epoch 00428: val_accuracy did not improve from 0.61818\n","Epoch 429/1000\n","143/143 [==============================] - 0s 375us/step - loss: 2.6803e-04 - accuracy: 1.0000 - val_loss: 3.3732 - val_accuracy: 0.5273\n","\n","Epoch 00429: val_accuracy did not improve from 0.61818\n","Epoch 430/1000\n","143/143 [==============================] - 0s 367us/step - loss: 6.5085e-04 - accuracy: 1.0000 - val_loss: 3.5429 - val_accuracy: 0.4909\n","\n","Epoch 00430: val_accuracy did not improve from 0.61818\n","Epoch 431/1000\n","143/143 [==============================] - 0s 356us/step - loss: 8.6605e-04 - accuracy: 1.0000 - val_loss: 3.5994 - val_accuracy: 0.5091\n","\n","Epoch 00431: val_accuracy did not improve from 0.61818\n","Epoch 432/1000\n","143/143 [==============================] - 0s 358us/step - loss: 0.0196 - accuracy: 0.9930 - val_loss: 3.0012 - val_accuracy: 0.5273\n","\n","Epoch 00432: val_accuracy did not improve from 0.61818\n","Epoch 433/1000\n","143/143 [==============================] - 0s 374us/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 2.8675 - val_accuracy: 0.5455\n","\n","Epoch 00433: val_accuracy did not improve from 0.61818\n","Epoch 434/1000\n","143/143 [==============================] - 0s 346us/step - loss: 0.0086 - accuracy: 0.9930 - val_loss: 3.1900 - val_accuracy: 0.4909\n","\n","Epoch 00434: val_accuracy did not improve from 0.61818\n","Epoch 435/1000\n","143/143 [==============================] - 0s 348us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 3.5942 - val_accuracy: 0.5273\n","\n","Epoch 00435: val_accuracy did not improve from 0.61818\n","Epoch 436/1000\n","143/143 [==============================] - 0s 338us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 3.6839 - val_accuracy: 0.5091\n","\n","Epoch 00436: val_accuracy did not improve from 0.61818\n","Epoch 437/1000\n","143/143 [==============================] - 0s 349us/step - loss: 4.6119e-04 - accuracy: 1.0000 - val_loss: 3.5246 - val_accuracy: 0.5273\n","\n","Epoch 00437: val_accuracy did not improve from 0.61818\n","Epoch 438/1000\n","143/143 [==============================] - 0s 344us/step - loss: 3.4163e-04 - accuracy: 1.0000 - val_loss: 3.4274 - val_accuracy: 0.5273\n","\n","Epoch 00438: val_accuracy did not improve from 0.61818\n","Epoch 439/1000\n","143/143 [==============================] - 0s 364us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 3.3760 - val_accuracy: 0.5091\n","\n","Epoch 00439: val_accuracy did not improve from 0.61818\n","Epoch 440/1000\n","143/143 [==============================] - 0s 396us/step - loss: 4.3293e-04 - accuracy: 1.0000 - val_loss: 3.3253 - val_accuracy: 0.5273\n","\n","Epoch 00440: val_accuracy did not improve from 0.61818\n","Epoch 441/1000\n","143/143 [==============================] - 0s 373us/step - loss: 3.5137e-04 - accuracy: 1.0000 - val_loss: 3.2938 - val_accuracy: 0.5455\n","\n","Epoch 00441: val_accuracy did not improve from 0.61818\n","Epoch 442/1000\n","143/143 [==============================] - 0s 346us/step - loss: 1.9691e-04 - accuracy: 1.0000 - val_loss: 3.2855 - val_accuracy: 0.5455\n","\n","Epoch 00442: val_accuracy did not improve from 0.61818\n","Epoch 443/1000\n","143/143 [==============================] - 0s 337us/step - loss: 3.5177e-04 - accuracy: 1.0000 - val_loss: 3.2728 - val_accuracy: 0.5273\n","\n","Epoch 00443: val_accuracy did not improve from 0.61818\n","Epoch 444/1000\n","143/143 [==============================] - 0s 342us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 3.2608 - val_accuracy: 0.5273\n","\n","Epoch 00444: val_accuracy did not improve from 0.61818\n","Epoch 445/1000\n","143/143 [==============================] - 0s 340us/step - loss: 9.8377e-04 - accuracy: 1.0000 - val_loss: 3.2594 - val_accuracy: 0.5273\n","\n","Epoch 00445: val_accuracy did not improve from 0.61818\n","Epoch 446/1000\n","143/143 [==============================] - 0s 368us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 3.2692 - val_accuracy: 0.5455\n","\n","Epoch 00446: val_accuracy did not improve from 0.61818\n","Epoch 447/1000\n","143/143 [==============================] - 0s 354us/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 3.0994 - val_accuracy: 0.5636\n","\n","Epoch 00447: val_accuracy did not improve from 0.61818\n","Epoch 448/1000\n","143/143 [==============================] - 0s 358us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 3.0637 - val_accuracy: 0.5455\n","\n","Epoch 00448: val_accuracy did not improve from 0.61818\n","Epoch 449/1000\n","143/143 [==============================] - 0s 352us/step - loss: 9.4040e-04 - accuracy: 1.0000 - val_loss: 3.0685 - val_accuracy: 0.5636\n","\n","Epoch 00449: val_accuracy did not improve from 0.61818\n","Epoch 450/1000\n","143/143 [==============================] - 0s 348us/step - loss: 6.2457e-04 - accuracy: 1.0000 - val_loss: 3.0952 - val_accuracy: 0.5636\n","\n","Epoch 00450: val_accuracy did not improve from 0.61818\n","Epoch 451/1000\n","143/143 [==============================] - 0s 349us/step - loss: 5.7425e-04 - accuracy: 1.0000 - val_loss: 3.1980 - val_accuracy: 0.5455\n","\n","Epoch 00451: val_accuracy did not improve from 0.61818\n","Epoch 452/1000\n","143/143 [==============================] - 0s 355us/step - loss: 6.8575e-04 - accuracy: 1.0000 - val_loss: 3.2929 - val_accuracy: 0.5455\n","\n","Epoch 00452: val_accuracy did not improve from 0.61818\n","Epoch 453/1000\n","143/143 [==============================] - 0s 346us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 3.2538 - val_accuracy: 0.5455\n","\n","Epoch 00453: val_accuracy did not improve from 0.61818\n","Epoch 454/1000\n","143/143 [==============================] - 0s 353us/step - loss: 9.3668e-04 - accuracy: 1.0000 - val_loss: 3.0245 - val_accuracy: 0.5636\n","\n","Epoch 00454: val_accuracy did not improve from 0.61818\n","Epoch 455/1000\n","143/143 [==============================] - 0s 347us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 3.0091 - val_accuracy: 0.5455\n","\n","Epoch 00455: val_accuracy did not improve from 0.61818\n","Epoch 456/1000\n","143/143 [==============================] - 0s 352us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 3.2350 - val_accuracy: 0.5455\n","\n","Epoch 00456: val_accuracy did not improve from 0.61818\n","Epoch 457/1000\n","143/143 [==============================] - 0s 380us/step - loss: 4.3114e-04 - accuracy: 1.0000 - val_loss: 3.4280 - val_accuracy: 0.4909\n","\n","Epoch 00457: val_accuracy did not improve from 0.61818\n","Epoch 458/1000\n","143/143 [==============================] - 0s 345us/step - loss: 0.0087 - accuracy: 0.9930 - val_loss: 3.0762 - val_accuracy: 0.5818\n","\n","Epoch 00458: val_accuracy did not improve from 0.61818\n","Epoch 459/1000\n","143/143 [==============================] - 0s 377us/step - loss: 0.0074 - accuracy: 1.0000 - val_loss: 3.2682 - val_accuracy: 0.5091\n","\n","Epoch 00459: val_accuracy did not improve from 0.61818\n","Epoch 460/1000\n","143/143 [==============================] - 0s 351us/step - loss: 8.0309e-04 - accuracy: 1.0000 - val_loss: 3.6185 - val_accuracy: 0.4727\n","\n","Epoch 00460: val_accuracy did not improve from 0.61818\n","Epoch 461/1000\n","143/143 [==============================] - 0s 348us/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 3.6233 - val_accuracy: 0.4727\n","\n","Epoch 00461: val_accuracy did not improve from 0.61818\n","Epoch 462/1000\n","143/143 [==============================] - 0s 349us/step - loss: 6.1417e-04 - accuracy: 1.0000 - val_loss: 3.3228 - val_accuracy: 0.5636\n","\n","Epoch 00462: val_accuracy did not improve from 0.61818\n","Epoch 463/1000\n","143/143 [==============================] - 0s 352us/step - loss: 4.2329e-04 - accuracy: 1.0000 - val_loss: 3.2430 - val_accuracy: 0.5273\n","\n","Epoch 00463: val_accuracy did not improve from 0.61818\n","Epoch 464/1000\n","143/143 [==============================] - 0s 376us/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 3.4554 - val_accuracy: 0.5455\n","\n","Epoch 00464: val_accuracy did not improve from 0.61818\n","Epoch 465/1000\n","143/143 [==============================] - 0s 353us/step - loss: 1.6874e-04 - accuracy: 1.0000 - val_loss: 3.7078 - val_accuracy: 0.4909\n","\n","Epoch 00465: val_accuracy did not improve from 0.61818\n","Epoch 466/1000\n","143/143 [==============================] - 0s 353us/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 3.5883 - val_accuracy: 0.5273\n","\n","Epoch 00466: val_accuracy did not improve from 0.61818\n","Epoch 467/1000\n","143/143 [==============================] - 0s 354us/step - loss: 2.7224e-04 - accuracy: 1.0000 - val_loss: 3.4185 - val_accuracy: 0.5455\n","\n","Epoch 00467: val_accuracy did not improve from 0.61818\n","Epoch 468/1000\n","143/143 [==============================] - 0s 369us/step - loss: 3.1215e-04 - accuracy: 1.0000 - val_loss: 3.3306 - val_accuracy: 0.5273\n","\n","Epoch 00468: val_accuracy did not improve from 0.61818\n","Epoch 469/1000\n","143/143 [==============================] - 0s 345us/step - loss: 9.7349e-04 - accuracy: 1.0000 - val_loss: 3.3271 - val_accuracy: 0.5273\n","\n","Epoch 00469: val_accuracy did not improve from 0.61818\n","Epoch 470/1000\n","143/143 [==============================] - 0s 361us/step - loss: 8.2433e-04 - accuracy: 1.0000 - val_loss: 3.3666 - val_accuracy: 0.5455\n","\n","Epoch 00470: val_accuracy did not improve from 0.61818\n","Epoch 471/1000\n","143/143 [==============================] - 0s 347us/step - loss: 1.3453e-04 - accuracy: 1.0000 - val_loss: 3.4148 - val_accuracy: 0.5455\n","\n","Epoch 00471: val_accuracy did not improve from 0.61818\n","Epoch 472/1000\n","143/143 [==============================] - 0s 355us/step - loss: 6.8406e-04 - accuracy: 1.0000 - val_loss: 3.4736 - val_accuracy: 0.5273\n","\n","Epoch 00472: val_accuracy did not improve from 0.61818\n","Epoch 473/1000\n","143/143 [==============================] - 0s 349us/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 3.4605 - val_accuracy: 0.5273\n","\n","Epoch 00473: val_accuracy did not improve from 0.61818\n","Epoch 474/1000\n","143/143 [==============================] - 0s 347us/step - loss: 6.3946e-04 - accuracy: 1.0000 - val_loss: 3.4341 - val_accuracy: 0.5455\n","\n","Epoch 00474: val_accuracy did not improve from 0.61818\n","Epoch 475/1000\n","143/143 [==============================] - 0s 352us/step - loss: 3.9051e-04 - accuracy: 1.0000 - val_loss: 3.4581 - val_accuracy: 0.5273\n","\n","Epoch 00475: val_accuracy did not improve from 0.61818\n","Epoch 476/1000\n","143/143 [==============================] - 0s 352us/step - loss: 9.7343e-04 - accuracy: 1.0000 - val_loss: 3.5171 - val_accuracy: 0.5273\n","\n","Epoch 00476: val_accuracy did not improve from 0.61818\n","Epoch 477/1000\n","143/143 [==============================] - 0s 433us/step - loss: 4.2402e-04 - accuracy: 1.0000 - val_loss: 3.5933 - val_accuracy: 0.5091\n","\n","Epoch 00477: val_accuracy did not improve from 0.61818\n","Epoch 478/1000\n","143/143 [==============================] - 0s 340us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 3.5085 - val_accuracy: 0.5273\n","\n","Epoch 00478: val_accuracy did not improve from 0.61818\n","Epoch 479/1000\n","143/143 [==============================] - 0s 361us/step - loss: 8.1152e-05 - accuracy: 1.0000 - val_loss: 3.4421 - val_accuracy: 0.5091\n","\n","Epoch 00479: val_accuracy did not improve from 0.61818\n","Epoch 480/1000\n","143/143 [==============================] - 0s 348us/step - loss: 5.1470e-04 - accuracy: 1.0000 - val_loss: 3.3933 - val_accuracy: 0.5455\n","\n","Epoch 00480: val_accuracy did not improve from 0.61818\n","Epoch 481/1000\n","143/143 [==============================] - 0s 344us/step - loss: 1.6309e-04 - accuracy: 1.0000 - val_loss: 3.3749 - val_accuracy: 0.5455\n","\n","Epoch 00481: val_accuracy did not improve from 0.61818\n","Epoch 482/1000\n","143/143 [==============================] - 0s 391us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 3.3236 - val_accuracy: 0.5273\n","\n","Epoch 00482: val_accuracy did not improve from 0.61818\n","Epoch 483/1000\n","143/143 [==============================] - 0s 343us/step - loss: 6.7248e-04 - accuracy: 1.0000 - val_loss: 3.3288 - val_accuracy: 0.5455\n","\n","Epoch 00483: val_accuracy did not improve from 0.61818\n","Epoch 484/1000\n","143/143 [==============================] - 0s 357us/step - loss: 0.0048 - accuracy: 1.0000 - val_loss: 3.4514 - val_accuracy: 0.5273\n","\n","Epoch 00484: val_accuracy did not improve from 0.61818\n","Epoch 485/1000\n","143/143 [==============================] - 0s 361us/step - loss: 0.0134 - accuracy: 0.9930 - val_loss: 4.0677 - val_accuracy: 0.4545\n","\n","Epoch 00485: val_accuracy did not improve from 0.61818\n","Epoch 486/1000\n","143/143 [==============================] - 0s 412us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.2788 - val_accuracy: 0.4909\n","\n","Epoch 00486: val_accuracy did not improve from 0.61818\n","Epoch 487/1000\n","143/143 [==============================] - 0s 361us/step - loss: 7.7723e-04 - accuracy: 1.0000 - val_loss: 3.0310 - val_accuracy: 0.5636\n","\n","Epoch 00487: val_accuracy did not improve from 0.61818\n","Epoch 488/1000\n","143/143 [==============================] - 0s 348us/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 3.3202 - val_accuracy: 0.4909\n","\n","Epoch 00488: val_accuracy did not improve from 0.61818\n","Epoch 489/1000\n","143/143 [==============================] - 0s 344us/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 3.8819 - val_accuracy: 0.4545\n","\n","Epoch 00489: val_accuracy did not improve from 0.61818\n","Epoch 490/1000\n","143/143 [==============================] - 0s 369us/step - loss: 6.8405e-04 - accuracy: 1.0000 - val_loss: 4.1471 - val_accuracy: 0.4545\n","\n","Epoch 00490: val_accuracy did not improve from 0.61818\n","Epoch 491/1000\n","143/143 [==============================] - 0s 356us/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 3.8803 - val_accuracy: 0.4727\n","\n","Epoch 00491: val_accuracy did not improve from 0.61818\n","Epoch 492/1000\n","143/143 [==============================] - 0s 347us/step - loss: 7.4636e-04 - accuracy: 1.0000 - val_loss: 3.5572 - val_accuracy: 0.4727\n","\n","Epoch 00492: val_accuracy did not improve from 0.61818\n","Epoch 493/1000\n","143/143 [==============================] - 0s 350us/step - loss: 4.0769e-04 - accuracy: 1.0000 - val_loss: 3.4209 - val_accuracy: 0.4727\n","\n","Epoch 00493: val_accuracy did not improve from 0.61818\n","Epoch 494/1000\n","143/143 [==============================] - 0s 353us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 3.4394 - val_accuracy: 0.4727\n","\n","Epoch 00494: val_accuracy did not improve from 0.61818\n","Epoch 495/1000\n","143/143 [==============================] - 0s 417us/step - loss: 3.8127e-04 - accuracy: 1.0000 - val_loss: 3.5028 - val_accuracy: 0.4727\n","\n","Epoch 00495: val_accuracy did not improve from 0.61818\n","Epoch 496/1000\n","143/143 [==============================] - 0s 363us/step - loss: 7.4027e-04 - accuracy: 1.0000 - val_loss: 3.5387 - val_accuracy: 0.4727\n","\n","Epoch 00496: val_accuracy did not improve from 0.61818\n","Epoch 497/1000\n","143/143 [==============================] - 0s 340us/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 3.7338 - val_accuracy: 0.4727\n","\n","Epoch 00497: val_accuracy did not improve from 0.61818\n","Epoch 498/1000\n","143/143 [==============================] - 0s 351us/step - loss: 2.5940e-04 - accuracy: 1.0000 - val_loss: 3.9219 - val_accuracy: 0.4727\n","\n","Epoch 00498: val_accuracy did not improve from 0.61818\n","Epoch 499/1000\n","143/143 [==============================] - 0s 344us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.8252 - val_accuracy: 0.4545\n","\n","Epoch 00499: val_accuracy did not improve from 0.61818\n","Epoch 500/1000\n","143/143 [==============================] - 0s 394us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.6256 - val_accuracy: 0.4909\n","\n","Epoch 00500: val_accuracy did not improve from 0.61818\n","Epoch 501/1000\n","143/143 [==============================] - 0s 335us/step - loss: 8.2036e-04 - accuracy: 1.0000 - val_loss: 3.4467 - val_accuracy: 0.5091\n","\n","Epoch 00501: val_accuracy did not improve from 0.61818\n","Epoch 502/1000\n","143/143 [==============================] - 0s 341us/step - loss: 8.4514e-04 - accuracy: 1.0000 - val_loss: 3.3970 - val_accuracy: 0.5091\n","\n","Epoch 00502: val_accuracy did not improve from 0.61818\n","Epoch 503/1000\n","143/143 [==============================] - 0s 338us/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 3.6025 - val_accuracy: 0.4727\n","\n","Epoch 00503: val_accuracy did not improve from 0.61818\n","Epoch 504/1000\n","143/143 [==============================] - 0s 335us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 3.9131 - val_accuracy: 0.4545\n","\n","Epoch 00504: val_accuracy did not improve from 0.61818\n","Epoch 505/1000\n","143/143 [==============================] - 0s 354us/step - loss: 1.0654e-04 - accuracy: 1.0000 - val_loss: 4.0764 - val_accuracy: 0.4545\n","\n","Epoch 00505: val_accuracy did not improve from 0.61818\n","Epoch 506/1000\n","143/143 [==============================] - 0s 353us/step - loss: 0.0317 - accuracy: 0.9930 - val_loss: 3.3935 - val_accuracy: 0.5091\n","\n","Epoch 00506: val_accuracy did not improve from 0.61818\n","Epoch 507/1000\n","143/143 [==============================] - 0s 339us/step - loss: 0.0331 - accuracy: 0.9860 - val_loss: 3.5154 - val_accuracy: 0.5091\n","\n","Epoch 00507: val_accuracy did not improve from 0.61818\n","Epoch 508/1000\n","143/143 [==============================] - 0s 345us/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 5.2237 - val_accuracy: 0.3818\n","\n","Epoch 00508: val_accuracy did not improve from 0.61818\n","Epoch 509/1000\n","143/143 [==============================] - 0s 336us/step - loss: 0.0810 - accuracy: 0.9860 - val_loss: 3.4748 - val_accuracy: 0.5091\n","\n","Epoch 00509: val_accuracy did not improve from 0.61818\n","Epoch 510/1000\n","143/143 [==============================] - 0s 343us/step - loss: 0.0108 - accuracy: 0.9930 - val_loss: 3.1701 - val_accuracy: 0.6000\n","\n","Epoch 00510: val_accuracy did not improve from 0.61818\n","Epoch 511/1000\n","143/143 [==============================] - 0s 340us/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 3.6640 - val_accuracy: 0.4545\n","\n","Epoch 00511: val_accuracy did not improve from 0.61818\n","Epoch 512/1000\n","143/143 [==============================] - 0s 338us/step - loss: 0.0119 - accuracy: 0.9930 - val_loss: 3.8995 - val_accuracy: 0.4545\n","\n","Epoch 00512: val_accuracy did not improve from 0.61818\n","Epoch 513/1000\n","143/143 [==============================] - 0s 337us/step - loss: 0.0406 - accuracy: 0.9930 - val_loss: 3.5002 - val_accuracy: 0.5091\n","\n","Epoch 00513: val_accuracy did not improve from 0.61818\n","Epoch 514/1000\n","143/143 [==============================] - 0s 400us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 3.3653 - val_accuracy: 0.5273\n","\n","Epoch 00514: val_accuracy did not improve from 0.61818\n","Epoch 515/1000\n","143/143 [==============================] - 0s 382us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.3809 - val_accuracy: 0.5273\n","\n","Epoch 00515: val_accuracy did not improve from 0.61818\n","Epoch 516/1000\n","143/143 [==============================] - 0s 342us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 3.5654 - val_accuracy: 0.4727\n","\n","Epoch 00516: val_accuracy did not improve from 0.61818\n","Epoch 517/1000\n","143/143 [==============================] - 0s 340us/step - loss: 5.2937e-04 - accuracy: 1.0000 - val_loss: 3.7845 - val_accuracy: 0.4364\n","\n","Epoch 00517: val_accuracy did not improve from 0.61818\n","Epoch 518/1000\n","143/143 [==============================] - 0s 332us/step - loss: 1.2597e-04 - accuracy: 1.0000 - val_loss: 3.9792 - val_accuracy: 0.4364\n","\n","Epoch 00518: val_accuracy did not improve from 0.61818\n","Epoch 519/1000\n","143/143 [==============================] - 0s 374us/step - loss: 2.2007e-04 - accuracy: 1.0000 - val_loss: 4.0933 - val_accuracy: 0.4364\n","\n","Epoch 00519: val_accuracy did not improve from 0.61818\n","Epoch 520/1000\n","143/143 [==============================] - 0s 344us/step - loss: 5.0147e-04 - accuracy: 1.0000 - val_loss: 4.1255 - val_accuracy: 0.4364\n","\n","Epoch 00520: val_accuracy did not improve from 0.61818\n","Epoch 521/1000\n","143/143 [==============================] - 0s 356us/step - loss: 3.7045e-04 - accuracy: 1.0000 - val_loss: 4.1327 - val_accuracy: 0.4364\n","\n","Epoch 00521: val_accuracy did not improve from 0.61818\n","Epoch 522/1000\n","143/143 [==============================] - 0s 342us/step - loss: 0.0112 - accuracy: 0.9930 - val_loss: 3.4128 - val_accuracy: 0.5091\n","\n","Epoch 00522: val_accuracy did not improve from 0.61818\n","Epoch 523/1000\n","143/143 [==============================] - 0s 378us/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 3.2239 - val_accuracy: 0.5273\n","\n","Epoch 00523: val_accuracy did not improve from 0.61818\n","Epoch 524/1000\n","143/143 [==============================] - 0s 346us/step - loss: 0.0100 - accuracy: 0.9930 - val_loss: 3.3480 - val_accuracy: 0.5091\n","\n","Epoch 00524: val_accuracy did not improve from 0.61818\n","Epoch 525/1000\n","143/143 [==============================] - 0s 369us/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 3.9203 - val_accuracy: 0.4545\n","\n","Epoch 00525: val_accuracy did not improve from 0.61818\n","Epoch 526/1000\n","143/143 [==============================] - 0s 366us/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 3.9768 - val_accuracy: 0.4545\n","\n","Epoch 00526: val_accuracy did not improve from 0.61818\n","Epoch 527/1000\n","143/143 [==============================] - 0s 374us/step - loss: 3.8355e-04 - accuracy: 1.0000 - val_loss: 3.9218 - val_accuracy: 0.4545\n","\n","Epoch 00527: val_accuracy did not improve from 0.61818\n","Epoch 528/1000\n","143/143 [==============================] - 0s 374us/step - loss: 0.0105 - accuracy: 0.9930 - val_loss: 3.3845 - val_accuracy: 0.5091\n","\n","Epoch 00528: val_accuracy did not improve from 0.61818\n","Epoch 529/1000\n","143/143 [==============================] - 0s 376us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 3.2938 - val_accuracy: 0.5455\n","\n","Epoch 00529: val_accuracy did not improve from 0.61818\n","Epoch 530/1000\n","143/143 [==============================] - 0s 360us/step - loss: 0.0082 - accuracy: 0.9930 - val_loss: 3.5500 - val_accuracy: 0.5091\n","\n","Epoch 00530: val_accuracy did not improve from 0.61818\n","Epoch 531/1000\n","143/143 [==============================] - 0s 352us/step - loss: 1.9889e-04 - accuracy: 1.0000 - val_loss: 3.8339 - val_accuracy: 0.4545\n","\n","Epoch 00531: val_accuracy did not improve from 0.61818\n","Epoch 532/1000\n","143/143 [==============================] - 0s 391us/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 3.8144 - val_accuracy: 0.4727\n","\n","Epoch 00532: val_accuracy did not improve from 0.61818\n","Epoch 533/1000\n","143/143 [==============================] - 0s 370us/step - loss: 1.6504e-04 - accuracy: 1.0000 - val_loss: 3.5313 - val_accuracy: 0.5273\n","\n","Epoch 00533: val_accuracy did not improve from 0.61818\n","Epoch 534/1000\n","143/143 [==============================] - 0s 341us/step - loss: 5.3534e-04 - accuracy: 1.0000 - val_loss: 3.4409 - val_accuracy: 0.5273\n","\n","Epoch 00534: val_accuracy did not improve from 0.61818\n","Epoch 535/1000\n","143/143 [==============================] - 0s 387us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.4451 - val_accuracy: 0.5273\n","\n","Epoch 00535: val_accuracy did not improve from 0.61818\n","Epoch 536/1000\n","143/143 [==============================] - 0s 343us/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 3.6738 - val_accuracy: 0.5091\n","\n","Epoch 00536: val_accuracy did not improve from 0.61818\n","Epoch 537/1000\n","143/143 [==============================] - 0s 376us/step - loss: 0.0484 - accuracy: 0.9930 - val_loss: 3.5170 - val_accuracy: 0.5273\n","\n","Epoch 00537: val_accuracy did not improve from 0.61818\n","Epoch 538/1000\n","143/143 [==============================] - 0s 358us/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 3.3488 - val_accuracy: 0.5273\n","\n","Epoch 00538: val_accuracy did not improve from 0.61818\n","Epoch 539/1000\n","143/143 [==============================] - 0s 402us/step - loss: 4.5609e-04 - accuracy: 1.0000 - val_loss: 3.2579 - val_accuracy: 0.5455\n","\n","Epoch 00539: val_accuracy did not improve from 0.61818\n","Epoch 540/1000\n","143/143 [==============================] - 0s 354us/step - loss: 1.6996e-04 - accuracy: 1.0000 - val_loss: 3.2152 - val_accuracy: 0.5455\n","\n","Epoch 00540: val_accuracy did not improve from 0.61818\n","Epoch 541/1000\n","143/143 [==============================] - 0s 344us/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 3.2153 - val_accuracy: 0.5455\n","\n","Epoch 00541: val_accuracy did not improve from 0.61818\n","Epoch 542/1000\n","143/143 [==============================] - 0s 350us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 3.2037 - val_accuracy: 0.5455\n","\n","Epoch 00542: val_accuracy did not improve from 0.61818\n","Epoch 543/1000\n","143/143 [==============================] - 0s 359us/step - loss: 4.6181e-04 - accuracy: 1.0000 - val_loss: 3.2195 - val_accuracy: 0.5273\n","\n","Epoch 00543: val_accuracy did not improve from 0.61818\n","Epoch 544/1000\n","143/143 [==============================] - 0s 356us/step - loss: 5.5449e-04 - accuracy: 1.0000 - val_loss: 3.2440 - val_accuracy: 0.5091\n","\n","Epoch 00544: val_accuracy did not improve from 0.61818\n","Epoch 545/1000\n","143/143 [==============================] - 0s 375us/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 3.3574 - val_accuracy: 0.4727\n","\n","Epoch 00545: val_accuracy did not improve from 0.61818\n","Epoch 546/1000\n","143/143 [==============================] - 0s 358us/step - loss: 1.1139e-04 - accuracy: 1.0000 - val_loss: 3.5422 - val_accuracy: 0.4545\n","\n","Epoch 00546: val_accuracy did not improve from 0.61818\n","Epoch 547/1000\n","143/143 [==============================] - 0s 354us/step - loss: 2.9113e-04 - accuracy: 1.0000 - val_loss: 3.6538 - val_accuracy: 0.4545\n","\n","Epoch 00547: val_accuracy did not improve from 0.61818\n","Epoch 548/1000\n","143/143 [==============================] - 0s 342us/step - loss: 9.4083e-04 - accuracy: 1.0000 - val_loss: 3.6443 - val_accuracy: 0.4727\n","\n","Epoch 00548: val_accuracy did not improve from 0.61818\n","Epoch 549/1000\n","143/143 [==============================] - 0s 368us/step - loss: 4.6589e-04 - accuracy: 1.0000 - val_loss: 3.6092 - val_accuracy: 0.4545\n","\n","Epoch 00549: val_accuracy did not improve from 0.61818\n","Epoch 550/1000\n","143/143 [==============================] - 0s 375us/step - loss: 0.0201 - accuracy: 0.9930 - val_loss: 3.2034 - val_accuracy: 0.5636\n","\n","Epoch 00550: val_accuracy did not improve from 0.61818\n","Epoch 551/1000\n","143/143 [==============================] - 0s 379us/step - loss: 0.0112 - accuracy: 0.9930 - val_loss: 3.2479 - val_accuracy: 0.5273\n","\n","Epoch 00551: val_accuracy did not improve from 0.61818\n","Epoch 552/1000\n","143/143 [==============================] - 0s 353us/step - loss: 8.5159e-04 - accuracy: 1.0000 - val_loss: 3.4950 - val_accuracy: 0.4909\n","\n","Epoch 00552: val_accuracy did not improve from 0.61818\n","Epoch 553/1000\n","143/143 [==============================] - 0s 345us/step - loss: 2.1957e-04 - accuracy: 1.0000 - val_loss: 3.6610 - val_accuracy: 0.4545\n","\n","Epoch 00553: val_accuracy did not improve from 0.61818\n","Epoch 554/1000\n","143/143 [==============================] - 0s 352us/step - loss: 2.2888e-04 - accuracy: 1.0000 - val_loss: 3.7508 - val_accuracy: 0.4545\n","\n","Epoch 00554: val_accuracy did not improve from 0.61818\n","Epoch 555/1000\n","143/143 [==============================] - 0s 391us/step - loss: 0.0115 - accuracy: 0.9930 - val_loss: 3.4895 - val_accuracy: 0.5455\n","\n","Epoch 00555: val_accuracy did not improve from 0.61818\n","Epoch 556/1000\n","143/143 [==============================] - 0s 351us/step - loss: 7.3009e-04 - accuracy: 1.0000 - val_loss: 3.3446 - val_accuracy: 0.5273\n","\n","Epoch 00556: val_accuracy did not improve from 0.61818\n","Epoch 557/1000\n","143/143 [==============================] - 0s 346us/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 3.4029 - val_accuracy: 0.5273\n","\n","Epoch 00557: val_accuracy did not improve from 0.61818\n","Epoch 558/1000\n","143/143 [==============================] - 0s 368us/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 4.1017 - val_accuracy: 0.4545\n","\n","Epoch 00558: val_accuracy did not improve from 0.61818\n","Epoch 559/1000\n","143/143 [==============================] - 0s 369us/step - loss: 0.0070 - accuracy: 0.9930 - val_loss: 4.4956 - val_accuracy: 0.4182\n","\n","Epoch 00559: val_accuracy did not improve from 0.61818\n","Epoch 560/1000\n","143/143 [==============================] - 0s 369us/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 3.8063 - val_accuracy: 0.5455\n","\n","Epoch 00560: val_accuracy did not improve from 0.61818\n","Epoch 561/1000\n","143/143 [==============================] - 0s 368us/step - loss: 6.9725e-04 - accuracy: 1.0000 - val_loss: 3.6614 - val_accuracy: 0.5636\n","\n","Epoch 00561: val_accuracy did not improve from 0.61818\n","Epoch 562/1000\n","143/143 [==============================] - 0s 352us/step - loss: 9.9436e-04 - accuracy: 1.0000 - val_loss: 3.6706 - val_accuracy: 0.5636\n","\n","Epoch 00562: val_accuracy did not improve from 0.61818\n","Epoch 563/1000\n","143/143 [==============================] - 0s 352us/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 3.6722 - val_accuracy: 0.5636\n","\n","Epoch 00563: val_accuracy did not improve from 0.61818\n","Epoch 564/1000\n","143/143 [==============================] - 0s 356us/step - loss: 0.0072 - accuracy: 0.9930 - val_loss: 3.7187 - val_accuracy: 0.5636\n","\n","Epoch 00564: val_accuracy did not improve from 0.61818\n","Epoch 565/1000\n","143/143 [==============================] - 0s 363us/step - loss: 2.3674e-04 - accuracy: 1.0000 - val_loss: 3.8681 - val_accuracy: 0.5273\n","\n","Epoch 00565: val_accuracy did not improve from 0.61818\n","Epoch 566/1000\n","143/143 [==============================] - 0s 345us/step - loss: 5.7203e-04 - accuracy: 1.0000 - val_loss: 4.0056 - val_accuracy: 0.5455\n","\n","Epoch 00566: val_accuracy did not improve from 0.61818\n","Epoch 567/1000\n","143/143 [==============================] - 0s 353us/step - loss: 3.7151e-04 - accuracy: 1.0000 - val_loss: 4.0774 - val_accuracy: 0.5455\n","\n","Epoch 00567: val_accuracy did not improve from 0.61818\n","Epoch 568/1000\n","143/143 [==============================] - 0s 357us/step - loss: 1.7156e-04 - accuracy: 1.0000 - val_loss: 4.1131 - val_accuracy: 0.5455\n","\n","Epoch 00568: val_accuracy did not improve from 0.61818\n","Epoch 569/1000\n","143/143 [==============================] - 0s 389us/step - loss: 2.3253e-04 - accuracy: 1.0000 - val_loss: 4.1246 - val_accuracy: 0.5455\n","\n","Epoch 00569: val_accuracy did not improve from 0.61818\n","Epoch 570/1000\n","143/143 [==============================] - 0s 346us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 4.0428 - val_accuracy: 0.5455\n","\n","Epoch 00570: val_accuracy did not improve from 0.61818\n","Epoch 571/1000\n","143/143 [==============================] - 0s 351us/step - loss: 0.0104 - accuracy: 0.9930 - val_loss: 3.8160 - val_accuracy: 0.5455\n","\n","Epoch 00571: val_accuracy did not improve from 0.61818\n","Epoch 572/1000\n","143/143 [==============================] - 0s 338us/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 3.7127 - val_accuracy: 0.5455\n","\n","Epoch 00572: val_accuracy did not improve from 0.61818\n","Epoch 573/1000\n","143/143 [==============================] - 0s 386us/step - loss: 4.7241e-04 - accuracy: 1.0000 - val_loss: 3.8943 - val_accuracy: 0.5455\n","\n","Epoch 00573: val_accuracy did not improve from 0.61818\n","Epoch 574/1000\n","143/143 [==============================] - 0s 351us/step - loss: 2.6489e-04 - accuracy: 1.0000 - val_loss: 4.1191 - val_accuracy: 0.4727\n","\n","Epoch 00574: val_accuracy did not improve from 0.61818\n","Epoch 575/1000\n","143/143 [==============================] - 0s 343us/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 4.0748 - val_accuracy: 0.4727\n","\n","Epoch 00575: val_accuracy did not improve from 0.61818\n","Epoch 576/1000\n","143/143 [==============================] - 0s 363us/step - loss: 1.9646e-04 - accuracy: 1.0000 - val_loss: 3.5808 - val_accuracy: 0.5636\n","\n","Epoch 00576: val_accuracy did not improve from 0.61818\n","Epoch 577/1000\n","143/143 [==============================] - 0s 344us/step - loss: 1.5102e-04 - accuracy: 1.0000 - val_loss: 3.3829 - val_accuracy: 0.5636\n","\n","Epoch 00577: val_accuracy did not improve from 0.61818\n","Epoch 578/1000\n","143/143 [==============================] - 0s 346us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 3.3030 - val_accuracy: 0.5636\n","\n","Epoch 00578: val_accuracy did not improve from 0.61818\n","Epoch 579/1000\n","143/143 [==============================] - 0s 374us/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 3.3104 - val_accuracy: 0.5636\n","\n","Epoch 00579: val_accuracy did not improve from 0.61818\n","Epoch 580/1000\n","143/143 [==============================] - 0s 356us/step - loss: 5.6443e-04 - accuracy: 1.0000 - val_loss: 3.3698 - val_accuracy: 0.5636\n","\n","Epoch 00580: val_accuracy did not improve from 0.61818\n","Epoch 581/1000\n","143/143 [==============================] - 0s 347us/step - loss: 6.2771e-04 - accuracy: 1.0000 - val_loss: 3.4339 - val_accuracy: 0.5455\n","\n","Epoch 00581: val_accuracy did not improve from 0.61818\n","Epoch 582/1000\n","143/143 [==============================] - 0s 346us/step - loss: 3.2731e-04 - accuracy: 1.0000 - val_loss: 3.4862 - val_accuracy: 0.5091\n","\n","Epoch 00582: val_accuracy did not improve from 0.61818\n","Epoch 583/1000\n","143/143 [==============================] - 0s 346us/step - loss: 5.3316e-04 - accuracy: 1.0000 - val_loss: 3.5431 - val_accuracy: 0.5091\n","\n","Epoch 00583: val_accuracy did not improve from 0.61818\n","Epoch 584/1000\n","143/143 [==============================] - 0s 342us/step - loss: 0.0155 - accuracy: 0.9930 - val_loss: 3.6701 - val_accuracy: 0.4909\n","\n","Epoch 00584: val_accuracy did not improve from 0.61818\n","Epoch 585/1000\n","143/143 [==============================] - 0s 346us/step - loss: 3.0713e-04 - accuracy: 1.0000 - val_loss: 3.8176 - val_accuracy: 0.4727\n","\n","Epoch 00585: val_accuracy did not improve from 0.61818\n","Epoch 586/1000\n","143/143 [==============================] - 0s 346us/step - loss: 4.0108e-04 - accuracy: 1.0000 - val_loss: 3.8808 - val_accuracy: 0.4727\n","\n","Epoch 00586: val_accuracy did not improve from 0.61818\n","Epoch 587/1000\n","143/143 [==============================] - 0s 394us/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 3.4384 - val_accuracy: 0.5455\n","\n","Epoch 00587: val_accuracy did not improve from 0.61818\n","Epoch 588/1000\n","143/143 [==============================] - 0s 348us/step - loss: 4.5264e-04 - accuracy: 1.0000 - val_loss: 3.2505 - val_accuracy: 0.5818\n","\n","Epoch 00588: val_accuracy did not improve from 0.61818\n","Epoch 589/1000\n","143/143 [==============================] - 0s 350us/step - loss: 0.0190 - accuracy: 0.9930 - val_loss: 3.5362 - val_accuracy: 0.4909\n","\n","Epoch 00589: val_accuracy did not improve from 0.61818\n","Epoch 590/1000\n","143/143 [==============================] - 0s 338us/step - loss: 3.7376e-04 - accuracy: 1.0000 - val_loss: 3.8840 - val_accuracy: 0.4364\n","\n","Epoch 00590: val_accuracy did not improve from 0.61818\n","Epoch 591/1000\n","143/143 [==============================] - 0s 396us/step - loss: 4.9970e-04 - accuracy: 1.0000 - val_loss: 4.0545 - val_accuracy: 0.4364\n","\n","Epoch 00591: val_accuracy did not improve from 0.61818\n","Epoch 592/1000\n","143/143 [==============================] - 0s 372us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 3.7619 - val_accuracy: 0.4545\n","\n","Epoch 00592: val_accuracy did not improve from 0.61818\n","Epoch 593/1000\n","143/143 [==============================] - 0s 381us/step - loss: 1.4804e-04 - accuracy: 1.0000 - val_loss: 3.4864 - val_accuracy: 0.5636\n","\n","Epoch 00593: val_accuracy did not improve from 0.61818\n","Epoch 594/1000\n","143/143 [==============================] - 0s 388us/step - loss: 5.0709e-04 - accuracy: 1.0000 - val_loss: 3.3506 - val_accuracy: 0.5636\n","\n","Epoch 00594: val_accuracy did not improve from 0.61818\n","Epoch 595/1000\n","143/143 [==============================] - 0s 354us/step - loss: 1.7435e-04 - accuracy: 1.0000 - val_loss: 3.2868 - val_accuracy: 0.5818\n","\n","Epoch 00595: val_accuracy did not improve from 0.61818\n","Epoch 596/1000\n","143/143 [==============================] - 0s 350us/step - loss: 6.5835e-05 - accuracy: 1.0000 - val_loss: 3.2565 - val_accuracy: 0.5636\n","\n","Epoch 00596: val_accuracy did not improve from 0.61818\n","Epoch 597/1000\n","143/143 [==============================] - 0s 356us/step - loss: 6.0086e-04 - accuracy: 1.0000 - val_loss: 3.2391 - val_accuracy: 0.5636\n","\n","Epoch 00597: val_accuracy did not improve from 0.61818\n","Epoch 598/1000\n","143/143 [==============================] - 0s 352us/step - loss: 2.9750e-04 - accuracy: 1.0000 - val_loss: 3.2457 - val_accuracy: 0.5636\n","\n","Epoch 00598: val_accuracy did not improve from 0.61818\n","Epoch 599/1000\n","143/143 [==============================] - 0s 348us/step - loss: 2.7634e-04 - accuracy: 1.0000 - val_loss: 3.2558 - val_accuracy: 0.5636\n","\n","Epoch 00599: val_accuracy did not improve from 0.61818\n","Epoch 600/1000\n","143/143 [==============================] - 0s 345us/step - loss: 6.9688e-04 - accuracy: 1.0000 - val_loss: 3.2886 - val_accuracy: 0.5818\n","\n","Epoch 00600: val_accuracy did not improve from 0.61818\n","Epoch 601/1000\n","143/143 [==============================] - 0s 352us/step - loss: 2.2839e-04 - accuracy: 1.0000 - val_loss: 3.3292 - val_accuracy: 0.5636\n","\n","Epoch 00601: val_accuracy did not improve from 0.61818\n","Epoch 602/1000\n","143/143 [==============================] - 0s 360us/step - loss: 2.5346e-04 - accuracy: 1.0000 - val_loss: 3.3565 - val_accuracy: 0.5636\n","\n","Epoch 00602: val_accuracy did not improve from 0.61818\n","Epoch 603/1000\n","143/143 [==============================] - 0s 351us/step - loss: 5.4901e-04 - accuracy: 1.0000 - val_loss: 3.3794 - val_accuracy: 0.5636\n","\n","Epoch 00603: val_accuracy did not improve from 0.61818\n","Epoch 604/1000\n","143/143 [==============================] - 0s 345us/step - loss: 9.0036e-04 - accuracy: 1.0000 - val_loss: 3.3815 - val_accuracy: 0.5636\n","\n","Epoch 00604: val_accuracy did not improve from 0.61818\n","Epoch 605/1000\n","143/143 [==============================] - 0s 376us/step - loss: 8.7239e-05 - accuracy: 1.0000 - val_loss: 3.3864 - val_accuracy: 0.5636\n","\n","Epoch 00605: val_accuracy did not improve from 0.61818\n","Epoch 606/1000\n","143/143 [==============================] - 0s 341us/step - loss: 2.9753e-04 - accuracy: 1.0000 - val_loss: 3.3883 - val_accuracy: 0.5818\n","\n","Epoch 00606: val_accuracy did not improve from 0.61818\n","Epoch 607/1000\n","143/143 [==============================] - 0s 362us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.2916 - val_accuracy: 0.5636\n","\n","Epoch 00607: val_accuracy did not improve from 0.61818\n","Epoch 608/1000\n","143/143 [==============================] - 0s 348us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.2559 - val_accuracy: 0.5818\n","\n","Epoch 00608: val_accuracy did not improve from 0.61818\n","Epoch 609/1000\n","143/143 [==============================] - 0s 416us/step - loss: 1.8736e-04 - accuracy: 1.0000 - val_loss: 3.2419 - val_accuracy: 0.5818\n","\n","Epoch 00609: val_accuracy did not improve from 0.61818\n","Epoch 610/1000\n","143/143 [==============================] - 0s 354us/step - loss: 9.1978e-04 - accuracy: 1.0000 - val_loss: 3.2498 - val_accuracy: 0.5818\n","\n","Epoch 00610: val_accuracy did not improve from 0.61818\n","Epoch 611/1000\n","143/143 [==============================] - 0s 353us/step - loss: 0.0078 - accuracy: 0.9930 - val_loss: 3.4003 - val_accuracy: 0.5818\n","\n","Epoch 00611: val_accuracy did not improve from 0.61818\n","Epoch 612/1000\n","143/143 [==============================] - 0s 372us/step - loss: 1.5066e-04 - accuracy: 1.0000 - val_loss: 3.8222 - val_accuracy: 0.4909\n","\n","Epoch 00612: val_accuracy did not improve from 0.61818\n","Epoch 613/1000\n","143/143 [==============================] - 0s 357us/step - loss: 0.0082 - accuracy: 0.9930 - val_loss: 3.7029 - val_accuracy: 0.4727\n","\n","Epoch 00613: val_accuracy did not improve from 0.61818\n","Epoch 614/1000\n","143/143 [==============================] - 0s 353us/step - loss: 8.5687e-04 - accuracy: 1.0000 - val_loss: 3.0739 - val_accuracy: 0.5636\n","\n","Epoch 00614: val_accuracy did not improve from 0.61818\n","Epoch 615/1000\n","143/143 [==============================] - 0s 351us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.9905 - val_accuracy: 0.6364\n","\n","Epoch 00615: val_accuracy improved from 0.61818 to 0.63636, saving model to /content/drive/My Drive/saveModels/epi_eeg_conv1D_nigiria_5_80_32_1000_gazar_july_13_.hdf5\n","Epoch 616/1000\n","143/143 [==============================] - 0s 395us/step - loss: 0.0115 - accuracy: 0.9930 - val_loss: 3.0370 - val_accuracy: 0.5636\n","\n","Epoch 00616: val_accuracy did not improve from 0.63636\n","Epoch 617/1000\n","143/143 [==============================] - 0s 402us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 3.3695 - val_accuracy: 0.5455\n","\n","Epoch 00617: val_accuracy did not improve from 0.63636\n","Epoch 618/1000\n","143/143 [==============================] - 0s 352us/step - loss: 5.2217e-04 - accuracy: 1.0000 - val_loss: 3.6521 - val_accuracy: 0.4545\n","\n","Epoch 00618: val_accuracy did not improve from 0.63636\n","Epoch 619/1000\n","143/143 [==============================] - 0s 351us/step - loss: 2.4802e-04 - accuracy: 1.0000 - val_loss: 3.8172 - val_accuracy: 0.4364\n","\n","Epoch 00619: val_accuracy did not improve from 0.63636\n","Epoch 620/1000\n","143/143 [==============================] - 0s 419us/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 3.6196 - val_accuracy: 0.4364\n","\n","Epoch 00620: val_accuracy did not improve from 0.63636\n","Epoch 621/1000\n","143/143 [==============================] - 0s 351us/step - loss: 1.1765e-04 - accuracy: 1.0000 - val_loss: 3.3119 - val_accuracy: 0.5455\n","\n","Epoch 00621: val_accuracy did not improve from 0.63636\n","Epoch 622/1000\n","143/143 [==============================] - 0s 345us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 3.1207 - val_accuracy: 0.5455\n","\n","Epoch 00622: val_accuracy did not improve from 0.63636\n","Epoch 623/1000\n","143/143 [==============================] - 0s 365us/step - loss: 0.0064 - accuracy: 0.9930 - val_loss: 3.2209 - val_accuracy: 0.5818\n","\n","Epoch 00623: val_accuracy did not improve from 0.63636\n","Epoch 624/1000\n","143/143 [==============================] - 0s 352us/step - loss: 0.0146 - accuracy: 0.9930 - val_loss: 3.8902 - val_accuracy: 0.4182\n","\n","Epoch 00624: val_accuracy did not improve from 0.63636\n","Epoch 625/1000\n","143/143 [==============================] - 0s 348us/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 3.5010 - val_accuracy: 0.5455\n","\n","Epoch 00625: val_accuracy did not improve from 0.63636\n","Epoch 626/1000\n","143/143 [==============================] - 0s 353us/step - loss: 2.8517e-04 - accuracy: 1.0000 - val_loss: 3.4331 - val_accuracy: 0.5818\n","\n","Epoch 00626: val_accuracy did not improve from 0.63636\n","Epoch 627/1000\n","143/143 [==============================] - 0s 342us/step - loss: 8.7971e-04 - accuracy: 1.0000 - val_loss: 3.3859 - val_accuracy: 0.5818\n","\n","Epoch 00627: val_accuracy did not improve from 0.63636\n","Epoch 628/1000\n","143/143 [==============================] - 0s 347us/step - loss: 2.8140e-04 - accuracy: 1.0000 - val_loss: 3.3762 - val_accuracy: 0.5636\n","\n","Epoch 00628: val_accuracy did not improve from 0.63636\n","Epoch 629/1000\n","143/143 [==============================] - 0s 344us/step - loss: 2.0382e-04 - accuracy: 1.0000 - val_loss: 3.3755 - val_accuracy: 0.5636\n","\n","Epoch 00629: val_accuracy did not improve from 0.63636\n","Epoch 630/1000\n","143/143 [==============================] - 0s 356us/step - loss: 1.6462e-04 - accuracy: 1.0000 - val_loss: 3.3773 - val_accuracy: 0.5636\n","\n","Epoch 00630: val_accuracy did not improve from 0.63636\n","Epoch 631/1000\n","143/143 [==============================] - 0s 347us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.3800 - val_accuracy: 0.5636\n","\n","Epoch 00631: val_accuracy did not improve from 0.63636\n","Epoch 632/1000\n","143/143 [==============================] - 0s 347us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 3.3767 - val_accuracy: 0.5636\n","\n","Epoch 00632: val_accuracy did not improve from 0.63636\n","Epoch 633/1000\n","143/143 [==============================] - 0s 413us/step - loss: 4.7925e-04 - accuracy: 1.0000 - val_loss: 3.3961 - val_accuracy: 0.5636\n","\n","Epoch 00633: val_accuracy did not improve from 0.63636\n","Epoch 634/1000\n","143/143 [==============================] - 0s 348us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.4540 - val_accuracy: 0.5636\n","\n","Epoch 00634: val_accuracy did not improve from 0.63636\n","Epoch 635/1000\n","143/143 [==============================] - 0s 417us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 3.6226 - val_accuracy: 0.5818\n","\n","Epoch 00635: val_accuracy did not improve from 0.63636\n","Epoch 636/1000\n","143/143 [==============================] - 0s 346us/step - loss: 3.4692e-04 - accuracy: 1.0000 - val_loss: 3.7099 - val_accuracy: 0.5636\n","\n","Epoch 00636: val_accuracy did not improve from 0.63636\n","Epoch 637/1000\n","143/143 [==============================] - 0s 347us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 3.5814 - val_accuracy: 0.5818\n","\n","Epoch 00637: val_accuracy did not improve from 0.63636\n","Epoch 638/1000\n","143/143 [==============================] - 0s 377us/step - loss: 3.1518e-04 - accuracy: 1.0000 - val_loss: 3.4935 - val_accuracy: 0.5636\n","\n","Epoch 00638: val_accuracy did not improve from 0.63636\n","Epoch 639/1000\n","143/143 [==============================] - 0s 383us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 3.4917 - val_accuracy: 0.5636\n","\n","Epoch 00639: val_accuracy did not improve from 0.63636\n","Epoch 640/1000\n","143/143 [==============================] - 0s 371us/step - loss: 7.8635e-05 - accuracy: 1.0000 - val_loss: 3.6558 - val_accuracy: 0.6000\n","\n","Epoch 00640: val_accuracy did not improve from 0.63636\n","Epoch 641/1000\n","143/143 [==============================] - 0s 359us/step - loss: 8.4573e-04 - accuracy: 1.0000 - val_loss: 3.7374 - val_accuracy: 0.5455\n","\n","Epoch 00641: val_accuracy did not improve from 0.63636\n","Epoch 642/1000\n","143/143 [==============================] - 0s 348us/step - loss: 5.8150e-04 - accuracy: 1.0000 - val_loss: 3.7382 - val_accuracy: 0.5455\n","\n","Epoch 00642: val_accuracy did not improve from 0.63636\n","Epoch 643/1000\n","143/143 [==============================] - 0s 346us/step - loss: 7.6233e-05 - accuracy: 1.0000 - val_loss: 3.7393 - val_accuracy: 0.5455\n","\n","Epoch 00643: val_accuracy did not improve from 0.63636\n","Epoch 644/1000\n","143/143 [==============================] - 0s 355us/step - loss: 2.5608e-04 - accuracy: 1.0000 - val_loss: 3.7376 - val_accuracy: 0.5455\n","\n","Epoch 00644: val_accuracy did not improve from 0.63636\n","Epoch 645/1000\n","143/143 [==============================] - 0s 360us/step - loss: 1.8969e-04 - accuracy: 1.0000 - val_loss: 3.7143 - val_accuracy: 0.5636\n","\n","Epoch 00645: val_accuracy did not improve from 0.63636\n","Epoch 646/1000\n","143/143 [==============================] - 0s 356us/step - loss: 9.5797e-04 - accuracy: 1.0000 - val_loss: 3.6629 - val_accuracy: 0.5818\n","\n","Epoch 00646: val_accuracy did not improve from 0.63636\n","Epoch 647/1000\n","143/143 [==============================] - 0s 361us/step - loss: 2.3351e-04 - accuracy: 1.0000 - val_loss: 3.6222 - val_accuracy: 0.5818\n","\n","Epoch 00647: val_accuracy did not improve from 0.63636\n","Epoch 648/1000\n","143/143 [==============================] - 0s 348us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 3.6228 - val_accuracy: 0.5818\n","\n","Epoch 00648: val_accuracy did not improve from 0.63636\n","Epoch 649/1000\n","143/143 [==============================] - 0s 345us/step - loss: 1.2706e-04 - accuracy: 1.0000 - val_loss: 3.6251 - val_accuracy: 0.5818\n","\n","Epoch 00649: val_accuracy did not improve from 0.63636\n","Epoch 650/1000\n","143/143 [==============================] - 0s 360us/step - loss: 1.0713e-04 - accuracy: 1.0000 - val_loss: 3.6283 - val_accuracy: 0.5818\n","\n","Epoch 00650: val_accuracy did not improve from 0.63636\n","Epoch 651/1000\n","143/143 [==============================] - 0s 341us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 3.5618 - val_accuracy: 0.5636\n","\n","Epoch 00651: val_accuracy did not improve from 0.63636\n","Epoch 652/1000\n","143/143 [==============================] - 0s 349us/step - loss: 6.5257e-04 - accuracy: 1.0000 - val_loss: 3.5422 - val_accuracy: 0.5636\n","\n","Epoch 00652: val_accuracy did not improve from 0.63636\n","Epoch 653/1000\n","143/143 [==============================] - 0s 408us/step - loss: 1.0005e-04 - accuracy: 1.0000 - val_loss: 3.5454 - val_accuracy: 0.5636\n","\n","Epoch 00653: val_accuracy did not improve from 0.63636\n","Epoch 654/1000\n","143/143 [==============================] - 0s 350us/step - loss: 1.3007e-04 - accuracy: 1.0000 - val_loss: 3.5497 - val_accuracy: 0.5636\n","\n","Epoch 00654: val_accuracy did not improve from 0.63636\n","Epoch 655/1000\n","143/143 [==============================] - 0s 351us/step - loss: 5.0273e-04 - accuracy: 1.0000 - val_loss: 3.5516 - val_accuracy: 0.5636\n","\n","Epoch 00655: val_accuracy did not improve from 0.63636\n","Epoch 656/1000\n","143/143 [==============================] - 0s 409us/step - loss: 7.4851e-05 - accuracy: 1.0000 - val_loss: 3.5607 - val_accuracy: 0.5636\n","\n","Epoch 00656: val_accuracy did not improve from 0.63636\n","Epoch 657/1000\n","143/143 [==============================] - 0s 372us/step - loss: 3.8162e-04 - accuracy: 1.0000 - val_loss: 3.5707 - val_accuracy: 0.5636\n","\n","Epoch 00657: val_accuracy did not improve from 0.63636\n","Epoch 658/1000\n","143/143 [==============================] - 0s 382us/step - loss: 5.5530e-04 - accuracy: 1.0000 - val_loss: 3.5924 - val_accuracy: 0.5818\n","\n","Epoch 00658: val_accuracy did not improve from 0.63636\n","Epoch 659/1000\n","143/143 [==============================] - 0s 349us/step - loss: 0.0104 - accuracy: 0.9930 - val_loss: 3.5478 - val_accuracy: 0.5818\n","\n","Epoch 00659: val_accuracy did not improve from 0.63636\n","Epoch 660/1000\n","143/143 [==============================] - 0s 337us/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 3.9764 - val_accuracy: 0.4545\n","\n","Epoch 00660: val_accuracy did not improve from 0.63636\n","Epoch 661/1000\n","143/143 [==============================] - 0s 354us/step - loss: 1.4569e-04 - accuracy: 1.0000 - val_loss: 4.2344 - val_accuracy: 0.4545\n","\n","Epoch 00661: val_accuracy did not improve from 0.63636\n","Epoch 662/1000\n","143/143 [==============================] - 0s 357us/step - loss: 0.0147 - accuracy: 0.9860 - val_loss: 3.7278 - val_accuracy: 0.4909\n","\n","Epoch 00662: val_accuracy did not improve from 0.63636\n","Epoch 663/1000\n","143/143 [==============================] - 0s 351us/step - loss: 3.5190e-04 - accuracy: 1.0000 - val_loss: 3.4133 - val_accuracy: 0.5636\n","\n","Epoch 00663: val_accuracy did not improve from 0.63636\n","Epoch 664/1000\n","143/143 [==============================] - 0s 346us/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 3.5236 - val_accuracy: 0.5273\n","\n","Epoch 00664: val_accuracy did not improve from 0.63636\n","Epoch 665/1000\n","143/143 [==============================] - 0s 343us/step - loss: 0.0077 - accuracy: 0.9930 - val_loss: 4.1293 - val_accuracy: 0.4727\n","\n","Epoch 00665: val_accuracy did not improve from 0.63636\n","Epoch 666/1000\n","143/143 [==============================] - 0s 358us/step - loss: 0.0075 - accuracy: 0.9930 - val_loss: 4.2659 - val_accuracy: 0.4545\n","\n","Epoch 00666: val_accuracy did not improve from 0.63636\n","Epoch 667/1000\n","143/143 [==============================] - 0s 369us/step - loss: 0.0052 - accuracy: 0.9930 - val_loss: 3.6517 - val_accuracy: 0.5636\n","\n","Epoch 00667: val_accuracy did not improve from 0.63636\n","Epoch 668/1000\n","143/143 [==============================] - 0s 356us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 3.6542 - val_accuracy: 0.6182\n","\n","Epoch 00668: val_accuracy did not improve from 0.63636\n","Epoch 669/1000\n","143/143 [==============================] - 0s 337us/step - loss: 3.7266e-04 - accuracy: 1.0000 - val_loss: 3.6785 - val_accuracy: 0.6000\n","\n","Epoch 00669: val_accuracy did not improve from 0.63636\n","Epoch 670/1000\n","143/143 [==============================] - 0s 350us/step - loss: 5.6751e-04 - accuracy: 1.0000 - val_loss: 3.6873 - val_accuracy: 0.6000\n","\n","Epoch 00670: val_accuracy did not improve from 0.63636\n","Epoch 671/1000\n","143/143 [==============================] - 0s 383us/step - loss: 2.0559e-04 - accuracy: 1.0000 - val_loss: 3.6776 - val_accuracy: 0.6182\n","\n","Epoch 00671: val_accuracy did not improve from 0.63636\n","Epoch 672/1000\n","143/143 [==============================] - 0s 348us/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 3.6182 - val_accuracy: 0.6182\n","\n","Epoch 00672: val_accuracy did not improve from 0.63636\n","Epoch 673/1000\n","143/143 [==============================] - 0s 363us/step - loss: 0.0088 - accuracy: 0.9930 - val_loss: 3.6129 - val_accuracy: 0.6182\n","\n","Epoch 00673: val_accuracy did not improve from 0.63636\n","Epoch 674/1000\n","143/143 [==============================] - 0s 398us/step - loss: 7.7407e-04 - accuracy: 1.0000 - val_loss: 3.6285 - val_accuracy: 0.6000\n","\n","Epoch 00674: val_accuracy did not improve from 0.63636\n","Epoch 675/1000\n","143/143 [==============================] - 0s 371us/step - loss: 2.3567e-04 - accuracy: 1.0000 - val_loss: 3.6441 - val_accuracy: 0.6000\n","\n","Epoch 00675: val_accuracy did not improve from 0.63636\n","Epoch 676/1000\n","143/143 [==============================] - 0s 358us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 3.6297 - val_accuracy: 0.6000\n","\n","Epoch 00676: val_accuracy did not improve from 0.63636\n","Epoch 677/1000\n","143/143 [==============================] - 0s 386us/step - loss: 9.1376e-04 - accuracy: 1.0000 - val_loss: 3.7121 - val_accuracy: 0.6000\n","\n","Epoch 00677: val_accuracy did not improve from 0.63636\n","Epoch 678/1000\n","143/143 [==============================] - 0s 359us/step - loss: 1.7928e-04 - accuracy: 1.0000 - val_loss: 3.7871 - val_accuracy: 0.5818\n","\n","Epoch 00678: val_accuracy did not improve from 0.63636\n","Epoch 679/1000\n","143/143 [==============================] - 0s 344us/step - loss: 6.9323e-04 - accuracy: 1.0000 - val_loss: 3.8087 - val_accuracy: 0.5455\n","\n","Epoch 00679: val_accuracy did not improve from 0.63636\n","Epoch 680/1000\n","143/143 [==============================] - 0s 349us/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 3.7248 - val_accuracy: 0.5818\n","\n","Epoch 00680: val_accuracy did not improve from 0.63636\n","Epoch 681/1000\n","143/143 [==============================] - 0s 343us/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 3.4851 - val_accuracy: 0.5636\n","\n","Epoch 00681: val_accuracy did not improve from 0.63636\n","Epoch 682/1000\n","143/143 [==============================] - 0s 350us/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 3.4818 - val_accuracy: 0.6000\n","\n","Epoch 00682: val_accuracy did not improve from 0.63636\n","Epoch 683/1000\n","143/143 [==============================] - 0s 352us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 3.7082 - val_accuracy: 0.5636\n","\n","Epoch 00683: val_accuracy did not improve from 0.63636\n","Epoch 684/1000\n","143/143 [==============================] - 0s 352us/step - loss: 1.4212e-04 - accuracy: 1.0000 - val_loss: 3.9810 - val_accuracy: 0.5091\n","\n","Epoch 00684: val_accuracy did not improve from 0.63636\n","Epoch 685/1000\n","143/143 [==============================] - 0s 351us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 4.1233 - val_accuracy: 0.5091\n","\n","Epoch 00685: val_accuracy did not improve from 0.63636\n","Epoch 686/1000\n","143/143 [==============================] - 0s 349us/step - loss: 5.9564e-04 - accuracy: 1.0000 - val_loss: 4.1624 - val_accuracy: 0.5091\n","\n","Epoch 00686: val_accuracy did not improve from 0.63636\n","Epoch 687/1000\n","143/143 [==============================] - 0s 336us/step - loss: 2.0499e-04 - accuracy: 1.0000 - val_loss: 4.1729 - val_accuracy: 0.5091\n","\n","Epoch 00687: val_accuracy did not improve from 0.63636\n","Epoch 688/1000\n","143/143 [==============================] - 0s 341us/step - loss: 9.7205e-04 - accuracy: 1.0000 - val_loss: 4.0713 - val_accuracy: 0.5455\n","\n","Epoch 00688: val_accuracy did not improve from 0.63636\n","Epoch 689/1000\n","143/143 [==============================] - 0s 349us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 4.0970 - val_accuracy: 0.5455\n","\n","Epoch 00689: val_accuracy did not improve from 0.63636\n","Epoch 690/1000\n","143/143 [==============================] - 0s 396us/step - loss: 6.7853e-04 - accuracy: 1.0000 - val_loss: 4.2061 - val_accuracy: 0.5091\n","\n","Epoch 00690: val_accuracy did not improve from 0.63636\n","Epoch 691/1000\n","143/143 [==============================] - 0s 344us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 4.1378 - val_accuracy: 0.5273\n","\n","Epoch 00691: val_accuracy did not improve from 0.63636\n","Epoch 692/1000\n","143/143 [==============================] - 0s 350us/step - loss: 1.0362e-04 - accuracy: 1.0000 - val_loss: 4.1174 - val_accuracy: 0.5273\n","\n","Epoch 00692: val_accuracy did not improve from 0.63636\n","Epoch 693/1000\n","143/143 [==============================] - 0s 374us/step - loss: 5.2844e-04 - accuracy: 1.0000 - val_loss: 4.1120 - val_accuracy: 0.5273\n","\n","Epoch 00693: val_accuracy did not improve from 0.63636\n","Epoch 694/1000\n","143/143 [==============================] - 0s 356us/step - loss: 7.0242e-04 - accuracy: 1.0000 - val_loss: 4.0809 - val_accuracy: 0.5273\n","\n","Epoch 00694: val_accuracy did not improve from 0.63636\n","Epoch 695/1000\n","143/143 [==============================] - 0s 363us/step - loss: 0.0094 - accuracy: 0.9930 - val_loss: 4.5987 - val_accuracy: 0.4727\n","\n","Epoch 00695: val_accuracy did not improve from 0.63636\n","Epoch 696/1000\n","143/143 [==============================] - 0s 343us/step - loss: 8.1610e-05 - accuracy: 1.0000 - val_loss: 5.1690 - val_accuracy: 0.4182\n","\n","Epoch 00696: val_accuracy did not improve from 0.63636\n","Epoch 697/1000\n","143/143 [==============================] - 0s 354us/step - loss: 0.0208 - accuracy: 0.9930 - val_loss: 4.4989 - val_accuracy: 0.4545\n","\n","Epoch 00697: val_accuracy did not improve from 0.63636\n","Epoch 698/1000\n","143/143 [==============================] - 0s 343us/step - loss: 0.0074 - accuracy: 0.9930 - val_loss: 3.4729 - val_accuracy: 0.5273\n","\n","Epoch 00698: val_accuracy did not improve from 0.63636\n","Epoch 699/1000\n","143/143 [==============================] - 0s 355us/step - loss: 0.0118 - accuracy: 1.0000 - val_loss: 3.1126 - val_accuracy: 0.5818\n","\n","Epoch 00699: val_accuracy did not improve from 0.63636\n","Epoch 700/1000\n","143/143 [==============================] - 0s 350us/step - loss: 0.0072 - accuracy: 1.0000 - val_loss: 3.6432 - val_accuracy: 0.5091\n","\n","Epoch 00700: val_accuracy did not improve from 0.63636\n","Epoch 701/1000\n","143/143 [==============================] - 0s 355us/step - loss: 2.4445e-04 - accuracy: 1.0000 - val_loss: 4.2170 - val_accuracy: 0.4727\n","\n","Epoch 00701: val_accuracy did not improve from 0.63636\n","Epoch 702/1000\n","143/143 [==============================] - 0s 347us/step - loss: 3.1504e-04 - accuracy: 1.0000 - val_loss: 4.6136 - val_accuracy: 0.4727\n","\n","Epoch 00702: val_accuracy did not improve from 0.63636\n","Epoch 703/1000\n","143/143 [==============================] - 0s 341us/step - loss: 0.0430 - accuracy: 0.9930 - val_loss: 3.9328 - val_accuracy: 0.5091\n","\n","Epoch 00703: val_accuracy did not improve from 0.63636\n","Epoch 704/1000\n","143/143 [==============================] - 0s 350us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 3.8660 - val_accuracy: 0.5455\n","\n","Epoch 00704: val_accuracy did not improve from 0.63636\n","Epoch 705/1000\n","143/143 [==============================] - 0s 350us/step - loss: 0.0063 - accuracy: 0.9930 - val_loss: 3.9915 - val_accuracy: 0.4909\n","\n","Epoch 00705: val_accuracy did not improve from 0.63636\n","Epoch 706/1000\n","143/143 [==============================] - 0s 352us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 4.1979 - val_accuracy: 0.4727\n","\n","Epoch 00706: val_accuracy did not improve from 0.63636\n","Epoch 707/1000\n","143/143 [==============================] - 0s 354us/step - loss: 3.9040e-05 - accuracy: 1.0000 - val_loss: 4.0416 - val_accuracy: 0.4909\n","\n","Epoch 00707: val_accuracy did not improve from 0.63636\n","Epoch 708/1000\n","143/143 [==============================] - 0s 436us/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 4.1227 - val_accuracy: 0.4545\n","\n","Epoch 00708: val_accuracy did not improve from 0.63636\n","Epoch 709/1000\n","143/143 [==============================] - 0s 378us/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 4.6236 - val_accuracy: 0.4364\n","\n","Epoch 00709: val_accuracy did not improve from 0.63636\n","Epoch 710/1000\n","143/143 [==============================] - 0s 361us/step - loss: 4.2273e-04 - accuracy: 1.0000 - val_loss: 4.2242 - val_accuracy: 0.4545\n","\n","Epoch 00710: val_accuracy did not improve from 0.63636\n","Epoch 711/1000\n","143/143 [==============================] - 0s 386us/step - loss: 3.7260e-04 - accuracy: 1.0000 - val_loss: 3.9797 - val_accuracy: 0.4545\n","\n","Epoch 00711: val_accuracy did not improve from 0.63636\n","Epoch 712/1000\n","143/143 [==============================] - 0s 352us/step - loss: 6.7796e-04 - accuracy: 1.0000 - val_loss: 3.9037 - val_accuracy: 0.4545\n","\n","Epoch 00712: val_accuracy did not improve from 0.63636\n","Epoch 713/1000\n","143/143 [==============================] - 0s 347us/step - loss: 8.6293e-04 - accuracy: 1.0000 - val_loss: 3.9695 - val_accuracy: 0.4545\n","\n","Epoch 00713: val_accuracy did not improve from 0.63636\n","Epoch 714/1000\n","143/143 [==============================] - 0s 350us/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 4.4468 - val_accuracy: 0.4545\n","\n","Epoch 00714: val_accuracy did not improve from 0.63636\n","Epoch 715/1000\n","143/143 [==============================] - 0s 346us/step - loss: 0.0062 - accuracy: 0.9930 - val_loss: 4.3832 - val_accuracy: 0.4727\n","\n","Epoch 00715: val_accuracy did not improve from 0.63636\n","Epoch 716/1000\n","143/143 [==============================] - 0s 353us/step - loss: 1.3792e-04 - accuracy: 1.0000 - val_loss: 4.1117 - val_accuracy: 0.4545\n","\n","Epoch 00716: val_accuracy did not improve from 0.63636\n","Epoch 717/1000\n","143/143 [==============================] - 0s 353us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 3.9630 - val_accuracy: 0.4545\n","\n","Epoch 00717: val_accuracy did not improve from 0.63636\n","Epoch 718/1000\n","143/143 [==============================] - 0s 349us/step - loss: 6.5181e-04 - accuracy: 1.0000 - val_loss: 3.9415 - val_accuracy: 0.4545\n","\n","Epoch 00718: val_accuracy did not improve from 0.63636\n","Epoch 719/1000\n","143/143 [==============================] - 0s 347us/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 4.1720 - val_accuracy: 0.4545\n","\n","Epoch 00719: val_accuracy did not improve from 0.63636\n","Epoch 720/1000\n","143/143 [==============================] - 0s 348us/step - loss: 6.8953e-05 - accuracy: 1.0000 - val_loss: 4.5618 - val_accuracy: 0.4364\n","\n","Epoch 00720: val_accuracy did not improve from 0.63636\n","Epoch 721/1000\n","143/143 [==============================] - 0s 354us/step - loss: 3.1670e-04 - accuracy: 1.0000 - val_loss: 4.8023 - val_accuracy: 0.4364\n","\n","Epoch 00721: val_accuracy did not improve from 0.63636\n","Epoch 722/1000\n","143/143 [==============================] - 0s 353us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 4.8295 - val_accuracy: 0.4364\n","\n","Epoch 00722: val_accuracy did not improve from 0.63636\n","Epoch 723/1000\n","143/143 [==============================] - 0s 344us/step - loss: 4.1335e-04 - accuracy: 1.0000 - val_loss: 4.7253 - val_accuracy: 0.4364\n","\n","Epoch 00723: val_accuracy did not improve from 0.63636\n","Epoch 724/1000\n","143/143 [==============================] - 0s 348us/step - loss: 3.3474e-04 - accuracy: 1.0000 - val_loss: 4.6034 - val_accuracy: 0.4364\n","\n","Epoch 00724: val_accuracy did not improve from 0.63636\n","Epoch 725/1000\n","143/143 [==============================] - 0s 349us/step - loss: 9.3308e-04 - accuracy: 1.0000 - val_loss: 4.4074 - val_accuracy: 0.4364\n","\n","Epoch 00725: val_accuracy did not improve from 0.63636\n","Epoch 726/1000\n","143/143 [==============================] - 0s 345us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 4.2832 - val_accuracy: 0.4182\n","\n","Epoch 00726: val_accuracy did not improve from 0.63636\n","Epoch 727/1000\n","143/143 [==============================] - 0s 390us/step - loss: 1.8811e-04 - accuracy: 1.0000 - val_loss: 4.2624 - val_accuracy: 0.4364\n","\n","Epoch 00727: val_accuracy did not improve from 0.63636\n","Epoch 728/1000\n","143/143 [==============================] - 0s 378us/step - loss: 0.0255 - accuracy: 0.9930 - val_loss: 3.7897 - val_accuracy: 0.4545\n","\n","Epoch 00728: val_accuracy did not improve from 0.63636\n","Epoch 729/1000\n","143/143 [==============================] - 0s 383us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.2895 - val_accuracy: 0.5636\n","\n","Epoch 00729: val_accuracy did not improve from 0.63636\n","Epoch 730/1000\n","143/143 [==============================] - 0s 373us/step - loss: 0.0147 - accuracy: 0.9930 - val_loss: 3.8784 - val_accuracy: 0.4727\n","\n","Epoch 00730: val_accuracy did not improve from 0.63636\n","Epoch 731/1000\n","143/143 [==============================] - 0s 353us/step - loss: 0.0207 - accuracy: 0.9930 - val_loss: 4.4003 - val_accuracy: 0.4727\n","\n","Epoch 00731: val_accuracy did not improve from 0.63636\n","Epoch 732/1000\n","143/143 [==============================] - 0s 352us/step - loss: 9.0168e-04 - accuracy: 1.0000 - val_loss: 4.0442 - val_accuracy: 0.4727\n","\n","Epoch 00732: val_accuracy did not improve from 0.63636\n","Epoch 733/1000\n","143/143 [==============================] - 0s 347us/step - loss: 1.7714e-04 - accuracy: 1.0000 - val_loss: 3.8454 - val_accuracy: 0.4909\n","\n","Epoch 00733: val_accuracy did not improve from 0.63636\n","Epoch 734/1000\n","143/143 [==============================] - 0s 337us/step - loss: 5.6397e-04 - accuracy: 1.0000 - val_loss: 3.7931 - val_accuracy: 0.4909\n","\n","Epoch 00734: val_accuracy did not improve from 0.63636\n","Epoch 735/1000\n","143/143 [==============================] - 0s 347us/step - loss: 2.3475e-04 - accuracy: 1.0000 - val_loss: 3.7819 - val_accuracy: 0.5091\n","\n","Epoch 00735: val_accuracy did not improve from 0.63636\n","Epoch 736/1000\n","143/143 [==============================] - 0s 336us/step - loss: 9.2959e-04 - accuracy: 1.0000 - val_loss: 3.8470 - val_accuracy: 0.4909\n","\n","Epoch 00736: val_accuracy did not improve from 0.63636\n","Epoch 737/1000\n","143/143 [==============================] - 0s 345us/step - loss: 6.8005e-05 - accuracy: 1.0000 - val_loss: 3.8862 - val_accuracy: 0.4909\n","\n","Epoch 00737: val_accuracy did not improve from 0.63636\n","Epoch 738/1000\n","143/143 [==============================] - 0s 345us/step - loss: 2.2478e-04 - accuracy: 1.0000 - val_loss: 3.9080 - val_accuracy: 0.4909\n","\n","Epoch 00738: val_accuracy did not improve from 0.63636\n","Epoch 739/1000\n","143/143 [==============================] - 0s 356us/step - loss: 0.0093 - accuracy: 0.9930 - val_loss: 3.4588 - val_accuracy: 0.5636\n","\n","Epoch 00739: val_accuracy did not improve from 0.63636\n","Epoch 740/1000\n","143/143 [==============================] - 0s 346us/step - loss: 6.5270e-04 - accuracy: 1.0000 - val_loss: 3.2619 - val_accuracy: 0.5636\n","\n","Epoch 00740: val_accuracy did not improve from 0.63636\n","Epoch 741/1000\n","143/143 [==============================] - 0s 341us/step - loss: 0.0368 - accuracy: 0.9930 - val_loss: 3.7836 - val_accuracy: 0.4909\n","\n","Epoch 00741: val_accuracy did not improve from 0.63636\n","Epoch 742/1000\n","143/143 [==============================] - 0s 347us/step - loss: 0.0104 - accuracy: 0.9930 - val_loss: 4.5280 - val_accuracy: 0.4727\n","\n","Epoch 00742: val_accuracy did not improve from 0.63636\n","Epoch 743/1000\n","143/143 [==============================] - 0s 336us/step - loss: 0.0130 - accuracy: 0.9930 - val_loss: 4.0229 - val_accuracy: 0.4909\n","\n","Epoch 00743: val_accuracy did not improve from 0.63636\n","Epoch 744/1000\n","143/143 [==============================] - 0s 347us/step - loss: 2.1126e-04 - accuracy: 1.0000 - val_loss: 3.5357 - val_accuracy: 0.5091\n","\n","Epoch 00744: val_accuracy did not improve from 0.63636\n","Epoch 745/1000\n","143/143 [==============================] - 0s 391us/step - loss: 0.0056 - accuracy: 1.0000 - val_loss: 3.4063 - val_accuracy: 0.4909\n","\n","Epoch 00745: val_accuracy did not improve from 0.63636\n","Epoch 746/1000\n","143/143 [==============================] - 0s 342us/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 3.6441 - val_accuracy: 0.4727\n","\n","Epoch 00746: val_accuracy did not improve from 0.63636\n","Epoch 747/1000\n","143/143 [==============================] - 0s 345us/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 4.2386 - val_accuracy: 0.4727\n","\n","Epoch 00747: val_accuracy did not improve from 0.63636\n","Epoch 748/1000\n","143/143 [==============================] - 0s 397us/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 4.7711 - val_accuracy: 0.4182\n","\n","Epoch 00748: val_accuracy did not improve from 0.63636\n","Epoch 749/1000\n","143/143 [==============================] - 0s 355us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 5.1481 - val_accuracy: 0.4364\n","\n","Epoch 00749: val_accuracy did not improve from 0.63636\n","Epoch 750/1000\n","143/143 [==============================] - 0s 358us/step - loss: 4.7364e-04 - accuracy: 1.0000 - val_loss: 5.2042 - val_accuracy: 0.4364\n","\n","Epoch 00750: val_accuracy did not improve from 0.63636\n","Epoch 751/1000\n","143/143 [==============================] - 0s 349us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 5.0915 - val_accuracy: 0.4182\n","\n","Epoch 00751: val_accuracy did not improve from 0.63636\n","Epoch 752/1000\n","143/143 [==============================] - 0s 339us/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 4.6151 - val_accuracy: 0.4545\n","\n","Epoch 00752: val_accuracy did not improve from 0.63636\n","Epoch 753/1000\n","143/143 [==============================] - 0s 336us/step - loss: 2.4820e-04 - accuracy: 1.0000 - val_loss: 4.3405 - val_accuracy: 0.4909\n","\n","Epoch 00753: val_accuracy did not improve from 0.63636\n","Epoch 754/1000\n","143/143 [==============================] - 0s 347us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 4.2369 - val_accuracy: 0.4909\n","\n","Epoch 00754: val_accuracy did not improve from 0.63636\n","Epoch 755/1000\n","143/143 [==============================] - 0s 370us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 4.1471 - val_accuracy: 0.4727\n","\n","Epoch 00755: val_accuracy did not improve from 0.63636\n","Epoch 756/1000\n","143/143 [==============================] - 0s 347us/step - loss: 1.9406e-04 - accuracy: 1.0000 - val_loss: 4.2283 - val_accuracy: 0.4909\n","\n","Epoch 00756: val_accuracy did not improve from 0.63636\n","Epoch 757/1000\n","143/143 [==============================] - 0s 339us/step - loss: 1.5142e-04 - accuracy: 1.0000 - val_loss: 4.2859 - val_accuracy: 0.4909\n","\n","Epoch 00757: val_accuracy did not improve from 0.63636\n","Epoch 758/1000\n","143/143 [==============================] - 0s 338us/step - loss: 4.0770e-04 - accuracy: 1.0000 - val_loss: 4.3039 - val_accuracy: 0.4909\n","\n","Epoch 00758: val_accuracy did not improve from 0.63636\n","Epoch 759/1000\n","143/143 [==============================] - 0s 353us/step - loss: 3.1386e-04 - accuracy: 1.0000 - val_loss: 4.3170 - val_accuracy: 0.4909\n","\n","Epoch 00759: val_accuracy did not improve from 0.63636\n","Epoch 760/1000\n","143/143 [==============================] - 0s 336us/step - loss: 9.3240e-04 - accuracy: 1.0000 - val_loss: 4.2397 - val_accuracy: 0.4909\n","\n","Epoch 00760: val_accuracy did not improve from 0.63636\n","Epoch 761/1000\n","143/143 [==============================] - 0s 347us/step - loss: 1.9859e-04 - accuracy: 1.0000 - val_loss: 4.1872 - val_accuracy: 0.4909\n","\n","Epoch 00761: val_accuracy did not improve from 0.63636\n","Epoch 762/1000\n","143/143 [==============================] - 0s 346us/step - loss: 8.6007e-05 - accuracy: 1.0000 - val_loss: 4.1476 - val_accuracy: 0.4727\n","\n","Epoch 00762: val_accuracy did not improve from 0.63636\n","Epoch 763/1000\n","143/143 [==============================] - 0s 345us/step - loss: 1.1777e-04 - accuracy: 1.0000 - val_loss: 4.1359 - val_accuracy: 0.4727\n","\n","Epoch 00763: val_accuracy did not improve from 0.63636\n","Epoch 764/1000\n","143/143 [==============================] - 0s 382us/step - loss: 2.9586e-04 - accuracy: 1.0000 - val_loss: 4.1296 - val_accuracy: 0.4727\n","\n","Epoch 00764: val_accuracy did not improve from 0.63636\n","Epoch 765/1000\n","143/143 [==============================] - 0s 353us/step - loss: 1.0088e-04 - accuracy: 1.0000 - val_loss: 4.1474 - val_accuracy: 0.4727\n","\n","Epoch 00765: val_accuracy did not improve from 0.63636\n","Epoch 766/1000\n","143/143 [==============================] - 0s 412us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 4.2282 - val_accuracy: 0.4909\n","\n","Epoch 00766: val_accuracy did not improve from 0.63636\n","Epoch 767/1000\n","143/143 [==============================] - 0s 366us/step - loss: 0.0344 - accuracy: 0.9930 - val_loss: 3.7418 - val_accuracy: 0.4727\n","\n","Epoch 00767: val_accuracy did not improve from 0.63636\n","Epoch 768/1000\n","143/143 [==============================] - 0s 388us/step - loss: 0.0061 - accuracy: 0.9930 - val_loss: 3.6412 - val_accuracy: 0.5091\n","\n","Epoch 00768: val_accuracy did not improve from 0.63636\n","Epoch 769/1000\n","143/143 [==============================] - 0s 362us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 3.8426 - val_accuracy: 0.4909\n","\n","Epoch 00769: val_accuracy did not improve from 0.63636\n","Epoch 770/1000\n","143/143 [==============================] - 0s 360us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 4.1199 - val_accuracy: 0.4727\n","\n","Epoch 00770: val_accuracy did not improve from 0.63636\n","Epoch 771/1000\n","143/143 [==============================] - 0s 342us/step - loss: 1.3861e-04 - accuracy: 1.0000 - val_loss: 4.3416 - val_accuracy: 0.4727\n","\n","Epoch 00771: val_accuracy did not improve from 0.63636\n","Epoch 772/1000\n","143/143 [==============================] - 0s 338us/step - loss: 3.4404e-04 - accuracy: 1.0000 - val_loss: 4.4523 - val_accuracy: 0.4727\n","\n","Epoch 00772: val_accuracy did not improve from 0.63636\n","Epoch 773/1000\n","143/143 [==============================] - 0s 374us/step - loss: 1.9924e-04 - accuracy: 1.0000 - val_loss: 4.5226 - val_accuracy: 0.5091\n","\n","Epoch 00773: val_accuracy did not improve from 0.63636\n","Epoch 774/1000\n","143/143 [==============================] - 0s 374us/step - loss: 0.0080 - accuracy: 0.9930 - val_loss: 4.1820 - val_accuracy: 0.4727\n","\n","Epoch 00774: val_accuracy did not improve from 0.63636\n","Epoch 775/1000\n","143/143 [==============================] - 0s 373us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 3.9998 - val_accuracy: 0.4727\n","\n","Epoch 00775: val_accuracy did not improve from 0.63636\n","Epoch 776/1000\n","143/143 [==============================] - 0s 353us/step - loss: 6.1690e-04 - accuracy: 1.0000 - val_loss: 3.9928 - val_accuracy: 0.4727\n","\n","Epoch 00776: val_accuracy did not improve from 0.63636\n","Epoch 777/1000\n","143/143 [==============================] - 0s 347us/step - loss: 9.5722e-04 - accuracy: 1.0000 - val_loss: 4.1224 - val_accuracy: 0.4727\n","\n","Epoch 00777: val_accuracy did not improve from 0.63636\n","Epoch 778/1000\n","143/143 [==============================] - 0s 366us/step - loss: 8.5287e-04 - accuracy: 1.0000 - val_loss: 4.2973 - val_accuracy: 0.4727\n","\n","Epoch 00778: val_accuracy did not improve from 0.63636\n","Epoch 779/1000\n","143/143 [==============================] - 0s 356us/step - loss: 3.2687e-05 - accuracy: 1.0000 - val_loss: 4.4079 - val_accuracy: 0.4727\n","\n","Epoch 00779: val_accuracy did not improve from 0.63636\n","Epoch 780/1000\n","143/143 [==============================] - 0s 350us/step - loss: 2.3259e-04 - accuracy: 1.0000 - val_loss: 4.5003 - val_accuracy: 0.4727\n","\n","Epoch 00780: val_accuracy did not improve from 0.63636\n","Epoch 781/1000\n","143/143 [==============================] - 0s 353us/step - loss: 0.0051 - accuracy: 0.9930 - val_loss: 4.2438 - val_accuracy: 0.4727\n","\n","Epoch 00781: val_accuracy did not improve from 0.63636\n","Epoch 782/1000\n","143/143 [==============================] - 0s 401us/step - loss: 7.5790e-04 - accuracy: 1.0000 - val_loss: 3.9542 - val_accuracy: 0.4727\n","\n","Epoch 00782: val_accuracy did not improve from 0.63636\n","Epoch 783/1000\n","143/143 [==============================] - 0s 348us/step - loss: 9.6965e-05 - accuracy: 1.0000 - val_loss: 3.8427 - val_accuracy: 0.4727\n","\n","Epoch 00783: val_accuracy did not improve from 0.63636\n","Epoch 784/1000\n","143/143 [==============================] - 0s 373us/step - loss: 0.0082 - accuracy: 0.9930 - val_loss: 4.0865 - val_accuracy: 0.4727\n","\n","Epoch 00784: val_accuracy did not improve from 0.63636\n","Epoch 785/1000\n","143/143 [==============================] - 0s 374us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 4.5580 - val_accuracy: 0.4545\n","\n","Epoch 00785: val_accuracy did not improve from 0.63636\n","Epoch 786/1000\n","143/143 [==============================] - 0s 360us/step - loss: 0.0241 - accuracy: 0.9860 - val_loss: 4.2876 - val_accuracy: 0.4364\n","\n","Epoch 00786: val_accuracy did not improve from 0.63636\n","Epoch 787/1000\n","143/143 [==============================] - 0s 356us/step - loss: 6.7308e-05 - accuracy: 1.0000 - val_loss: 4.2837 - val_accuracy: 0.4364\n","\n","Epoch 00787: val_accuracy did not improve from 0.63636\n","Epoch 788/1000\n","143/143 [==============================] - 0s 338us/step - loss: 3.1707e-04 - accuracy: 1.0000 - val_loss: 4.3029 - val_accuracy: 0.4364\n","\n","Epoch 00788: val_accuracy did not improve from 0.63636\n","Epoch 789/1000\n","143/143 [==============================] - 0s 349us/step - loss: 1.2656e-04 - accuracy: 1.0000 - val_loss: 4.3361 - val_accuracy: 0.4545\n","\n","Epoch 00789: val_accuracy did not improve from 0.63636\n","Epoch 790/1000\n","143/143 [==============================] - 0s 354us/step - loss: 7.6235e-05 - accuracy: 1.0000 - val_loss: 4.3508 - val_accuracy: 0.4545\n","\n","Epoch 00790: val_accuracy did not improve from 0.63636\n","Epoch 791/1000\n","143/143 [==============================] - 0s 346us/step - loss: 2.6269e-04 - accuracy: 1.0000 - val_loss: 4.3782 - val_accuracy: 0.4545\n","\n","Epoch 00791: val_accuracy did not improve from 0.63636\n","Epoch 792/1000\n","143/143 [==============================] - 0s 348us/step - loss: 3.3013e-05 - accuracy: 1.0000 - val_loss: 4.4176 - val_accuracy: 0.4545\n","\n","Epoch 00792: val_accuracy did not improve from 0.63636\n","Epoch 793/1000\n","143/143 [==============================] - 0s 362us/step - loss: 1.7039e-04 - accuracy: 1.0000 - val_loss: 4.4302 - val_accuracy: 0.4545\n","\n","Epoch 00793: val_accuracy did not improve from 0.63636\n","Epoch 794/1000\n","143/143 [==============================] - 0s 357us/step - loss: 1.2138e-04 - accuracy: 1.0000 - val_loss: 4.4339 - val_accuracy: 0.4545\n","\n","Epoch 00794: val_accuracy did not improve from 0.63636\n","Epoch 795/1000\n","143/143 [==============================] - 0s 353us/step - loss: 0.0060 - accuracy: 0.9930 - val_loss: 4.0511 - val_accuracy: 0.4727\n","\n","Epoch 00795: val_accuracy did not improve from 0.63636\n","Epoch 796/1000\n","143/143 [==============================] - 0s 364us/step - loss: 0.0192 - accuracy: 0.9930 - val_loss: 4.2300 - val_accuracy: 0.4727\n","\n","Epoch 00796: val_accuracy did not improve from 0.63636\n","Epoch 797/1000\n","143/143 [==============================] - 0s 342us/step - loss: 0.0256 - accuracy: 0.9930 - val_loss: 3.9647 - val_accuracy: 0.5091\n","\n","Epoch 00797: val_accuracy did not improve from 0.63636\n","Epoch 798/1000\n","143/143 [==============================] - 0s 341us/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 3.4196 - val_accuracy: 0.4909\n","\n","Epoch 00798: val_accuracy did not improve from 0.63636\n","Epoch 799/1000\n","143/143 [==============================] - 0s 347us/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 3.6894 - val_accuracy: 0.4727\n","\n","Epoch 00799: val_accuracy did not improve from 0.63636\n","Epoch 800/1000\n","143/143 [==============================] - 0s 415us/step - loss: 4.3278e-04 - accuracy: 1.0000 - val_loss: 4.3822 - val_accuracy: 0.4909\n","\n","Epoch 00800: val_accuracy did not improve from 0.63636\n","Epoch 801/1000\n","143/143 [==============================] - 0s 347us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 4.7256 - val_accuracy: 0.4727\n","\n","Epoch 00801: val_accuracy did not improve from 0.63636\n","Epoch 802/1000\n","143/143 [==============================] - 0s 385us/step - loss: 3.6537e-04 - accuracy: 1.0000 - val_loss: 4.5335 - val_accuracy: 0.4727\n","\n","Epoch 00802: val_accuracy did not improve from 0.63636\n","Epoch 803/1000\n","143/143 [==============================] - 0s 355us/step - loss: 5.0683e-04 - accuracy: 1.0000 - val_loss: 4.3908 - val_accuracy: 0.4909\n","\n","Epoch 00803: val_accuracy did not improve from 0.63636\n","Epoch 804/1000\n","143/143 [==============================] - 0s 414us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 4.1527 - val_accuracy: 0.4545\n","\n","Epoch 00804: val_accuracy did not improve from 0.63636\n","Epoch 805/1000\n","143/143 [==============================] - 0s 350us/step - loss: 1.6190e-04 - accuracy: 1.0000 - val_loss: 3.9533 - val_accuracy: 0.4545\n","\n","Epoch 00805: val_accuracy did not improve from 0.63636\n","Epoch 806/1000\n","143/143 [==============================] - 0s 356us/step - loss: 0.0184 - accuracy: 0.9930 - val_loss: 3.2961 - val_accuracy: 0.5636\n","\n","Epoch 00806: val_accuracy did not improve from 0.63636\n","Epoch 807/1000\n","143/143 [==============================] - 0s 343us/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 3.3855 - val_accuracy: 0.5273\n","\n","Epoch 00807: val_accuracy did not improve from 0.63636\n","Epoch 808/1000\n","143/143 [==============================] - 0s 347us/step - loss: 9.9537e-04 - accuracy: 1.0000 - val_loss: 3.6891 - val_accuracy: 0.5091\n","\n","Epoch 00808: val_accuracy did not improve from 0.63636\n","Epoch 809/1000\n","143/143 [==============================] - 0s 352us/step - loss: 1.9474e-04 - accuracy: 1.0000 - val_loss: 3.9027 - val_accuracy: 0.4909\n","\n","Epoch 00809: val_accuracy did not improve from 0.63636\n","Epoch 810/1000\n","143/143 [==============================] - 0s 344us/step - loss: 6.3475e-05 - accuracy: 1.0000 - val_loss: 4.0413 - val_accuracy: 0.4909\n","\n","Epoch 00810: val_accuracy did not improve from 0.63636\n","Epoch 811/1000\n","143/143 [==============================] - 0s 354us/step - loss: 3.0936e-05 - accuracy: 1.0000 - val_loss: 4.1265 - val_accuracy: 0.4727\n","\n","Epoch 00811: val_accuracy did not improve from 0.63636\n","Epoch 812/1000\n","143/143 [==============================] - 0s 346us/step - loss: 7.2283e-05 - accuracy: 1.0000 - val_loss: 4.1752 - val_accuracy: 0.4909\n","\n","Epoch 00812: val_accuracy did not improve from 0.63636\n","Epoch 813/1000\n","143/143 [==============================] - 0s 345us/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 3.9291 - val_accuracy: 0.4909\n","\n","Epoch 00813: val_accuracy did not improve from 0.63636\n","Epoch 814/1000\n","143/143 [==============================] - 0s 365us/step - loss: 3.0828e-04 - accuracy: 1.0000 - val_loss: 3.4843 - val_accuracy: 0.5091\n","\n","Epoch 00814: val_accuracy did not improve from 0.63636\n","Epoch 815/1000\n","143/143 [==============================] - 0s 344us/step - loss: 2.4514e-04 - accuracy: 1.0000 - val_loss: 3.3044 - val_accuracy: 0.5273\n","\n","Epoch 00815: val_accuracy did not improve from 0.63636\n","Epoch 816/1000\n","143/143 [==============================] - 0s 349us/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 3.5401 - val_accuracy: 0.5091\n","\n","Epoch 00816: val_accuracy did not improve from 0.63636\n","Epoch 817/1000\n","143/143 [==============================] - 0s 354us/step - loss: 6.8826e-05 - accuracy: 1.0000 - val_loss: 3.7646 - val_accuracy: 0.4727\n","\n","Epoch 00817: val_accuracy did not improve from 0.63636\n","Epoch 818/1000\n","143/143 [==============================] - 0s 349us/step - loss: 1.3353e-04 - accuracy: 1.0000 - val_loss: 3.9313 - val_accuracy: 0.4909\n","\n","Epoch 00818: val_accuracy did not improve from 0.63636\n","Epoch 819/1000\n","143/143 [==============================] - 0s 411us/step - loss: 7.5763e-05 - accuracy: 1.0000 - val_loss: 4.0478 - val_accuracy: 0.4727\n","\n","Epoch 00819: val_accuracy did not improve from 0.63636\n","Epoch 820/1000\n","143/143 [==============================] - 0s 391us/step - loss: 3.5885e-05 - accuracy: 1.0000 - val_loss: 4.1254 - val_accuracy: 0.4727\n","\n","Epoch 00820: val_accuracy did not improve from 0.63636\n","Epoch 821/1000\n","143/143 [==============================] - 0s 350us/step - loss: 2.5408e-05 - accuracy: 1.0000 - val_loss: 4.1732 - val_accuracy: 0.4727\n","\n","Epoch 00821: val_accuracy did not improve from 0.63636\n","Epoch 822/1000\n","143/143 [==============================] - 0s 343us/step - loss: 6.3438e-05 - accuracy: 1.0000 - val_loss: 4.2028 - val_accuracy: 0.4727\n","\n","Epoch 00822: val_accuracy did not improve from 0.63636\n","Epoch 823/1000\n","143/143 [==============================] - 0s 354us/step - loss: 2.4932e-04 - accuracy: 1.0000 - val_loss: 4.1989 - val_accuracy: 0.4727\n","\n","Epoch 00823: val_accuracy did not improve from 0.63636\n","Epoch 824/1000\n","143/143 [==============================] - 0s 347us/step - loss: 3.1954e-04 - accuracy: 1.0000 - val_loss: 4.1617 - val_accuracy: 0.4727\n","\n","Epoch 00824: val_accuracy did not improve from 0.63636\n","Epoch 825/1000\n","143/143 [==============================] - 0s 358us/step - loss: 2.3054e-05 - accuracy: 1.0000 - val_loss: 4.1245 - val_accuracy: 0.4727\n","\n","Epoch 00825: val_accuracy did not improve from 0.63636\n","Epoch 826/1000\n","143/143 [==============================] - 0s 361us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 4.0046 - val_accuracy: 0.4727\n","\n","Epoch 00826: val_accuracy did not improve from 0.63636\n","Epoch 827/1000\n","143/143 [==============================] - 0s 358us/step - loss: 2.8924e-04 - accuracy: 1.0000 - val_loss: 3.9818 - val_accuracy: 0.4727\n","\n","Epoch 00827: val_accuracy did not improve from 0.63636\n","Epoch 828/1000\n","143/143 [==============================] - 0s 344us/step - loss: 4.4540e-04 - accuracy: 1.0000 - val_loss: 4.0232 - val_accuracy: 0.4727\n","\n","Epoch 00828: val_accuracy did not improve from 0.63636\n","Epoch 829/1000\n","143/143 [==============================] - 0s 368us/step - loss: 1.8123e-04 - accuracy: 1.0000 - val_loss: 4.0520 - val_accuracy: 0.4727\n","\n","Epoch 00829: val_accuracy did not improve from 0.63636\n","Epoch 830/1000\n","143/143 [==============================] - 0s 351us/step - loss: 4.8614e-05 - accuracy: 1.0000 - val_loss: 4.0775 - val_accuracy: 0.4727\n","\n","Epoch 00830: val_accuracy did not improve from 0.63636\n","Epoch 831/1000\n","143/143 [==============================] - 0s 350us/step - loss: 7.6473e-04 - accuracy: 1.0000 - val_loss: 4.1334 - val_accuracy: 0.4727\n","\n","Epoch 00831: val_accuracy did not improve from 0.63636\n","Epoch 832/1000\n","143/143 [==============================] - 0s 342us/step - loss: 5.4196e-04 - accuracy: 1.0000 - val_loss: 4.2288 - val_accuracy: 0.4364\n","\n","Epoch 00832: val_accuracy did not improve from 0.63636\n","Epoch 833/1000\n","143/143 [==============================] - 0s 352us/step - loss: 4.4237e-05 - accuracy: 1.0000 - val_loss: 4.2674 - val_accuracy: 0.4364\n","\n","Epoch 00833: val_accuracy did not improve from 0.63636\n","Epoch 834/1000\n","143/143 [==============================] - 0s 350us/step - loss: 6.1182e-05 - accuracy: 1.0000 - val_loss: 4.2949 - val_accuracy: 0.4364\n","\n","Epoch 00834: val_accuracy did not improve from 0.63636\n","Epoch 835/1000\n","143/143 [==============================] - 0s 349us/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 4.4498 - val_accuracy: 0.4364\n","\n","Epoch 00835: val_accuracy did not improve from 0.63636\n","Epoch 836/1000\n","143/143 [==============================] - 0s 364us/step - loss: 2.8912e-04 - accuracy: 1.0000 - val_loss: 4.6046 - val_accuracy: 0.4545\n","\n","Epoch 00836: val_accuracy did not improve from 0.63636\n","Epoch 837/1000\n","143/143 [==============================] - 0s 425us/step - loss: 4.2719e-04 - accuracy: 1.0000 - val_loss: 4.6417 - val_accuracy: 0.4545\n","\n","Epoch 00837: val_accuracy did not improve from 0.63636\n","Epoch 838/1000\n","143/143 [==============================] - 0s 382us/step - loss: 1.7684e-04 - accuracy: 1.0000 - val_loss: 4.6329 - val_accuracy: 0.4545\n","\n","Epoch 00838: val_accuracy did not improve from 0.63636\n","Epoch 839/1000\n","143/143 [==============================] - 0s 392us/step - loss: 6.5497e-04 - accuracy: 1.0000 - val_loss: 4.5651 - val_accuracy: 0.4545\n","\n","Epoch 00839: val_accuracy did not improve from 0.63636\n","Epoch 840/1000\n","143/143 [==============================] - 0s 359us/step - loss: 1.7571e-05 - accuracy: 1.0000 - val_loss: 4.4686 - val_accuracy: 0.4364\n","\n","Epoch 00840: val_accuracy did not improve from 0.63636\n","Epoch 841/1000\n","143/143 [==============================] - 0s 348us/step - loss: 2.4648e-04 - accuracy: 1.0000 - val_loss: 4.3934 - val_accuracy: 0.4364\n","\n","Epoch 00841: val_accuracy did not improve from 0.63636\n","Epoch 842/1000\n","143/143 [==============================] - 0s 342us/step - loss: 2.9204e-04 - accuracy: 1.0000 - val_loss: 4.3070 - val_accuracy: 0.4364\n","\n","Epoch 00842: val_accuracy did not improve from 0.63636\n","Epoch 843/1000\n","143/143 [==============================] - 0s 356us/step - loss: 2.0822e-04 - accuracy: 1.0000 - val_loss: 4.2647 - val_accuracy: 0.4364\n","\n","Epoch 00843: val_accuracy did not improve from 0.63636\n","Epoch 844/1000\n","143/143 [==============================] - 0s 356us/step - loss: 1.0193e-04 - accuracy: 1.0000 - val_loss: 4.2447 - val_accuracy: 0.4364\n","\n","Epoch 00844: val_accuracy did not improve from 0.63636\n","Epoch 845/1000\n","143/143 [==============================] - 0s 353us/step - loss: 3.5401e-05 - accuracy: 1.0000 - val_loss: 4.2321 - val_accuracy: 0.4364\n","\n","Epoch 00845: val_accuracy did not improve from 0.63636\n","Epoch 846/1000\n","143/143 [==============================] - 0s 340us/step - loss: 2.4104e-04 - accuracy: 1.0000 - val_loss: 4.2115 - val_accuracy: 0.4545\n","\n","Epoch 00846: val_accuracy did not improve from 0.63636\n","Epoch 847/1000\n","143/143 [==============================] - 0s 359us/step - loss: 4.5153e-05 - accuracy: 1.0000 - val_loss: 4.1927 - val_accuracy: 0.4545\n","\n","Epoch 00847: val_accuracy did not improve from 0.63636\n","Epoch 848/1000\n","143/143 [==============================] - 0s 382us/step - loss: 3.0990e-04 - accuracy: 1.0000 - val_loss: 4.1557 - val_accuracy: 0.4545\n","\n","Epoch 00848: val_accuracy did not improve from 0.63636\n","Epoch 849/1000\n","143/143 [==============================] - 0s 349us/step - loss: 1.6997e-04 - accuracy: 1.0000 - val_loss: 4.1072 - val_accuracy: 0.4727\n","\n","Epoch 00849: val_accuracy did not improve from 0.63636\n","Epoch 850/1000\n","143/143 [==============================] - 0s 353us/step - loss: 1.5246e-04 - accuracy: 1.0000 - val_loss: 4.0920 - val_accuracy: 0.4727\n","\n","Epoch 00850: val_accuracy did not improve from 0.63636\n","Epoch 851/1000\n","143/143 [==============================] - 0s 345us/step - loss: 4.5901e-04 - accuracy: 1.0000 - val_loss: 4.0585 - val_accuracy: 0.4727\n","\n","Epoch 00851: val_accuracy did not improve from 0.63636\n","Epoch 852/1000\n","143/143 [==============================] - 0s 355us/step - loss: 4.8186e-04 - accuracy: 1.0000 - val_loss: 4.0850 - val_accuracy: 0.4727\n","\n","Epoch 00852: val_accuracy did not improve from 0.63636\n","Epoch 853/1000\n","143/143 [==============================] - 0s 350us/step - loss: 2.0928e-04 - accuracy: 1.0000 - val_loss: 4.1368 - val_accuracy: 0.4727\n","\n","Epoch 00853: val_accuracy did not improve from 0.63636\n","Epoch 854/1000\n","143/143 [==============================] - 0s 342us/step - loss: 5.2069e-05 - accuracy: 1.0000 - val_loss: 4.1770 - val_accuracy: 0.4545\n","\n","Epoch 00854: val_accuracy did not improve from 0.63636\n","Epoch 855/1000\n","143/143 [==============================] - 0s 402us/step - loss: 0.0087 - accuracy: 0.9930 - val_loss: 3.9343 - val_accuracy: 0.5091\n","\n","Epoch 00855: val_accuracy did not improve from 0.63636\n","Epoch 856/1000\n","143/143 [==============================] - 0s 353us/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 3.5580 - val_accuracy: 0.5455\n","\n","Epoch 00856: val_accuracy did not improve from 0.63636\n","Epoch 857/1000\n","143/143 [==============================] - 0s 400us/step - loss: 0.0109 - accuracy: 0.9930 - val_loss: 3.9659 - val_accuracy: 0.5091\n","\n","Epoch 00857: val_accuracy did not improve from 0.63636\n","Epoch 858/1000\n","143/143 [==============================] - 0s 338us/step - loss: 5.5319e-05 - accuracy: 1.0000 - val_loss: 4.6424 - val_accuracy: 0.4545\n","\n","Epoch 00858: val_accuracy did not improve from 0.63636\n","Epoch 859/1000\n","143/143 [==============================] - 0s 343us/step - loss: 8.6219e-04 - accuracy: 1.0000 - val_loss: 5.0250 - val_accuracy: 0.4364\n","\n","Epoch 00859: val_accuracy did not improve from 0.63636\n","Epoch 860/1000\n","143/143 [==============================] - 0s 351us/step - loss: 1.5766e-04 - accuracy: 1.0000 - val_loss: 5.1944 - val_accuracy: 0.4182\n","\n","Epoch 00860: val_accuracy did not improve from 0.63636\n","Epoch 861/1000\n","143/143 [==============================] - 0s 344us/step - loss: 5.7275e-04 - accuracy: 1.0000 - val_loss: 5.2244 - val_accuracy: 0.4182\n","\n","Epoch 00861: val_accuracy did not improve from 0.63636\n","Epoch 862/1000\n","143/143 [==============================] - 0s 343us/step - loss: 0.0097 - accuracy: 0.9930 - val_loss: 4.4054 - val_accuracy: 0.4909\n","\n","Epoch 00862: val_accuracy did not improve from 0.63636\n","Epoch 863/1000\n","143/143 [==============================] - 0s 350us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 3.6319 - val_accuracy: 0.5455\n","\n","Epoch 00863: val_accuracy did not improve from 0.63636\n","Epoch 864/1000\n","143/143 [==============================] - 0s 358us/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 3.6038 - val_accuracy: 0.5455\n","\n","Epoch 00864: val_accuracy did not improve from 0.63636\n","Epoch 865/1000\n","143/143 [==============================] - 0s 340us/step - loss: 5.1827e-04 - accuracy: 1.0000 - val_loss: 3.6454 - val_accuracy: 0.5455\n","\n","Epoch 00865: val_accuracy did not improve from 0.63636\n","Epoch 866/1000\n","143/143 [==============================] - 0s 370us/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 3.8512 - val_accuracy: 0.4909\n","\n","Epoch 00866: val_accuracy did not improve from 0.63636\n","Epoch 867/1000\n","143/143 [==============================] - 0s 346us/step - loss: 9.3727e-04 - accuracy: 1.0000 - val_loss: 4.2074 - val_accuracy: 0.5091\n","\n","Epoch 00867: val_accuracy did not improve from 0.63636\n","Epoch 868/1000\n","143/143 [==============================] - 0s 346us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 4.6404 - val_accuracy: 0.4545\n","\n","Epoch 00868: val_accuracy did not improve from 0.63636\n","Epoch 869/1000\n","143/143 [==============================] - 0s 352us/step - loss: 5.1699e-04 - accuracy: 1.0000 - val_loss: 4.9393 - val_accuracy: 0.4182\n","\n","Epoch 00869: val_accuracy did not improve from 0.63636\n","Epoch 870/1000\n","143/143 [==============================] - 0s 348us/step - loss: 0.0220 - accuracy: 0.9930 - val_loss: 4.1795 - val_accuracy: 0.4909\n","\n","Epoch 00870: val_accuracy did not improve from 0.63636\n","Epoch 871/1000\n","143/143 [==============================] - 0s 341us/step - loss: 8.0149e-05 - accuracy: 1.0000 - val_loss: 3.5461 - val_accuracy: 0.5455\n","\n","Epoch 00871: val_accuracy did not improve from 0.63636\n","Epoch 872/1000\n","143/143 [==============================] - 0s 343us/step - loss: 7.9642e-04 - accuracy: 1.0000 - val_loss: 3.3915 - val_accuracy: 0.5455\n","\n","Epoch 00872: val_accuracy did not improve from 0.63636\n","Epoch 873/1000\n","143/143 [==============================] - 0s 351us/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 3.4527 - val_accuracy: 0.5455\n","\n","Epoch 00873: val_accuracy did not improve from 0.63636\n","Epoch 874/1000\n","143/143 [==============================] - 0s 423us/step - loss: 0.0115 - accuracy: 0.9930 - val_loss: 4.6490 - val_accuracy: 0.4364\n","\n","Epoch 00874: val_accuracy did not improve from 0.63636\n","Epoch 875/1000\n","143/143 [==============================] - 0s 431us/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 5.5941 - val_accuracy: 0.3818\n","\n","Epoch 00875: val_accuracy did not improve from 0.63636\n","Epoch 876/1000\n","143/143 [==============================] - 0s 352us/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 5.1231 - val_accuracy: 0.3818\n","\n","Epoch 00876: val_accuracy did not improve from 0.63636\n","Epoch 877/1000\n","143/143 [==============================] - 0s 352us/step - loss: 7.2368e-04 - accuracy: 1.0000 - val_loss: 4.7332 - val_accuracy: 0.4000\n","\n","Epoch 00877: val_accuracy did not improve from 0.63636\n","Epoch 878/1000\n","143/143 [==============================] - 0s 351us/step - loss: 1.2468e-05 - accuracy: 1.0000 - val_loss: 4.4486 - val_accuracy: 0.4727\n","\n","Epoch 00878: val_accuracy did not improve from 0.63636\n","Epoch 879/1000\n","143/143 [==============================] - 0s 348us/step - loss: 6.7166e-04 - accuracy: 1.0000 - val_loss: 4.3264 - val_accuracy: 0.5273\n","\n","Epoch 00879: val_accuracy did not improve from 0.63636\n","Epoch 880/1000\n","143/143 [==============================] - 0s 353us/step - loss: 5.0636e-04 - accuracy: 1.0000 - val_loss: 4.3391 - val_accuracy: 0.5273\n","\n","Epoch 00880: val_accuracy did not improve from 0.63636\n","Epoch 881/1000\n","143/143 [==============================] - 0s 346us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 4.4792 - val_accuracy: 0.4727\n","\n","Epoch 00881: val_accuracy did not improve from 0.63636\n","Epoch 882/1000\n","143/143 [==============================] - 0s 348us/step - loss: 5.8184e-05 - accuracy: 1.0000 - val_loss: 4.6574 - val_accuracy: 0.4364\n","\n","Epoch 00882: val_accuracy did not improve from 0.63636\n","Epoch 883/1000\n","143/143 [==============================] - 0s 348us/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 4.5048 - val_accuracy: 0.4364\n","\n","Epoch 00883: val_accuracy did not improve from 0.63636\n","Epoch 884/1000\n","143/143 [==============================] - 0s 372us/step - loss: 2.1349e-05 - accuracy: 1.0000 - val_loss: 4.3008 - val_accuracy: 0.5273\n","\n","Epoch 00884: val_accuracy did not improve from 0.63636\n","Epoch 885/1000\n","143/143 [==============================] - 0s 352us/step - loss: 9.4591e-04 - accuracy: 1.0000 - val_loss: 4.2635 - val_accuracy: 0.5273\n","\n","Epoch 00885: val_accuracy did not improve from 0.63636\n","Epoch 886/1000\n","143/143 [==============================] - 0s 363us/step - loss: 2.9408e-05 - accuracy: 1.0000 - val_loss: 4.2631 - val_accuracy: 0.5273\n","\n","Epoch 00886: val_accuracy did not improve from 0.63636\n","Epoch 887/1000\n","143/143 [==============================] - 0s 345us/step - loss: 5.2491e-04 - accuracy: 1.0000 - val_loss: 4.2910 - val_accuracy: 0.4909\n","\n","Epoch 00887: val_accuracy did not improve from 0.63636\n","Epoch 888/1000\n","143/143 [==============================] - 0s 350us/step - loss: 3.1267e-05 - accuracy: 1.0000 - val_loss: 4.3451 - val_accuracy: 0.4545\n","\n","Epoch 00888: val_accuracy did not improve from 0.63636\n","Epoch 889/1000\n","143/143 [==============================] - 0s 349us/step - loss: 2.6633e-05 - accuracy: 1.0000 - val_loss: 4.3807 - val_accuracy: 0.4545\n","\n","Epoch 00889: val_accuracy did not improve from 0.63636\n","Epoch 890/1000\n","143/143 [==============================] - 0s 352us/step - loss: 1.1027e-04 - accuracy: 1.0000 - val_loss: 4.3925 - val_accuracy: 0.4364\n","\n","Epoch 00890: val_accuracy did not improve from 0.63636\n","Epoch 891/1000\n","143/143 [==============================] - 0s 352us/step - loss: 3.0857e-05 - accuracy: 1.0000 - val_loss: 4.3968 - val_accuracy: 0.4364\n","\n","Epoch 00891: val_accuracy did not improve from 0.63636\n","Epoch 892/1000\n","143/143 [==============================] - 0s 383us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 4.2422 - val_accuracy: 0.5091\n","\n","Epoch 00892: val_accuracy did not improve from 0.63636\n","Epoch 893/1000\n","143/143 [==============================] - 0s 407us/step - loss: 1.1194e-04 - accuracy: 1.0000 - val_loss: 4.0990 - val_accuracy: 0.5091\n","\n","Epoch 00893: val_accuracy did not improve from 0.63636\n","Epoch 894/1000\n","143/143 [==============================] - 0s 345us/step - loss: 7.7207e-04 - accuracy: 1.0000 - val_loss: 4.0820 - val_accuracy: 0.5273\n","\n","Epoch 00894: val_accuracy did not improve from 0.63636\n","Epoch 895/1000\n","143/143 [==============================] - 0s 366us/step - loss: 1.6317e-04 - accuracy: 1.0000 - val_loss: 4.0938 - val_accuracy: 0.5273\n","\n","Epoch 00895: val_accuracy did not improve from 0.63636\n","Epoch 896/1000\n","143/143 [==============================] - 0s 358us/step - loss: 2.5205e-04 - accuracy: 1.0000 - val_loss: 4.1249 - val_accuracy: 0.4909\n","\n","Epoch 00896: val_accuracy did not improve from 0.63636\n","Epoch 897/1000\n","143/143 [==============================] - 0s 351us/step - loss: 1.2027e-04 - accuracy: 1.0000 - val_loss: 4.1627 - val_accuracy: 0.4909\n","\n","Epoch 00897: val_accuracy did not improve from 0.63636\n","Epoch 898/1000\n","143/143 [==============================] - 0s 362us/step - loss: 1.6915e-04 - accuracy: 1.0000 - val_loss: 4.2002 - val_accuracy: 0.4727\n","\n","Epoch 00898: val_accuracy did not improve from 0.63636\n","Epoch 899/1000\n","143/143 [==============================] - 0s 351us/step - loss: 8.1860e-04 - accuracy: 1.0000 - val_loss: 4.3407 - val_accuracy: 0.4727\n","\n","Epoch 00899: val_accuracy did not improve from 0.63636\n","Epoch 900/1000\n","143/143 [==============================] - 0s 345us/step - loss: 4.6530e-05 - accuracy: 1.0000 - val_loss: 4.4584 - val_accuracy: 0.4545\n","\n","Epoch 00900: val_accuracy did not improve from 0.63636\n","Epoch 901/1000\n","143/143 [==============================] - 0s 350us/step - loss: 2.4553e-04 - accuracy: 1.0000 - val_loss: 4.5181 - val_accuracy: 0.4545\n","\n","Epoch 00901: val_accuracy did not improve from 0.63636\n","Epoch 902/1000\n","143/143 [==============================] - 0s 344us/step - loss: 7.7612e-05 - accuracy: 1.0000 - val_loss: 4.5264 - val_accuracy: 0.4545\n","\n","Epoch 00902: val_accuracy did not improve from 0.63636\n","Epoch 903/1000\n","143/143 [==============================] - 0s 391us/step - loss: 8.2285e-04 - accuracy: 1.0000 - val_loss: 4.4577 - val_accuracy: 0.4545\n","\n","Epoch 00903: val_accuracy did not improve from 0.63636\n","Epoch 904/1000\n","143/143 [==============================] - 0s 371us/step - loss: 1.8341e-04 - accuracy: 1.0000 - val_loss: 4.2635 - val_accuracy: 0.4727\n","\n","Epoch 00904: val_accuracy did not improve from 0.63636\n","Epoch 905/1000\n","143/143 [==============================] - 0s 356us/step - loss: 4.5916e-05 - accuracy: 1.0000 - val_loss: 4.1599 - val_accuracy: 0.4909\n","\n","Epoch 00905: val_accuracy did not improve from 0.63636\n","Epoch 906/1000\n","143/143 [==============================] - 0s 348us/step - loss: 7.3576e-05 - accuracy: 1.0000 - val_loss: 4.1094 - val_accuracy: 0.5091\n","\n","Epoch 00906: val_accuracy did not improve from 0.63636\n","Epoch 907/1000\n","143/143 [==============================] - 0s 349us/step - loss: 0.0064 - accuracy: 0.9930 - val_loss: 4.5156 - val_accuracy: 0.4364\n","\n","Epoch 00907: val_accuracy did not improve from 0.63636\n","Epoch 908/1000\n","143/143 [==============================] - 0s 355us/step - loss: 3.4903e-05 - accuracy: 1.0000 - val_loss: 5.1064 - val_accuracy: 0.3636\n","\n","Epoch 00908: val_accuracy did not improve from 0.63636\n","Epoch 909/1000\n","143/143 [==============================] - 0s 354us/step - loss: 6.4195e-04 - accuracy: 1.0000 - val_loss: 5.3755 - val_accuracy: 0.3636\n","\n","Epoch 00909: val_accuracy did not improve from 0.63636\n","Epoch 910/1000\n","143/143 [==============================] - 0s 409us/step - loss: 0.0127 - accuracy: 0.9930 - val_loss: 4.0775 - val_accuracy: 0.4727\n","\n","Epoch 00910: val_accuracy did not improve from 0.63636\n","Epoch 911/1000\n","143/143 [==============================] - 0s 389us/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 3.7173 - val_accuracy: 0.5091\n","\n","Epoch 00911: val_accuracy did not improve from 0.63636\n","Epoch 912/1000\n","143/143 [==============================] - 0s 379us/step - loss: 3.1396e-04 - accuracy: 1.0000 - val_loss: 3.6561 - val_accuracy: 0.5091\n","\n","Epoch 00912: val_accuracy did not improve from 0.63636\n","Epoch 913/1000\n","143/143 [==============================] - 0s 362us/step - loss: 4.8289e-04 - accuracy: 1.0000 - val_loss: 3.6593 - val_accuracy: 0.5273\n","\n","Epoch 00913: val_accuracy did not improve from 0.63636\n","Epoch 914/1000\n","143/143 [==============================] - 0s 349us/step - loss: 0.0054 - accuracy: 0.9930 - val_loss: 3.9444 - val_accuracy: 0.4909\n","\n","Epoch 00914: val_accuracy did not improve from 0.63636\n","Epoch 915/1000\n","143/143 [==============================] - 0s 342us/step - loss: 1.0483e-04 - accuracy: 1.0000 - val_loss: 4.5546 - val_accuracy: 0.4000\n","\n","Epoch 00915: val_accuracy did not improve from 0.63636\n","Epoch 916/1000\n","143/143 [==============================] - 0s 348us/step - loss: 5.9191e-05 - accuracy: 1.0000 - val_loss: 4.9723 - val_accuracy: 0.3818\n","\n","Epoch 00916: val_accuracy did not improve from 0.63636\n","Epoch 917/1000\n","143/143 [==============================] - 0s 348us/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 4.7533 - val_accuracy: 0.4000\n","\n","Epoch 00917: val_accuracy did not improve from 0.63636\n","Epoch 918/1000\n","143/143 [==============================] - 0s 351us/step - loss: 1.0014e-04 - accuracy: 1.0000 - val_loss: 4.5151 - val_accuracy: 0.4000\n","\n","Epoch 00918: val_accuracy did not improve from 0.63636\n","Epoch 919/1000\n","143/143 [==============================] - 0s 354us/step - loss: 3.7452e-05 - accuracy: 1.0000 - val_loss: 4.3745 - val_accuracy: 0.4364\n","\n","Epoch 00919: val_accuracy did not improve from 0.63636\n","Epoch 920/1000\n","143/143 [==============================] - 0s 346us/step - loss: 1.5983e-04 - accuracy: 1.0000 - val_loss: 4.2830 - val_accuracy: 0.4545\n","\n","Epoch 00920: val_accuracy did not improve from 0.63636\n","Epoch 921/1000\n","143/143 [==============================] - 0s 350us/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 3.5211 - val_accuracy: 0.5273\n","\n","Epoch 00921: val_accuracy did not improve from 0.63636\n","Epoch 922/1000\n","143/143 [==============================] - 0s 354us/step - loss: 0.0225 - accuracy: 0.9930 - val_loss: 3.6238 - val_accuracy: 0.5091\n","\n","Epoch 00922: val_accuracy did not improve from 0.63636\n","Epoch 923/1000\n","143/143 [==============================] - 0s 352us/step - loss: 3.4468e-04 - accuracy: 1.0000 - val_loss: 4.6597 - val_accuracy: 0.4182\n","\n","Epoch 00923: val_accuracy did not improve from 0.63636\n","Epoch 924/1000\n","143/143 [==============================] - 0s 357us/step - loss: 4.6020e-04 - accuracy: 1.0000 - val_loss: 5.4020 - val_accuracy: 0.4000\n","\n","Epoch 00924: val_accuracy did not improve from 0.63636\n","Epoch 925/1000\n","143/143 [==============================] - 0s 343us/step - loss: 5.8300e-04 - accuracy: 1.0000 - val_loss: 5.6902 - val_accuracy: 0.4000\n","\n","Epoch 00925: val_accuracy did not improve from 0.63636\n","Epoch 926/1000\n","143/143 [==============================] - 0s 344us/step - loss: 0.0122 - accuracy: 0.9930 - val_loss: 5.1632 - val_accuracy: 0.3636\n","\n","Epoch 00926: val_accuracy did not improve from 0.63636\n","Epoch 927/1000\n","143/143 [==============================] - 0s 347us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 4.2314 - val_accuracy: 0.4909\n","\n","Epoch 00927: val_accuracy did not improve from 0.63636\n","Epoch 928/1000\n","143/143 [==============================] - 0s 366us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 4.0655 - val_accuracy: 0.5273\n","\n","Epoch 00928: val_accuracy did not improve from 0.63636\n","Epoch 929/1000\n","143/143 [==============================] - 0s 426us/step - loss: 0.0095 - accuracy: 0.9930 - val_loss: 4.7728 - val_accuracy: 0.4545\n","\n","Epoch 00929: val_accuracy did not improve from 0.63636\n","Epoch 930/1000\n","143/143 [==============================] - 0s 374us/step - loss: 4.6666e-04 - accuracy: 1.0000 - val_loss: 5.4748 - val_accuracy: 0.4000\n","\n","Epoch 00930: val_accuracy did not improve from 0.63636\n","Epoch 931/1000\n","143/143 [==============================] - 0s 348us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 5.6051 - val_accuracy: 0.3818\n","\n","Epoch 00931: val_accuracy did not improve from 0.63636\n","Epoch 932/1000\n","143/143 [==============================] - 0s 352us/step - loss: 0.0234 - accuracy: 0.9930 - val_loss: 4.2396 - val_accuracy: 0.5273\n","\n","Epoch 00932: val_accuracy did not improve from 0.63636\n","Epoch 933/1000\n","143/143 [==============================] - 0s 349us/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 3.6186 - val_accuracy: 0.5455\n","\n","Epoch 00933: val_accuracy did not improve from 0.63636\n","Epoch 934/1000\n","143/143 [==============================] - 0s 349us/step - loss: 9.5913e-04 - accuracy: 1.0000 - val_loss: 3.5739 - val_accuracy: 0.5636\n","\n","Epoch 00934: val_accuracy did not improve from 0.63636\n","Epoch 935/1000\n","143/143 [==============================] - 0s 340us/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 4.2264 - val_accuracy: 0.4545\n","\n","Epoch 00935: val_accuracy did not improve from 0.63636\n","Epoch 936/1000\n","143/143 [==============================] - 0s 348us/step - loss: 9.7373e-04 - accuracy: 1.0000 - val_loss: 4.6694 - val_accuracy: 0.4000\n","\n","Epoch 00936: val_accuracy did not improve from 0.63636\n","Epoch 937/1000\n","143/143 [==============================] - 0s 346us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 4.6750 - val_accuracy: 0.4000\n","\n","Epoch 00937: val_accuracy did not improve from 0.63636\n","Epoch 938/1000\n","143/143 [==============================] - 0s 348us/step - loss: 8.1950e-04 - accuracy: 1.0000 - val_loss: 4.4879 - val_accuracy: 0.4364\n","\n","Epoch 00938: val_accuracy did not improve from 0.63636\n","Epoch 939/1000\n","143/143 [==============================] - 0s 360us/step - loss: 1.5025e-04 - accuracy: 1.0000 - val_loss: 4.4235 - val_accuracy: 0.4364\n","\n","Epoch 00939: val_accuracy did not improve from 0.63636\n","Epoch 940/1000\n","143/143 [==============================] - 0s 350us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 4.5259 - val_accuracy: 0.4364\n","\n","Epoch 00940: val_accuracy did not improve from 0.63636\n","Epoch 941/1000\n","143/143 [==============================] - 0s 367us/step - loss: 1.3011e-04 - accuracy: 1.0000 - val_loss: 4.6568 - val_accuracy: 0.4000\n","\n","Epoch 00941: val_accuracy did not improve from 0.63636\n","Epoch 942/1000\n","143/143 [==============================] - 0s 352us/step - loss: 1.1441e-04 - accuracy: 1.0000 - val_loss: 4.7160 - val_accuracy: 0.4000\n","\n","Epoch 00942: val_accuracy did not improve from 0.63636\n","Epoch 943/1000\n","143/143 [==============================] - 0s 355us/step - loss: 4.6404e-05 - accuracy: 1.0000 - val_loss: 4.7323 - val_accuracy: 0.4000\n","\n","Epoch 00943: val_accuracy did not improve from 0.63636\n","Epoch 944/1000\n","143/143 [==============================] - 0s 350us/step - loss: 6.7603e-05 - accuracy: 1.0000 - val_loss: 4.7381 - val_accuracy: 0.4000\n","\n","Epoch 00944: val_accuracy did not improve from 0.63636\n","Epoch 945/1000\n","143/143 [==============================] - 0s 361us/step - loss: 0.0074 - accuracy: 0.9930 - val_loss: 4.0884 - val_accuracy: 0.4545\n","\n","Epoch 00945: val_accuracy did not improve from 0.63636\n","Epoch 946/1000\n","143/143 [==============================] - 0s 362us/step - loss: 7.1569e-04 - accuracy: 1.0000 - val_loss: 3.5722 - val_accuracy: 0.5273\n","\n","Epoch 00946: val_accuracy did not improve from 0.63636\n","Epoch 947/1000\n","143/143 [==============================] - 0s 396us/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 3.5998 - val_accuracy: 0.5273\n","\n","Epoch 00947: val_accuracy did not improve from 0.63636\n","Epoch 948/1000\n","143/143 [==============================] - 0s 356us/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 3.8522 - val_accuracy: 0.4909\n","\n","Epoch 00948: val_accuracy did not improve from 0.63636\n","Epoch 949/1000\n","143/143 [==============================] - 0s 336us/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 4.4921 - val_accuracy: 0.4182\n","\n","Epoch 00949: val_accuracy did not improve from 0.63636\n","Epoch 950/1000\n","143/143 [==============================] - 0s 354us/step - loss: 5.4257e-04 - accuracy: 1.0000 - val_loss: 5.1971 - val_accuracy: 0.4000\n","\n","Epoch 00950: val_accuracy did not improve from 0.63636\n","Epoch 951/1000\n","143/143 [==============================] - 0s 345us/step - loss: 1.0117e-04 - accuracy: 1.0000 - val_loss: 5.5523 - val_accuracy: 0.4000\n","\n","Epoch 00951: val_accuracy did not improve from 0.63636\n","Epoch 952/1000\n","143/143 [==============================] - 0s 369us/step - loss: 6.0872e-04 - accuracy: 1.0000 - val_loss: 5.6413 - val_accuracy: 0.4182\n","\n","Epoch 00952: val_accuracy did not improve from 0.63636\n","Epoch 953/1000\n","143/143 [==============================] - 0s 347us/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 4.7040 - val_accuracy: 0.4182\n","\n","Epoch 00953: val_accuracy did not improve from 0.63636\n","Epoch 954/1000\n","143/143 [==============================] - 0s 345us/step - loss: 0.0172 - accuracy: 0.9930 - val_loss: 3.2065 - val_accuracy: 0.6182\n","\n","Epoch 00954: val_accuracy did not improve from 0.63636\n","Epoch 955/1000\n","143/143 [==============================] - 0s 337us/step - loss: 0.0182 - accuracy: 0.9930 - val_loss: 3.3651 - val_accuracy: 0.5636\n","\n","Epoch 00955: val_accuracy did not improve from 0.63636\n","Epoch 956/1000\n","143/143 [==============================] - 0s 344us/step - loss: 2.7116e-04 - accuracy: 1.0000 - val_loss: 3.8189 - val_accuracy: 0.5091\n","\n","Epoch 00956: val_accuracy did not improve from 0.63636\n","Epoch 957/1000\n","143/143 [==============================] - 0s 346us/step - loss: 1.4107e-04 - accuracy: 1.0000 - val_loss: 4.3120 - val_accuracy: 0.4364\n","\n","Epoch 00957: val_accuracy did not improve from 0.63636\n","Epoch 958/1000\n","143/143 [==============================] - 0s 348us/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 4.1655 - val_accuracy: 0.4364\n","\n","Epoch 00958: val_accuracy did not improve from 0.63636\n","Epoch 959/1000\n","143/143 [==============================] - 0s 337us/step - loss: 0.0068 - accuracy: 0.9930 - val_loss: 3.6092 - val_accuracy: 0.5273\n","\n","Epoch 00959: val_accuracy did not improve from 0.63636\n","Epoch 960/1000\n","143/143 [==============================] - 0s 343us/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 3.5631 - val_accuracy: 0.5636\n","\n","Epoch 00960: val_accuracy did not improve from 0.63636\n","Epoch 961/1000\n","143/143 [==============================] - 0s 349us/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 3.7410 - val_accuracy: 0.4727\n","\n","Epoch 00961: val_accuracy did not improve from 0.63636\n","Epoch 962/1000\n","143/143 [==============================] - 0s 346us/step - loss: 6.0310e-04 - accuracy: 1.0000 - val_loss: 4.1715 - val_accuracy: 0.4909\n","\n","Epoch 00962: val_accuracy did not improve from 0.63636\n","Epoch 963/1000\n","143/143 [==============================] - 0s 361us/step - loss: 9.4857e-05 - accuracy: 1.0000 - val_loss: 4.5243 - val_accuracy: 0.4545\n","\n","Epoch 00963: val_accuracy did not improve from 0.63636\n","Epoch 964/1000\n","143/143 [==============================] - 0s 374us/step - loss: 1.0514e-04 - accuracy: 1.0000 - val_loss: 4.7472 - val_accuracy: 0.3818\n","\n","Epoch 00964: val_accuracy did not improve from 0.63636\n","Epoch 965/1000\n","143/143 [==============================] - 0s 479us/step - loss: 7.2814e-05 - accuracy: 1.0000 - val_loss: 4.8860 - val_accuracy: 0.3818\n","\n","Epoch 00965: val_accuracy did not improve from 0.63636\n","Epoch 966/1000\n","143/143 [==============================] - 0s 435us/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 4.8068 - val_accuracy: 0.3818\n","\n","Epoch 00966: val_accuracy did not improve from 0.63636\n","Epoch 967/1000\n","143/143 [==============================] - 0s 380us/step - loss: 7.4409e-05 - accuracy: 1.0000 - val_loss: 4.6762 - val_accuracy: 0.4182\n","\n","Epoch 00967: val_accuracy did not improve from 0.63636\n","Epoch 968/1000\n","143/143 [==============================] - 0s 347us/step - loss: 2.5412e-04 - accuracy: 1.0000 - val_loss: 4.5705 - val_accuracy: 0.4364\n","\n","Epoch 00968: val_accuracy did not improve from 0.63636\n","Epoch 969/1000\n","143/143 [==============================] - 0s 349us/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 4.2652 - val_accuracy: 0.4909\n","\n","Epoch 00969: val_accuracy did not improve from 0.63636\n","Epoch 970/1000\n","143/143 [==============================] - 0s 349us/step - loss: 3.5253e-04 - accuracy: 1.0000 - val_loss: 4.0828 - val_accuracy: 0.4909\n","\n","Epoch 00970: val_accuracy did not improve from 0.63636\n","Epoch 971/1000\n","143/143 [==============================] - 0s 347us/step - loss: 2.6430e-04 - accuracy: 1.0000 - val_loss: 4.0614 - val_accuracy: 0.4909\n","\n","Epoch 00971: val_accuracy did not improve from 0.63636\n","Epoch 972/1000\n","143/143 [==============================] - 0s 347us/step - loss: 1.7352e-04 - accuracy: 1.0000 - val_loss: 4.0617 - val_accuracy: 0.4909\n","\n","Epoch 00972: val_accuracy did not improve from 0.63636\n","Epoch 973/1000\n","143/143 [==============================] - 0s 344us/step - loss: 1.7821e-04 - accuracy: 1.0000 - val_loss: 4.0703 - val_accuracy: 0.4909\n","\n","Epoch 00973: val_accuracy did not improve from 0.63636\n","Epoch 974/1000\n","143/143 [==============================] - 0s 347us/step - loss: 2.9637e-04 - accuracy: 1.0000 - val_loss: 4.1360 - val_accuracy: 0.4909\n","\n","Epoch 00974: val_accuracy did not improve from 0.63636\n","Epoch 975/1000\n","143/143 [==============================] - 0s 370us/step - loss: 5.9889e-05 - accuracy: 1.0000 - val_loss: 4.1834 - val_accuracy: 0.4909\n","\n","Epoch 00975: val_accuracy did not improve from 0.63636\n","Epoch 976/1000\n","143/143 [==============================] - 0s 352us/step - loss: 0.0068 - accuracy: 0.9930 - val_loss: 5.0828 - val_accuracy: 0.4000\n","\n","Epoch 00976: val_accuracy did not improve from 0.63636\n","Epoch 977/1000\n","143/143 [==============================] - 0s 378us/step - loss: 1.2816e-04 - accuracy: 1.0000 - val_loss: 5.6879 - val_accuracy: 0.4182\n","\n","Epoch 00977: val_accuracy did not improve from 0.63636\n","Epoch 978/1000\n","143/143 [==============================] - 0s 370us/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 5.3415 - val_accuracy: 0.4182\n","\n","Epoch 00978: val_accuracy did not improve from 0.63636\n","Epoch 979/1000\n","143/143 [==============================] - 0s 343us/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 3.7367 - val_accuracy: 0.5273\n","\n","Epoch 00979: val_accuracy did not improve from 0.63636\n","Epoch 980/1000\n","143/143 [==============================] - 0s 351us/step - loss: 3.7373e-04 - accuracy: 1.0000 - val_loss: 3.5508 - val_accuracy: 0.5455\n","\n","Epoch 00980: val_accuracy did not improve from 0.63636\n","Epoch 981/1000\n","143/143 [==============================] - 0s 351us/step - loss: 0.0256 - accuracy: 0.9860 - val_loss: 4.6566 - val_accuracy: 0.4727\n","\n","Epoch 00981: val_accuracy did not improve from 0.63636\n","Epoch 982/1000\n","143/143 [==============================] - 0s 347us/step - loss: 5.0506e-04 - accuracy: 1.0000 - val_loss: 6.5716 - val_accuracy: 0.4000\n","\n","Epoch 00982: val_accuracy did not improve from 0.63636\n","Epoch 983/1000\n","143/143 [==============================] - 0s 371us/step - loss: 0.0118 - accuracy: 0.9930 - val_loss: 5.7363 - val_accuracy: 0.4182\n","\n","Epoch 00983: val_accuracy did not improve from 0.63636\n","Epoch 984/1000\n","143/143 [==============================] - 0s 395us/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 4.8424 - val_accuracy: 0.4727\n","\n","Epoch 00984: val_accuracy did not improve from 0.63636\n","Epoch 985/1000\n","143/143 [==============================] - 0s 351us/step - loss: 7.7624e-05 - accuracy: 1.0000 - val_loss: 4.1889 - val_accuracy: 0.5091\n","\n","Epoch 00985: val_accuracy did not improve from 0.63636\n","Epoch 986/1000\n","143/143 [==============================] - 0s 359us/step - loss: 2.9065e-04 - accuracy: 1.0000 - val_loss: 3.9412 - val_accuracy: 0.5636\n","\n","Epoch 00986: val_accuracy did not improve from 0.63636\n","Epoch 987/1000\n","143/143 [==============================] - 0s 347us/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 3.9297 - val_accuracy: 0.5636\n","\n","Epoch 00987: val_accuracy did not improve from 0.63636\n","Epoch 988/1000\n","143/143 [==============================] - 0s 349us/step - loss: 7.0446e-05 - accuracy: 1.0000 - val_loss: 4.0486 - val_accuracy: 0.5273\n","\n","Epoch 00988: val_accuracy did not improve from 0.63636\n","Epoch 989/1000\n","143/143 [==============================] - 0s 353us/step - loss: 6.3451e-05 - accuracy: 1.0000 - val_loss: 4.1348 - val_accuracy: 0.5091\n","\n","Epoch 00989: val_accuracy did not improve from 0.63636\n","Epoch 990/1000\n","143/143 [==============================] - 0s 343us/step - loss: 8.5360e-05 - accuracy: 1.0000 - val_loss: 4.1876 - val_accuracy: 0.5091\n","\n","Epoch 00990: val_accuracy did not improve from 0.63636\n","Epoch 991/1000\n","143/143 [==============================] - 0s 350us/step - loss: 2.3901e-04 - accuracy: 1.0000 - val_loss: 4.2123 - val_accuracy: 0.5091\n","\n","Epoch 00991: val_accuracy did not improve from 0.63636\n","Epoch 992/1000\n","143/143 [==============================] - 0s 335us/step - loss: 6.0155e-05 - accuracy: 1.0000 - val_loss: 4.2209 - val_accuracy: 0.5091\n","\n","Epoch 00992: val_accuracy did not improve from 0.63636\n","Epoch 993/1000\n","143/143 [==============================] - 0s 349us/step - loss: 9.5612e-05 - accuracy: 1.0000 - val_loss: 4.2240 - val_accuracy: 0.5091\n","\n","Epoch 00993: val_accuracy did not improve from 0.63636\n","Epoch 994/1000\n","143/143 [==============================] - 0s 371us/step - loss: 5.2956e-04 - accuracy: 1.0000 - val_loss: 4.2695 - val_accuracy: 0.5091\n","\n","Epoch 00994: val_accuracy did not improve from 0.63636\n","Epoch 995/1000\n","143/143 [==============================] - 0s 376us/step - loss: 5.6709e-04 - accuracy: 1.0000 - val_loss: 4.3937 - val_accuracy: 0.5091\n","\n","Epoch 00995: val_accuracy did not improve from 0.63636\n","Epoch 996/1000\n","143/143 [==============================] - 0s 349us/step - loss: 0.0142 - accuracy: 0.9930 - val_loss: 3.8673 - val_accuracy: 0.5455\n","\n","Epoch 00996: val_accuracy did not improve from 0.63636\n","Epoch 997/1000\n","143/143 [==============================] - 0s 359us/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 3.5087 - val_accuracy: 0.5636\n","\n","Epoch 00997: val_accuracy did not improve from 0.63636\n","Epoch 998/1000\n","143/143 [==============================] - 0s 354us/step - loss: 0.0101 - accuracy: 1.0000 - val_loss: 4.5308 - val_accuracy: 0.4364\n","\n","Epoch 00998: val_accuracy did not improve from 0.63636\n","Epoch 999/1000\n","143/143 [==============================] - 0s 354us/step - loss: 2.9065e-04 - accuracy: 1.0000 - val_loss: 5.9731 - val_accuracy: 0.4000\n","\n","Epoch 00999: val_accuracy did not improve from 0.63636\n","Epoch 1000/1000\n","143/143 [==============================] - 0s 349us/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 6.4585 - val_accuracy: 0.4000\n","\n","Epoch 01000: val_accuracy did not improve from 0.63636\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_f9S9rFMVuIw","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594661205690,"user_tz":-330,"elapsed":60325,"user":{"displayName":"Manoj Kaushik","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhhMecDSNh8KC1pSFRd792Uf7-_hhbyuVBzLZm2nQ=s64","userId":"07264516168551766650"}},"outputId":"963b23ec-dd84-49da-e770-cf8130979ab7"},"source":["time = (toc-tic)/60\n","print(\"Total training time is: \", time)"],"execution_count":117,"outputs":[{"output_type":"stream","text":["Total training time is:  1.0372131166666672\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7HszbTl9V4wH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594661205693,"user_tz":-330,"elapsed":60300,"user":{"displayName":"Manoj Kaushik","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhhMecDSNh8KC1pSFRd792Uf7-_hhbyuVBzLZm2nQ=s64","userId":"07264516168551766650"}},"outputId":"0afc24ba-ceb2-46d0-9c83-1f3cf7d00ff8"},"source":["_, acc = model.evaluate(val_x, val_y, verbose=0)\n","print('validation acc> %.3f' % (acc* 100.0), '%, tt:', time,', ml:',maxlen,', bs:',batch_size,', e_d:',embedding_dims,\n","      ', f:',filters,', k_s:',kernel_size,', h_d:',hidden_dims,', epo:',epochs,', m_f:',max_features,', of row number:',row)"],"execution_count":118,"outputs":[{"output_type":"stream","text":["validation acc> 40.000 %, tt: 1.0372131166666672 , ml: 1000 , bs: 32 , e_d: 5 , f: 80 , k_s: 3 , h_d: 300 , epo: 1000 , m_f: 8000 , of row number: 8\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"iB1FkxYbv_Ck","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":122},"executionInfo":{"status":"ok","timestamp":1594661210160,"user_tz":-330,"elapsed":64744,"user":{"displayName":"Manoj Kaushik","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhhMecDSNh8KC1pSFRd792Uf7-_hhbyuVBzLZm2nQ=s64","userId":"07264516168551766650"}},"outputId":"513a72a9-b709-403d-8a71-c241661bd453"},"source":["from keras.models import load_model\n","model_new = load_model(pathModelSave)\n","\n","_train, acc_train = model_new.evaluate(train_x, train_y, verbose=0)\n","print('training acc> %.3f' % (acc_train* 100.0), '%, tt:', time,', ml:',maxlen,', bs:',batch_size,', e_d:',embedding_dims,\n","      ', f:',filters,', k_s:',kernel_size,', h_d:',hidden_dims,', epo:',epochs,', m_f:',max_features,', of row number:',row)\n","\n","_val, acc_val = model_new.evaluate(val_x, val_y, verbose=0)\n","print('val..... acc> %.3f' % (acc_val* 100.0), '%, tt:', time,', ml:',maxlen,', bs:',batch_size,', e_d:',embedding_dims,\n","      ', f:',filters,', k_s:',kernel_size,', h_d:',hidden_dims,', epo:',epochs,', m_f:',max_features,', of row number:',row)\n","\n","_test, acc_test = model_new.evaluate(test_x, test_y, verbose=0)\n","print('testing. acc> %.3f' % (acc_test* 100.0), '%, tt:', time,', ml:',maxlen,', bs:',batch_size,', e_d:',embedding_dims,\n","      ', f:',filters,', k_s:',kernel_size,', h_d:',hidden_dims,', epo:',epochs,', m_f:',max_features,', of row number:',row)"],"execution_count":119,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"],"name":"stderr"},{"output_type":"stream","text":["training acc> 100.000 %, tt: 1.0372131166666672 , ml: 1000 , bs: 32 , e_d: 5 , f: 80 , k_s: 3 , h_d: 300 , epo: 1000 , m_f: 8000 , of row number: 8\n","val..... acc> 63.636 %, tt: 1.0372131166666672 , ml: 1000 , bs: 32 , e_d: 5 , f: 80 , k_s: 3 , h_d: 300 , epo: 1000 , m_f: 8000 , of row number: 8\n","testing. acc> 47.826 %, tt: 1.0372131166666672 , ml: 1000 , bs: 32 , e_d: 5 , f: 80 , k_s: 3 , h_d: 300 , epo: 1000 , m_f: 8000 , of row number: 8\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZoR5LNiyKFO8","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594661210164,"user_tz":-330,"elapsed":64717,"user":{"displayName":"Manoj Kaushik","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhhMecDSNh8KC1pSFRd792Uf7-_hhbyuVBzLZm2nQ=s64","userId":"07264516168551766650"}}},"source":["# training acc> 100.000 %, tt: 0.45934235 , ml: 400 , bs: 32 , e_d: 5 , f: 80 , k_s: 3 , h_d: 300 , epo: 500 , m_f: 8000 , of row number: 8\n","# val..... acc> 65.455 %, tt: 0.45934235 , ml: 400 , bs: 32 , e_d: 5 , f: 80 , k_s: 3 , h_d: 300 , epo: 500 , m_f: 8000 , of row number: 8\n","# testing. acc> 52.174 %, tt: 0.45934235 , ml: 400 , bs: 32 , e_d: 5 , f: 80 , k_s: 3 , h_d: 300 , epo: 500 , m_f: 8000 , of row number: 8\n","\n","#------------------"],"execution_count":120,"outputs":[]},{"cell_type":"code","metadata":{"id":"VpJQpvGJHHmh","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594661210168,"user_tz":-330,"elapsed":64702,"user":{"displayName":"Manoj Kaushik","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhhMecDSNh8KC1pSFRd792Uf7-_hhbyuVBzLZm2nQ=s64","userId":"07264516168551766650"}}},"source":["def convert_string_label(intLabel):\n","  Y = []\n","  length = len(intLabel)\n","  for i in range(length):\n","    if intLabel[i] == 0:\n","      Y.append(\"Control\")\n","    elif intLabel[i] == 1:\n","      Y.append(\"Epilipsy\")\n","  return Y"],"execution_count":121,"outputs":[]},{"cell_type":"code","metadata":{"id":"7yotXHf9Twpu","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":324},"executionInfo":{"status":"ok","timestamp":1594661210170,"user_tz":-330,"elapsed":64680,"user":{"displayName":"Manoj Kaushik","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhhMecDSNh8KC1pSFRd792Uf7-_hhbyuVBzLZm2nQ=s64","userId":"07264516168551766650"}},"outputId":"06c6e44e-66ff-4fd9-e02d-3f3115976211"},"source":["import matplotlib.pyplot as plt\n","from sklearn.metrics import confusion_matrix\n","Y_prediction = model_new.predict(test_x)\n","Y_pred_classes = []\n","for i in Y_prediction:\n","  if i[0] < 0.5:\n","    Y_pred_classes.append(0)\n","  else:\n","    Y_pred_classes.append(1)\n","\n","Y_pred_classes = np.asarray(Y_pred_classes)\n","confusion_mtx = confusion_matrix(test_y, Y_pred_classes)\n","\n","import seaborn as sns\n","plt.figure(figsize=(5,5))\n","sns.heatmap(confusion_mtx, annot=True, fmt=\"d\");"],"execution_count":122,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 360x360 with 2 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"wfMKzcNBxyYD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":573},"executionInfo":{"status":"ok","timestamp":1594661211557,"user_tz":-330,"elapsed":66027,"user":{"displayName":"Manoj Kaushik","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhhMecDSNh8KC1pSFRd792Uf7-_hhbyuVBzLZm2nQ=s64","userId":"07264516168551766650"}},"outputId":"9ab8c987-07fc-4da5-d0cb-a23a0f069f20"},"source":["# author Manoj kaushik\n","import matplotlib.pyplot as plt\n","\n","# Plot training & validation loss values\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('Model loss')\n","plt.ylabel('Loss')\n","plt.xlabel('Epoch')\n","plt.legend(['Training Loss', 'Validation Loss'], loc='upper left')\n","plt.show()\n","\n","# Plot training & validation accuracy values\n","plt.plot(history.history['accuracy'])\n","plt.plot(history.history['val_accuracy'])\n","plt.title('Model accuracy')\n","plt.ylabel('Accuracy')\n","plt.xlabel('Epoch')\n","plt.legend(['Training Accuracy', 'Validation Accuracy'], loc='upper left')\n","plt.show()"],"execution_count":123,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"hcJAzNbl0PYs","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":71},"executionInfo":{"status":"ok","timestamp":1594661212561,"user_tz":-330,"elapsed":66993,"user":{"displayName":"Manoj Kaushik","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhhMecDSNh8KC1pSFRd792Uf7-_hhbyuVBzLZm2nQ=s64","userId":"07264516168551766650"}},"outputId":"ea774518-2cfc-48fb-bff8-0401473c87a5"},"source":["# testing accuracies\n","import time\n","import os\n","import pandas as pd\n","import numpy as np\n","import sys\n","from keras.models import load_model\n","model = load_model(pathModelSave)\n","\n","def predict_fun(filename, type, row):\n","  list = os.listdir(filename)\n","  list.sort()\n","  tic = time.clock()\n","  count_control = 0\n","  count = 0\n","  for name in list:\n","      count += 1\n","      file = os.path.join(filename, name)\n","      df = pd.read_csv(file, header = None, error_bad_lines = False)\n","      values = df.values[row - 1]\n","      data = []\n","      data.append(values.tolist())\n","      data = np.asarray(data)\n","      values = sequence.pad_sequences(data, maxlen = maxlen)\n","      p = model.predict(values)[0][0]\n","      if p < 0.5:\n","        count_control += 1\n","      #   print(count, '. ', name, \": Control predicted\")\n","      # else :\n","      #   print(count, '. ', name, \": Epilipsy Pridicted\")\n","  toc = time.clock()\n","  total_ele = len(list)\n","  print('total files of ' + str(type)+' are :', count, ' control predicted:', count_control, ' epilipsy predicted:', count - count_control, '| row',row)"],"execution_count":124,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n","  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"G3FlehY3Ivm_","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594661212563,"user_tz":-330,"elapsed":66945,"user":{"displayName":"Manoj Kaushik","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhhMecDSNh8KC1pSFRd792Uf7-_hhbyuVBzLZm2nQ=s64","userId":"07264516168551766650"}}},"source":["# total files of control are : 93  control predicted: 91  epilipsy predicted: 2 | row 8\n","# total files of epilipsy are : 128  control predicted: 21  epilipsy predicted: 107 | row 8\n","\n","# total files of control are : 46  control predicted: 15  epilipsy predicted: 31 | row 2\n","# total files of epilipsy are : 51  control predicted: 14  epilipsy predicted: 37 | row 2"],"execution_count":125,"outputs":[]},{"cell_type":"code","metadata":{"id":"oTyrzMrU0Qes","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594661212565,"user_tz":-330,"elapsed":66864,"user":{"displayName":"Manoj Kaushik","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhhMecDSNh8KC1pSFRd792Uf7-_hhbyuVBzLZm2nQ=s64","userId":"07264516168551766650"}}},"source":["# predict_fun('/content/drive/My Drive/datasets/EEGs_Nigeria_transposed/control/', 'control', 8)\n","# predict_fun('/content/drive/My Drive/datasets/EEGs_Nigeria_transposed/epilipsy/', 'epilipsy', 8)"],"execution_count":126,"outputs":[]},{"cell_type":"code","metadata":{"id":"-Kok9ctL0peU","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594661212566,"user_tz":-330,"elapsed":66843,"user":{"displayName":"Manoj Kaushik","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhhMecDSNh8KC1pSFRd792Uf7-_hhbyuVBzLZm2nQ=s64","userId":"07264516168551766650"}}},"source":["# predict_fun('/content/drive/My Drive/datasets/EEGs_Guinea-Bissau_classified/control/', 'control', 2)\n","# predict_fun('/content/drive/My Drive/datasets/EEGs_Guinea-Bissau_classified/epilipsy/', 'epilipsy', 2)"],"execution_count":127,"outputs":[]}]}